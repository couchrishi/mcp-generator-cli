{
  "metadata": {
    "description": "Project description could not be extracted.",
    "discovery_time_utc": "2025-04-08T01:21:01.395721+00:00",
    "discovery_method": "github_api_regex",
    "discovery_counts": {
      "reference_servers": 20,
      "official_integrations": 132,
      "community_servers": 281
    },
    "readme_source_url": "https://api.github.com/repos/modelcontextprotocol/servers/readme",
    "gemini_model_analysis": "gemini-2.5-pro-exp-03-25"
  },
  "items": [
    {
      "name": "AWS KB Retrieval",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/aws-kb-retrieval-server",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.659446+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Brave Search",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/brave-search",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.659929+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "EverArt",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/everart",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.660288+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Everything",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/everything",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.660675+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Fetch",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/fetch",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.661067+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Filesystem",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.661369+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Git",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/git",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.661820+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "GitHub",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/github",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.662239+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "GitLab",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/gitlab",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.662674+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Google Drive",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/gdrive",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.663067+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Google Maps",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/google-maps",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.663618+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Memory",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/memory",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.664003+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "PostgreSQL",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/postgres",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.664355+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Puppeteer",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/puppeteer",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.664662+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Redis",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/redis",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.665198+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Sentry",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/sentry",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.665821+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Sequential Thinking",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.666448+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Slack",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/slack",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.666879+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Sqlite",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/sqlite",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.667379+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Time",
      "repo_url": "https://github.com/modelcontextprotocol/servers/tree/main/src/time",
      "type": "reference",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:18.667714+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32398,
        "forks": 3445,
        "watchers": 32398,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.",
        "tools_exposed": [
          "retrieve_from_aws_kb"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@aws-sdk/client-bedrock-agent-runtime": "^3.0.0"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/aws-kb-retrieval-server /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "21st.dev Magic",
      "repo_url": "https://github.com/21st-dev/magic-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:39.632748+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1052,
        "forks": 71,
        "watchers": 1052,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server, the Magic AI Agent, is an AI-driven tool that helps developers create UI components instantly through natural language descriptions, integrating with various IDEs.",
        "tools_exposed": [
          "/ui"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "@types/cors": "^2.8.17",
            "@types/express": "^5.0.0",
            "@types/node-fetch": "^2.6.12",
            "class-variance-authority": "^0.7.1",
            "clsx": "^2.1.1",
            "cors": "^2.8.5",
            "express": "^4.21.2",
            "framer-motion": "^12.6.2",
            "node-fetch": "^2.7.0",
            "open": "^10.1.0",
            "tailwind-merge": "^3.0.2",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/axios": "^0.9.36",
            "@types/jest": "^29.5.14",
            "@types/node": "^22.13.4",
            "@types/react": "^19.0.12",
            "jest": "^29.7.0",
            "nodemon": "^3.1.9",
            "shx": "^0.3.4",
            "ts-jest": "^29.1.2",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "FROM node:22.14.0-alpine\n\nWORKDIR /app\n\n# Copy package files\nCOPY package.json package-lock.json ./\n\n# Install pnpm and dependencies\nRUN npm install\n\n# Copy application code\nCOPY . .\n\n# Build TypeScript\nRUN npm run build\n\n# Command will be provided by smithery.yaml\nCMD [\"node\", \"dist/index.js\"] ",
        "base_docker_image": "node:22.14.0-alpine"
      }
    },
    {
      "name": "Adfin",
      "repo_url": "https://github.com/Adfin-Engineering/mcp-server-adfin",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:58.535380+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 3,
        "forks": 1,
        "watchers": 3,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates with the Adfin service for financial tasks like credit control checks and invoice creation, and also provides tools for interacting with the local filesystem.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.4.1",
            "requests>=2.32.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Adfin",
      "repo_url": "https://www.adfin.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:21:58.536009+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.adfin.com/"
      }
    },
    {
      "name": "AgentQL",
      "repo_url": "https://github.com/tinyfish-io/agentql-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:22:14.927195+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 34,
        "forks": 4,
        "watchers": 34,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a Model Context Protocol (MCP) server that integrates AgentQL's data extraction capabilities.",
        "tools_exposed": [
          "extract-web-data"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.6.1",
            "node-fetch": "^3.3.2"
          },
          "devDependencies": {
            "@trivago/prettier-plugin-sort-imports": "^4.3.0",
            "@types/node": "^20.11.24",
            "@types/node-fetch": "^2.6.12",
            "@typescript-eslint/eslint-plugin": "^8.4.0",
            "eslint": "^8.57.0",
            "eslint-config-prettier": "^9.1.0",
            "prettier": "^3.4.2",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "FROM node:18-alpine\n\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm install\n\n# Copy application code\nCOPY . .\n\n# Build the application\nRUN npm run build\n\n# Environment variables\nENV AGENTQL_API_KEY=your-api-key\n\n# Command will be provided by smithery.yaml\nCMD [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "AgentQL",
      "repo_url": "https://www.agentql.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:22:14.927450+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.agentql.com/"
      }
    },
    {
      "name": "AgentRPC",
      "repo_url": "https://github.com/agentrpc/agentrpc",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:22:27.766741+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 31,
        "forks": 6,
        "watchers": 31,
        "language_stack": [
          "Go",
          "Node.js",
          "Python"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "An MCP server, included with the AgentRPC TypeScript SDK, that allows external AI models to interact with user-registered tools and functions managed by the AgentRPC platform across network boundaries and languages.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "AgentRPC",
      "repo_url": "https://www.agentrpc.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:22:27.767087+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.agentrpc.com/"
      }
    },
    {
      "name": "Aiven",
      "repo_url": "https://github.com/Aiven-Open/mcp-aiven",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:22:45.322876+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 3,
        "forks": 1,
        "watchers": 3,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server provides access to Aiven services like PostgreSQL, Kafka, ClickHouse, Valkey, and OpenSearch, along with native connectors, enabling LLMs to interact with the Aiven ecosystem.",
        "tools_exposed": [
          "list_projects",
          "list_services",
          "get_service_details"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0",
            "python-dotenv>=1.0.1",
            "uvicorn>=0.34.0",
            "aiven-client>=4.5.1",
            "pip-system-certs>=4.0"
          ],
          "devDependencies": [
            "ruff",
            "pytest"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Aiven projects",
      "repo_url": "https://go.aiven.io/mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:22:45.323174+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://go.aiven.io/mcp-server"
      }
    },
    {
      "name": "Apache IoTDB",
      "repo_url": "https://github.com/apache/iotdb-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:23:02.923791+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 7,
        "forks": 0,
        "watchers": 7,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation providing database interaction and business intelligence capabilities through IoTDB, enabling SQL queries.",
        "tools_exposed": [
          "read_query",
          "list_tables",
          "describe-table"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "apache-iotdb>=2.0.1b0"
          ],
          "devDependencies": [
            "pyright",
            "black",
            "flake8"
          ]
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM python:3.12-alpine\n\n# Install dependencies\nRUN apk add --no-cache gcc musl-dev linux-headers\n\n# Set working directory\nWORKDIR /app\n\n# Copy project files\nCOPY . /app\n\n# Install project dependencies\nRUN pip install --no-cache-dir .\n\n# Expose any necessary ports (if applicable, though MCP uses stdio)\n\n# Run the server\nCMD [\"python\", \"-m\", \"iotdb_mcp_server.server\"]\n",
        "base_docker_image": "python:3.12-alpine"
      }
    },
    {
      "name": "Apache IoTDB",
      "repo_url": "https://github.com/apache/iotdb",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:23:39.403543+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5725,
        "forks": 1037,
        "watchers": 5725,
        "language_stack": [
          "Java"
        ],
        "package_manager": [
          "maven"
        ],
        "dependencies_file": "pom.xml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "IoTDB (Internet of Things Database) is a data management system for time series data, which provides users with specific services, including data collection, storage and analysis.",
        "tools_exposed": [
          "Cli",
          "CSV Import and Export Tool"
        ],
        "packages": {
          "dependencies": [
            {
              "name": "airlift-units",
              "version": "1.7"
            },
            {
              "name": "airlift",
              "version": "206"
            },
            {
              "name": "airline",
              "version": "0.9"
            },
            {
              "name": "antlr4",
              "version": "4.9.3"
            },
            {
              "name": "awaitility",
              "version": "4.2.0"
            },
            {
              "name": "caffeine",
              "version": "2.9.3"
            },
            {
              "name": "cglib",
              "version": "3.3.0"
            },
            {
              "name": "checker-qual",
              "version": "3.38.0"
            },
            {
              "name": "commons-cli",
              "version": "1.5.0"
            },
            {
              "name": "commons-codec",
              "version": "1.16.1"
            },
            {
              "name": "commons-csv",
              "version": "1.10.0"
            },
            {
              "name": "commons-io",
              "version": "2.14.0"
            },
            {
              "name": "commons-jexl3",
              "version": "3.3"
            },
            {
              "name": "commons-lang3",
              "version": "3.13.0"
            },
            {
              "name": "commons-math3",
              "version": "3.6.1"
            },
            {
              "name": "commons-pool2",
              "version": "2.11.1"
            },
            {
              "name": "commons.collections4",
              "version": "4.4"
            },
            {
              "name": "disruptor",
              "version": "3.4.4"
            },
            {
              "name": "drill.freemarker.maven.plugin",
              "version": "1.21.1"
            },
            {
              "name": "dropwizard.metrics",
              "version": "4.2.19"
            },
            {
              "name": "eclipse-collections",
              "version": "11.1.0"
            },
            {
              "name": "felix",
              "version": "5.1.9"
            }
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Apify",
      "repo_url": "https://github.com/apify/actors-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:24:06.081856+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 139,
        "forks": 14,
        "watchers": 139,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An implementation of an MCP server for Apify Actors, enabling AI assistants to use any Actor as a tool for tasks like data extraction and web searching.",
        "tools_exposed": [
          "apify/instagram-scraper",
          "apify/rag-web-browser",
          "lukaskrivka/google-maps-with-contact-details",
          "get-actor-details",
          "discover-actors",
          "add-actor-as-tool",
          "remove-actor-from-tool"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.3.1",
            "ajv": "^8.17.1",
            "apify": "^3.2.6",
            "apify-client": "^2.11.2",
            "express": "^4.21.2",
            "minimist": "^1.2.8",
            "zod": "^3.24.1",
            "zod-to-json-schema": "^3.24.1"
          },
          "devDependencies": {
            "@anthropic-ai/sdk": "^0.33.1",
            "@anthropic-ai/tokenizer": "^0.0.4",
            "@apify/eslint-config": "^0.5.0-beta.2",
            "@apify/tsconfig": "^0.1.0",
            "@types/express": "^4.0.0",
            "@types/minimist": "^1.2.5",
            "dotenv": "^16.4.7",
            "eslint": "^9.17.0",
            "eventsource": "^3.0.2",
            "tsx": "^4.6.2",
            "typescript": "^5.3.3",
            "typescript-eslint": "^8.18.2",
            "vitest": "^3.0.8"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Stage 1: Build the TypeScript project\nFROM node:18-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files and install dependencies\nCOPY package.json package-lock.json ./\nRUN npm install\n\n# Copy source files\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the project\nRUN npm run build\n\n# Stage 2: Set up the runtime environment\nFROM node:18-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy only the necessary files from the build stage\nCOPY --from=builder /app/dist ./dist\nCOPY package.json package-lock.json ./\n\n# Install production dependencies only\nRUN npm ci --omit=dev\n\n# Expose any necessary ports (example: 3000)\nEXPOSE 3000\n\n# Set the environment variable for the Apify token\nENV APIFY_TOKEN=<your-apify-token>\n\n# Set the entry point for the container\nENTRYPOINT [\"node\", \"dist/main.js\"]",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "Actors MCP Server",
      "repo_url": "https://apify.com/apify/actors-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:24:06.082132+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://apify.com/apify/actors-mcp-server"
      }
    },
    {
      "name": "APIMatic MCP",
      "repo_url": "https://github.com/apimatic/apimatic-validator-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:24:23.477686+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1,
        "forks": 2,
        "watchers": 1,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server validates OpenAPI 2.0 and 3.0 specifications (JSON/YAML) using the APIMatic API, processing files and returning validation summaries.",
        "tools_exposed": [
          "validate-openapi-using-apimatic"
        ],
        "packages": {
          "dependencies": {
            "@apimatic/authentication-adapters": "^0.5.6",
            "@apimatic/axios-client-adapter": "^0.3.8",
            "@apimatic/core": "^0.10.18",
            "@apimatic/schema": "^0.7.15",
            "@modelcontextprotocol/sdk": "^1.7.0",
            "adm-zip": "^0.5.16",
            "archiver": "^7.0.1",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/adm-zip": "^0.5.7",
            "@types/archiver": "^6.0.3",
            "@types/node": "^22.13.10",
            "chmod-cli": "^2.0.1",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "APIMatic",
      "repo_url": "https://www.apimatic.io/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:24:23.478020+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.apimatic.io/"
      }
    },
    {
      "name": "Audiense Insights",
      "repo_url": "https://github.com/AudienseCo/mcp-audiense-insights",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:24:42.814755+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6,
        "forks": 3,
        "watchers": 6,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows interaction with an Audiense Insights account to extract marketing insights and audience analysis from reports, covering demographics, culture, influencers, and content engagement.",
        "tools_exposed": [
          "get-reports",
          "get-report-info",
          "get-audience-insights",
          "get-baselines",
          "get-categories",
          "compare-audience-influencers",
          "get-audience-content",
          "report-summary"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.4.1",
            "base-64": "^1.0.0",
            "dotenv": "^16.4.7",
            "node-fetch": "^3.3.2",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/base-64": "^1.0.2",
            "@types/jest": "^29.5.14",
            "@types/node": "^22.12.0",
            "jest": "^29.7.0",
            "ts-jest": "^29.2.6",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use an official Node.js runtime as the base image\nFROM node:18-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json for installing dependencies\nCOPY package.json package-lock.json ./\n\n# Install dependencies (ignoring scripts to avoid running them yet)\nRUN npm install --ignore-scripts\n\n# Copy the rest of the application code\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the TypeScript code\nRUN npm run build\n\n# Use a lighter weight image for running the application\nFROM node:18-alpine\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the built code and node_modules from the builder stage\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY --from=builder /app/package.json ./package.json\n\n# Environment variables (should be replaced with actual credentials in production)\nENV AUDIENSE_CLIENT_ID=your_client_id_here\nENV AUDIENSE_CLIENT_SECRET=your_client_secret_here\nENV TWITTER_BEARER_TOKEN=your_token_here\n\n# Run the application\nCMD [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "Audiense",
      "repo_url": "https://www.audiense.com/products/audiense-insights",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:24:42.815001+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.audiense.com/products/audiense-insights"
      }
    },
    {
      "name": "Axiom",
      "repo_url": "https://github.com/axiomhq/mcp-server-axiom",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:25:05.992312+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 30,
        "forks": 3,
        "watchers": 30,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "Go Modules"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for Axiom that enables AI agents to query data using Axiom Processing Language (APL).",
        "tools_exposed": [
          "queryApl",
          "listDatasets"
        ],
        "packages": {
          "dependencies": [
            "github.com/acrmp/mcp",
            "github.com/axiomhq/axiom-go",
            "golang.org/x/time"
          ],
          "devDependencies": [
            "github.com/atombender/go-jsonschema",
            "github.com/cenkalti/backoff/v4",
            "github.com/fatih/color",
            "github.com/felixge/httpsnoop",
            "github.com/go-logr/logr",
            "github.com/go-logr/stdr",
            "github.com/goccy/go-yaml",
            "github.com/google/go-querystring",
            "github.com/inconshreveable/mousetrap",
            "github.com/klauspost/compress",
            "github.com/mattn/go-colorable",
            "github.com/mattn/go-isatty",
            "github.com/mitchellh/go-wordwrap",
            "github.com/peterbourgon/ff",
            "github.com/peterbourgon/ff/v3",
            "github.com/pkg/errors",
            "github.com/sanity-io/litter",
            "github.com/sourcegraph/jsonrpc2",
            "github.com/spf13/cobra",
            "github.com/spf13/pflag",
            "go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp",
            "go.opentelemetry.io/otel",
            "go.opentelemetry.io/otel/metric",
            "go.opentelemetry.io/otel/trace",
            "golang.org/x/crypto",
            "golang.org/x/exp",
            "golang.org/x/sys",
            "golang.org/x/xerrors"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Bankless Onchain",
      "repo_url": "https://github.com/bankless/onchain-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:25:23.157954+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 22,
        "forks": 5,
        "watchers": 22,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP (Model Context Protocol) server providing a framework for interacting with on-chain blockchain data (state, events, transactions) via the Bankless API.",
        "tools_exposed": [
          "read_contract",
          "get_proxy",
          "get_events",
          "build_event_topic",
          "get_abi",
          "get_source",
          "get_transaction_history",
          "get_transaction_info"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.7.0",
            "@types/node": "^22",
            "@types/node-fetch": "^2.6.12",
            "axios": "^1.8.3",
            "node-fetch": "^3.3.2",
            "universal-user-agent": "^7.0.2",
            "zod": "^3.24.2",
            "zod-to-json-schema": "^3.24.2"
          },
          "devDependencies": {
            "@types/jest": "^29.5.14",
            "shx": "^0.3.4",
            "ts-node": "^10.9.2",
            "typescript": "^5.8.2",
            "vitest": "^3.0.8"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "BICScan",
      "repo_url": "https://github.com/ahnlabio/bicscan-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:25:46.751159+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1,
        "forks": 2,
        "watchers": 1,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Blockchain address risk scoring MCP Server leveraging the BICScan API to provide risk assessments and asset information for blockchain addresses, domains, and dApps.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.5.0",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\r\nFROM ghcr.io/astral-sh/uv:python3.10-bookworm-slim AS uv\r\n\r\n# Install the project into `/app`\r\nWORKDIR /app\r\n\r\n# Enable bytecode compilation\r\nENV UV_COMPILE_BYTECODE=1\r\n\r\n# Copy from the cache instead of linking since it's a mounted volume\r\nENV UV_LINK_MODE=copy\r\n\r\n# Generate proper TOML lockfile first\r\nRUN --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\r\n    uv lock\r\n\r\n# Install the project's dependencies using the lockfile\r\nRUN --mount=type=cache,target=/root/.cache/uv \\\r\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\r\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\r\n    uv sync --frozen --no-install-project --no-dev --no-editable\r\n\r\n# Then, add the rest of the project source code and install it\r\nADD . /app\r\nRUN --mount=type=cache,target=/root/.cache/uv \\\r\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\r\n    uv sync --frozen --no-dev --no-editable\r\n\r\nFROM python:3.10-slim\r\n\r\nWORKDIR /app\r\n\r\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\r\nCOPY .env.example /app/.env\r\n\r\n# Place executables in the environment at the front of the path\r\nENV PATH=\"/app/.venv/bin:$PATH\"\r\n\r\nENTRYPOINT [\"bicscan-mcp\"]\r\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.10-bookworm-slim"
      }
    },
    {
      "name": "Box",
      "repo_url": "https://github.com/box-community/mcp-server-box",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:26:08.720682+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 1,
        "watchers": 8,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "Integrates with the Box API via the Model Context Protocol (MCP) to perform operations like file search, text extraction, AI querying, and data extraction on Box files and folders.",
        "tools_exposed": [
          "box_who_am_i",
          "box_authorize_app_tool",
          "box_search_tool",
          "box_read_tool",
          "box_ask_ai_tool",
          "box_search_folder_by_name",
          "box_ai_extract_data",
          "box_list_folder_content_by_folder_id",
          "box_manage_folder_tool",
          "box_upload_file_tool",
          "box_download_file_tool"
        ],
        "packages": {
          "dependencies": [
            "box-ai-agents-toolkit>=0.0.38",
            "box-sdk-gen>=1.13.0",
            "mcp[cli]>=1.6.0",
            "python-dotenv>=1.1.0"
          ],
          "devDependencies": [
            "pytest>=8.3.5",
            "pytest-asyncio>=0.26.0",
            "pytest-cov>=6.1.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Browserbase",
      "repo_url": "https://github.com/browserbase/mcp-server-browserbase",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:26:21.629870+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 708,
        "forks": 78,
        "watchers": 708,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This server provides cloud browser automation capabilities using Browserbase and Stagehand, enabling LLMs to interact with web pages, take screenshots, and execute JavaScript in a cloud browser environment.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Chargebee",
      "repo_url": "https://github.com/chargebee/agentkit/tree/main/modelcontextprotocol",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:26:41.390677+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6,
        "forks": 1,
        "watchers": 6,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "The Chargebee MCP Server integrates with AI code editors and tools to provide context about Chargebee products/APIs, generate relevant code snippets, and search Chargebee's knowledge base (documentation, FAQs, release notes, etc.).",
        "tools_exposed": [
          "chargebee_documentation_search",
          "chargebee_code_planner"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "commander": "^13.1.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.10",
            "cross-env": "^7.0.3",
            "dotenv": "^16.4.7",
            "shx": "^0.3.4",
            "tsup": "^8.4.0",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Chargebee platform",
      "repo_url": "https://www.chargebee.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:26:41.390973+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.chargebee.com"
      }
    },
    {
      "name": "Chroma",
      "repo_url": "https://github.com/chroma-core/chroma-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:27:03.360108+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 66,
        "forks": 9,
        "watchers": 66,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This server provides data retrieval capabilities powered by Chroma, enabling AI models to manage collections (create, modify, delete, list) and perform operations on documents (add, query, get, update, delete) using vector search, full-text search, and metadata filtering.",
        "tools_exposed": [
          "chroma_list_collections",
          "chroma_create_collection",
          "chroma_peek_collection",
          "chroma_get_collection_info",
          "chroma_get_collection_count",
          "chroma_modify_collection",
          "chroma_delete_collection",
          "chroma_add_documents",
          "chroma_query_documents",
          "chroma_get_documents",
          "chroma_update_documents",
          "chroma_delete_documents"
        ],
        "packages": {
          "dependencies": [
            "chromadb>=1.0.0",
            "cohere>=5.14.2",
            "httpx>=0.28.1",
            "mcp[cli]>=1.2.1",
            "openai>=1.70.0",
            "pillow>=11.1.0",
            "pytest>=8.3.5",
            "pytest-asyncio>=0.26.0",
            "python-dotenv>=0.19.0",
            "typing-extensions>=4.13.1",
            "voyageai>=0.3.2"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM python:3.10-slim\n\n# set working directory\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends gcc\n\n# Copy project files\nCOPY . /app\n\n# Install pip dependencies\nRUN python -m pip install --upgrade pip && \\\n    pip install .\n\n# Expose any necessary ports if needed (e.g., 8080)\nEXPOSE 8080\n\n# Command to run MCP server\nCMD [\"chroma-mcp\"]\n",
        "base_docker_image": "python:3.10-slim"
      }
    },
    {
      "name": "Chronulus AI",
      "repo_url": "https://github.com/ChronulusAI/chronulus-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:27:24.881997+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 44,
        "forks": 4,
        "watchers": 44,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables users to chat with Chronulus AI Forecasting & Prediction Agents directly within the Claude interface.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0",
            "chronulus>=0.0.11",
            "chronulus-core>=0.0.19",
            "pandas",
            "requests"
          ],
          "devDependencies": [
            "mcp[cli]>=1.3.0",
            "twine>=6.1.0"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"chronulus-mcp\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "CircleCI",
      "repo_url": "https://github.com/CircleCI-Public/mcp-server-circleci",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:27:40.042858+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 3,
        "forks": 3,
        "watchers": 3,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This repository provides a Model Context Protocol (MCP) Server for CircleCI, allowing users to interact with CircleCI using natural language through MCP clients like Cursor IDE.",
        "tools_exposed": [
          "get_build_failure_logs"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.8.0",
            "parse-github-url": "^1.0.3",
            "zod": "^3.24.2",
            "zod-to-json-schema": "^3.24.3"
          },
          "devDependencies": {
            "@eslint/js": "^9.21.0",
            "@types/node": "^22",
            "@types/parse-github-url": "^1.0.3",
            "@typescript-eslint/eslint-plugin": "^8.25.0",
            "@typescript-eslint/parser": "^8.25.0",
            "eslint": "^9.21.0",
            "eslint-config-prettier": "^10.0.2",
            "eslint-plugin-prettier": "^5.2.3",
            "nodemon": "^3.1.9",
            "prettier": "^3.5.2",
            "shx": "^0.4.0",
            "tsx": "^4.19.3",
            "typescript": "^5.6.2",
            "typescript-eslint": "^8.28.0",
            "vitest": "^3.1.1"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ClickHouse",
      "repo_url": "https://github.com/ClickHouse/mcp-clickhouse",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:27:55.219880+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 136,
        "forks": 29,
        "watchers": 136,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server for ClickHouse that allows executing SQL queries, listing databases, and listing tables.",
        "tools_exposed": [
          "run_select_query",
          "list_databases",
          "list_tables"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0",
            "python-dotenv>=1.0.1",
            "uvicorn>=0.34.0",
            "clickhouse-connect>=0.8.0",
            "pip-system-certs>=4.0"
          ],
          "devDependencies": [
            "ruff",
            "pytest"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ClickHouse",
      "repo_url": "https://clickhouse.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:27:55.220142+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://clickhouse.com/"
      }
    },
    {
      "name": "Cloudflare",
      "repo_url": "https://github.com/cloudflare/mcp-server-cloudflare",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:28:20.964438+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1239,
        "forks": 83,
        "watchers": 1239,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP Server for Cloudflare's API, allowing interaction with Cloudflare services (Workers, KV, R2, D1, etc.) using natural language via an MCP client like Claude Desktop.",
        "tools_exposed": [
          "get_kvs",
          "kv_get",
          "kv_put",
          "kv_list",
          "kv_delete",
          "r2_list_buckets",
          "r2_create_bucket",
          "r2_delete_bucket",
          "r2_list_objects",
          "r2_get_object",
          "r2_put_object",
          "r2_delete_object",
          "d1_list_databases",
          "d1_create_database",
          "d1_delete_database",
          "d1_query",
          "worker_list",
          "worker_get",
          "worker_put",
          "worker_delete",
          "durable_objects_list",
          "durable_objects_create",
          "durable_objects_delete",
          "durable_objects_list_instances",
          "durable_objects_get_instance",
          "durable_objects_delete_instance",
          "queues_list",
          "queues_create",
          "queues_delete",
          "queues_get",
          "queues_send_message",
          "queues_get_messages",
          "queues_update_consumer",
          "workers_ai_list_models",
          "workers_ai_get_model",
          "workers_ai_run_inference",
          "workers_ai_list_tasks",
          "workflows_list",
          "workflows_create",
          "workflows_delete",
          "workflows_get",
          "workflows_update",
          "workflows_execute",
          "templates_list",
          "templates_get",
          "templates_create_from_template",
          "w4p_list_dispatchers",
          "w4p_create_dispatcher",
          "w4p_delete_dispatcher",
          "w4p_get_dispatcher",
          "w4p_update_dispatcher",
          "bindings_list",
          "bindings_create",
          "bindings_update",
          "bindings_delete",
          "routing_list_routes",
          "routing_create_route",
          "routing_update_route",
          "routing_delete_route",
          "cron_list",
          "cron_create",
          "cron_update",
          "cron_delete",
          "zones_list",
          "zones_create",
          "zones_delete",
          "zones_get",
          "zones_check_activation",
          "secrets_list",
          "secrets_put",
          "secrets_delete",
          "versions_list",
          "versions_get",
          "versions_rollback",
          "wrangler_get_config",
          "wrangler_update_config",
          "analytics_get"
        ],
        "packages": {
          "dependencies": {
            "@iarna/toml": "^2.2.5",
            "@modelcontextprotocol/sdk": "^0.6.0",
            "chalk": "^5.3.0",
            "dotenv": "^16.4.5",
            "undici": "^5.28.4",
            "which": "^5.0.0",
            "xdg-app-paths": "^8.3.0",
            "zod": "^3.23.8"
          },
          "devDependencies": {
            "@cloudflare/workers-types": "^4.20241112.0",
            "@types/node": "^22.10.0",
            "@types/which": "^3.0.4",
            "@vitest/coverage-v8": "^3.0.8",
            "msw": "^2.7.3",
            "prettier": "^3.4.1",
            "shx": "^0.3.4",
            "tsup": "^8.3.5",
            "typescript": "^5.6.2",
            "vitest": "^3.0.8"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "CodeLogic",
      "repo_url": "https://github.com/CodeLogicIncEngineering/codelogic-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:28:45.328840+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP Server designed to utilize Codelogic's software dependency data within an AI programming assistant, primarily for impact assessment.",
        "tools_exposed": [
          "get-impact"
        ],
        "packages": {
          "dependencies": [
            "debugpy>=1.8.12",
            "httpx>=0.28.1",
            "mcp[cli]>=1.3.0",
            "neo4j>=5.28.1",
            "pip-licenses>=5.0.0",
            "python-dotenv>=1.0.1",
            "tenacity>=9.0.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "CodeLogic",
      "repo_url": "https://codelogic.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:28:45.329111+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://codelogic.com"
      }
    },
    {
      "name": "Comet Opik",
      "repo_url": "https://github.com/comet-ml/opik-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:29:05.985658+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 27,
        "forks": 3,
        "watchers": 27,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This is a Model Context Protocol (MCP) server implementation for the Opik platform, providing a unified interface to Opik's capabilities (like prompts, projects, traces, metrics) and enabling IDE integration via multiple transport mechanisms.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "dotenv": "^16.4.5",
            "yargs": "^17.7.2",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@jest/globals": "^29.7.0",
            "@modelcontextprotocol/sdk": "^1.6.1",
            "@types/cors": "^2.8.17",
            "@types/express": "^5.0.0",
            "@types/jest": "^29.5.12",
            "@types/node": "^22.13.9",
            "@typescript-eslint/eslint-plugin": "^7.4.0",
            "@typescript-eslint/parser": "^7.4.0",
            "cors": "^2.8.5",
            "eslint": "^8.57.0",
            "eslint-config-prettier": "^9.1.0",
            "eslint-plugin-prettier": "^5.1.3",
            "express": "^5.0.1",
            "jest": "^29.7.0",
            "jest-environment-jsdom": "^29.7.0",
            "node-fetch": "^3.3.2",
            "pre-commit": "^1.2.2",
            "prettier": "^3.2.5",
            "shx": "^0.3.4",
            "ts-jest": "^29.1.2",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install dependencies without running any scripts\nRUN npm install --ignore-scripts\n\n# Copy the rest of the source code\nCOPY . .\n\n# Build the project\nRUN npm run build\n\n# Expose port if needed (SSE transport might require it, but here we're using stdio)\n\n# Use index.js as the entrypoint\nCMD [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "Opik",
      "repo_url": "https://github.com/comet-ml/opik",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:29:25.881163+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6202,
        "forks": 438,
        "watchers": 6202,
        "language_stack": [
          "Java"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "Opik is an open-source platform for evaluating, testing, and monitoring LLM applications, providing features like tracing, annotations, evaluation metrics, and monitoring dashboards.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Convex",
      "repo_url": "https://stack.convex.dev/convex-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:29:25.881408+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://stack.convex.dev/convex-mcp-server"
      }
    },
    {
      "name": "Dart",
      "repo_url": "https://github.com/its-dart/dart-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:29:46.859781+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 33,
        "forks": 4,
        "watchers": 33,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is the official AI Model Context Protocol (MCP) server for Dart, an AI-powered project management system. It enables AI assistants to perform actions like task and document management within Dart.",
        "tools_exposed": [
          "get_config",
          "list_tasks",
          "create_task",
          "get_task",
          "update_task",
          "delete_task",
          "list_docs",
          "create_doc",
          "get_doc",
          "update_doc",
          "delete_doc"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "~1.5",
            "axios": "~1.8",
            "dotenv": "~16.4",
            "zod": "~3.24"
          },
          "devDependencies": {
            "@types/node": "22.13.13",
            "prettier": "3.4.2",
            "release-it": "17.11.0",
            "shx": "0.3.4",
            "typescript": "5.7.3"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY . /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nRUN --mount=type=cache,target=/root/.npm-production npm ci --ignore-scripts --omit-dev\n\nFROM node:22.12-alpine AS release\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nWORKDIR /app\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Dart",
      "repo_url": "https://itsdart.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:29:46.860100+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://itsdart.com"
      }
    },
    {
      "name": "DevHub",
      "repo_url": "https://github.com/devhub/devhub-cms-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:08.203141+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 2,
        "watchers": 0,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) integration for managing content in the DevHub CMS system.",
        "tools_exposed": [
          "get_businesses",
          "get_locations",
          "get_hours_of_operation",
          "update_hours",
          "get_nearest_location",
          "site_from_url",
          "get_blog_post",
          "create_blog_post",
          "update_blog_post",
          "upload_image"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.4.1",
            "requests-oauthlib>=2.0.0"
          ],
          "devDependencies": [
            "pytest>=7.0.0",
            "pytest-mock>=3.10.0",
            "pytest-cov>=4.1.0"
          ]
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM python:3.10-alpine\n\n# Set work directory\nWORKDIR /app\n\n# Install build dependencies\nRUN apk add --no-cache gcc musl-dev libffi-dev openssl-dev\n\n# Copy project files\nCOPY pyproject.toml ./\nCOPY main.py ./\nCOPY src/ ./src/\nCOPY README.md ./\nCOPY uv.lock ./\nCOPY tests/ ./tests/\n\n# Install pip and project dependencies\nRUN pip install --upgrade pip \\\n    && pip install .\n\n# Expose port if necessary (not required for stdio transport)\n\n# Default command to run the MCP server\nCMD [\"python\", \"main.py\"]\n",
        "base_docker_image": "python:3.10-alpine"
      }
    },
    {
      "name": "DevHub",
      "repo_url": "https://www.devhub.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:08.203426+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.devhub.com"
      }
    },
    {
      "name": "E2B",
      "repo_url": "https://github.com/e2b-dev/mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:24.559476+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 191,
        "forks": 29,
        "watchers": 191,
        "language_stack": [
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "The E2B MCP server adds code interpreting capabilities to the Claude Desktop app via the E2B Sandbox.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {
            "@changesets/cli": "^2.27.12",
            "@changesets/read": "^0.6.2",
            "changeset": "^0.2.6"
          }
        },
        "dockerfile_content": "# Dockerfile for E2B MCP Server JavaScript Edition\n\nFROM node:22-alpine AS builder\n\nWORKDIR /app\n\n# Copy the application files\nCOPY packages/js/ .\n\n# Install dependencies\nRUN npm install\n\n# Build the application\nRUN npm run build\n\nENV NODE_ENV=production\n\nENTRYPOINT [\"node\", \"./build/index.js\"]\n",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "E2B",
      "repo_url": "https://e2b.dev",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:24.559877+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://e2b.dev"
      }
    },
    {
      "name": "EduBase",
      "repo_url": "https://github.com/EduBase/MCP",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:38.866963+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 2,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is an MCP server implementation for the EduBase platform, allowing MCP clients and LLMs to interact with a user's EduBase account.",
        "tools_exposed": [
          "edubase_<method>_<endpoint>",
          "edubase_get_user"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.6.1",
            "query-string": "^9.1.1"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "## Multi-stage builder\nFROM node:22-alpine AS builder\nCOPY . /build\nWORKDIR /build\nRUN --mount=type=cache,target=/root/.npm npm install\n\n## EduBase MCP server image\nFROM node:22-alpine AS server\nWORKDIR /app\nCOPY --from=builder /build/dist /app/dist\nCOPY --from=builder /build/package.json /app/package.json\nCOPY --from=builder /build/package-lock.json /app/package-lock.json\nENV NODE_ENV=production\nRUN npm ci --ignore-scripts --omit-dev\nUSER node\nENTRYPOINT [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "EduBase",
      "repo_url": "https://www.edubase.net",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:38.867241+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.edubase.net"
      }
    },
    {
      "name": "Elasticsearch",
      "repo_url": "https://github.com/elastic/mcp-server-elasticsearch",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:54.607161+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 61,
        "forks": 5,
        "watchers": 61,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Connects MCP clients (like Claude Desktop) to Elasticsearch data using the Model Context Protocol, allowing interaction with Elasticsearch indices through natural language conversations.",
        "tools_exposed": [
          "list_indices",
          "get_mappings",
          "search",
          "get_shards"
        ],
        "packages": {
          "dependencies": {
            "@elastic/elasticsearch": "^8.17.1",
            "@modelcontextprotocol/sdk": "1.8.0"
          },
          "devDependencies": {
            "@types/node": "22.13.15",
            "shx": "0.4.0",
            "typescript": "5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Elasticsearch",
      "repo_url": "https://www.elastic.co/elasticsearch",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:30:54.607444+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.elastic.co/elasticsearch"
      }
    },
    {
      "name": "eSignatures",
      "repo_url": "https://github.com/esignaturescom/mcp-server-esignatures",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:31:14.005231+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 11,
        "forks": 4,
        "watchers": 11,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP server for eSignatures (https://esignatures.com), enabling contract and template management.",
        "tools_exposed": [
          "create_contract",
          "query_contract",
          "withdraw_contract",
          "delete_contract",
          "list_recent_contracts",
          "create_template",
          "update_template",
          "query_template",
          "delete_template",
          "list_templates",
          "add_template_collaborator",
          "remove_template_collaborator",
          "list_template_collaborators"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.2.0",
            "twine>=6.1.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Exa",
      "repo_url": "https://github.com/exa-labs/exa-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:31:35.808237+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 499,
        "forks": 44,
        "watchers": 499,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This Model Context Protocol (MCP) server allows AI assistants like Claude to utilize the Exa AI Search API for web searches, enabling access to real-time web information in a controlled manner.",
        "tools_exposed": [
          "web_search",
          "research_paper_search",
          "twitter_search",
          "company_research"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "axios": "^1.7.8",
            "dotenv": "^16.4.5",
            "yargs": "^17.7.2",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "@types/yargs": "^17.0.33",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Use the official Node.js 18 image as a parent image\nFROM node:18-alpine AS builder\n\n# Set the working directory in the container to /app\nWORKDIR /app\n\n# Copy package.json and package-lock.json into the container\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN npm ci --ignore-scripts\n\n# Copy the rest of the application code into the container\nCOPY src/ ./src/\nCOPY tsconfig.json ./\n\n# Build the project\nRUN npm run build\n\n# Use a minimal node image as the base image for running\nFROM node:18-alpine AS runner\n\nWORKDIR /app\n\n# Copy compiled code from the builder stage\nCOPY --from=builder /app/build ./build\nCOPY package.json package-lock.json ./\n\n# Install only production dependencies\nRUN npm ci --production --ignore-scripts\n\n# Set environment variable for the Exa API key\nENV EXA_API_KEY=your-api-key-here\n\n# Expose the port the app runs on\nEXPOSE 3000\n\n# Run the application\nENTRYPOINT [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "Exa",
      "repo_url": "https://exa.ai",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:31:35.808561+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://exa.ai"
      }
    },
    {
      "name": "Fewsats",
      "repo_url": "https://github.com/Fewsats/fewsats-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:31:51.885990+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 2,
        "watchers": 9,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates with Fewsats and allows AI Agents to purchase anything in a secure way.",
        "tools_exposed": [
          "balance",
          "payment_methods",
          "pay_offer",
          "payment_info"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.4.1",
            "fewsats>=0.0.19"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Fewsats",
      "repo_url": "https://fewsats.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:31:51.886355+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://fewsats.com"
      }
    },
    {
      "name": "Fibery",
      "repo_url": "https://github.com/Fibery-inc/fibery-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:32:09.564048+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 2,
        "watchers": 9,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server integrates Fibery with LLM providers supporting the MCP protocol, enabling interaction with a Fibery workspace using natural language.",
        "tools_exposed": [
          "list_databases",
          "describe_database",
          "query_database",
          "create_entity",
          "update_entity"
        ],
        "packages": {
          "dependencies": [
            "click>=8.1.8",
            "httpx>=0.28.1",
            "mcp[cli]>=1.4.1",
            "pydantic>=2.10.6",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": [
            "build>=1.2.2.post1",
            "pytest>=8.3.5",
            "pytest-asyncio>=0.25.3",
            "ruff>=0.11.0",
            "twine>=6.1.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Fibery",
      "repo_url": "https://fibery.io",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:32:09.564322+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://fibery.io"
      }
    },
    {
      "name": "Financial Datasets",
      "repo_url": "https://github.com/financial-datasets/mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:32:26.766255+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 180,
        "forks": 24,
        "watchers": 180,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing access to stock market data (income statements, balance sheets, cash flow statements, prices, news) from Financial Datasets for AI assistants.",
        "tools_exposed": [
          "get_income_statements",
          "get_balance_sheets",
          "get_cash_flow_statements",
          "get_current_price",
          "get_prices",
          "get_news"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.3.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Firecrawl",
      "repo_url": "https://github.com/mendableai/firecrawl-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:32:47.032566+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2227,
        "forks": 197,
        "watchers": 2227,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation that integrates with Firecrawl for web scraping capabilities, including scraping, crawling, searching, extraction, and batch processing.",
        "tools_exposed": [
          "firecrawl_scrape"
        ],
        "packages": {
          "dependencies": {
            "@mendable/firecrawl-js": "^1.19.0",
            "@modelcontextprotocol/sdk": "^1.4.1",
            "dotenv": "^16.4.7",
            "p-queue": "^8.0.1",
            "shx": "^0.3.4",
            "ws": "^8.18.1"
          },
          "devDependencies": {
            "@jest/globals": "^29.7.0",
            "@types/jest": "^29.5.14",
            "@types/node": "^20.10.5",
            "@typescript-eslint/eslint-plugin": "^7.0.0",
            "@typescript-eslint/parser": "^7.0.0",
            "eslint": "^8.56.0",
            "eslint-config-prettier": "^9.1.0",
            "jest": "^29.7.0",
            "jest-mock-extended": "^4.0.0-beta1",
            "prettier": "^3.1.1",
            "ts-jest": "^29.1.1",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image as the base for building the application\nFROM node:18-alpine AS builder\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Copy package.json and package-lock.json to install dependencies\nCOPY package.json package-lock.json ./\n\n# Install dependencies (ignoring scripts to prevent running the prepare script)\nRUN npm install --ignore-scripts\n\n# Copy the rest of the application source code\nCOPY . .\n\n# Build the application using TypeScript\nRUN npm run build\n\n# Use a smaller Node.js image for the final image\nFROM node:18-slim AS release\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Copy the built application from the builder stage\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\n# Install only production dependencies\nRUN npm ci --omit=dev --ignore-scripts\n\n# Set environment variables for API key and custom API URL if needed\nENV FIRECRAWL_API_KEY=your-api-key\nENV FIRECRAWL_API_URL=https://firecrawl.your-domain.com\n\n# Specify the command to run the application\nENTRYPOINT [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "Firecrawl",
      "repo_url": "https://firecrawl.dev",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:32:47.032784+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://firecrawl.dev"
      }
    },
    {
      "name": "Fireproof",
      "repo_url": "https://github.com/fireproof-storage/mcp-database-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:33:01.228761+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 14,
        "forks": 4,
        "watchers": 14,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This demo MCP server provides a basic JSON document store using a Fireproof database, supporting CRUD operations and sorted queries.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@fireproof/cloud": "^0.19.118",
            "@modelcontextprotocol/sdk": "0.6.0",
            "use-fireproof": "^0.19.118"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": "node"
      }
    },
    {
      "name": "Gitee",
      "repo_url": "https://github.com/oschina/mcp-gitee",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:33:20.462627+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 17,
        "forks": 2,
        "watchers": 17,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "go modules"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for Gitee, providing tools for AI assistants to interact with Gitee's API to manage repositories, issues, pull requests, notifications, and more.",
        "tools_exposed": [
          "list_user_repos",
          "get_file_content",
          "create_user_repo",
          "create_org_repo",
          "create_enter_repo",
          "create_release",
          "list_releases",
          "list_repo_pulls",
          "merge_pull",
          "create_pull",
          "update_pull",
          "get_pull_detail",
          "comment_pull",
          "list_pull_comments",
          "create_issue",
          "update_issue",
          "get_repo_issue_detail",
          "list_repo_issues",
          "comment_issue",
          "list_issue_comments",
          "get_user_info",
          "list_user_notifications"
        ],
        "packages": {
          "dependencies": [
            "github.com/mark3labs/mcp-go@v0.11.2",
            "github.com/google/uuid@v1.6.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM golang:1.23-bullseye AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy go.mod and go.sum files\nCOPY go.mod go.sum ./\n\n# Download dependencies\nRUN go mod download\n\n# Copy the source code\nCOPY . .\n\n# Build the application\nRUN go build -o mcp-gitee .\n\n# Final stage\nFROM debian:bullseye-slim\n\n# Install ca-certificates for HTTPS requests\nRUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*\n\n# Create a non-root user\nRUN useradd -r -u 1000 -m gitee\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the binary from the builder stage\nCOPY --from=builder --chown=1000:1000 /app/mcp-gitee /app/\n\n# Use the non-root user\nUSER gitee\n\n# Expose the port the app runs on\nEXPOSE 8000\n\n# Run the application\nENTRYPOINT [\"/app/mcp-gitee\", \"--transport\", \"sse\", \"--sse-address\", \"0.0.0.0:8000\"]",
        "base_docker_image": "golang:1.23-bullseye"
      }
    },
    {
      "name": "gotoHuman",
      "repo_url": "https://github.com/gotohuman/gotohuman-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:33:32.084603+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 13,
        "forks": 2,
        "watchers": 13,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables AI agents to request human reviews, approvals, or input via the gotoHuman platform using an asynchronous webhook-based workflow.",
        "tools_exposed": [
          "list-forms",
          "get-form-schema",
          "request-human-review-with-form"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "gotohuman": "^0.2.8"
          },
          "devDependencies": {
            "@types/node": "^22.13.4",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "gotoHuman",
      "repo_url": "https://www.gotohuman.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:33:32.084897+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.gotohuman.com"
      }
    },
    {
      "name": "Grafana",
      "repo_url": "https://github.com/grafana/mcp-grafana",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:33:58.818092+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 365,
        "forks": 28,
        "watchers": 365,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "Go Modules"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server for Grafana, providing access to a Grafana instance and its surrounding ecosystem (dashboards, datasources, Prometheus, Loki, Incidents, Alerting, OnCall).",
        "tools_exposed": [
          "search_dashboards",
          "get_dashboard_by_uid",
          "list_datasources",
          "get_datasource_by_uid",
          "get_datasource_by_name",
          "query_prometheus",
          "list_prometheus_metric_metadata",
          "list_prometheus_metric_names",
          "list_prometheus_label_names",
          "list_prometheus_label_values",
          "list_incidents",
          "create_incident",
          "add_activity_to_incident",
          "resolve_incident",
          "query_loki_logs",
          "list_loki_label_names",
          "list_loki_label_values",
          "query_loki_stats",
          "list_alert_rules",
          "get_alert_rule_by_uid",
          "list_oncall_schedules",
          "get_oncall_shift",
          "get_current_oncall_users",
          "list_oncall_teams",
          "list_oncall_users"
        ],
        "packages": {
          "dependencies": [
            "github.com/go-openapi/strfmt",
            "github.com/grafana/amixr-api-go-client",
            "github.com/grafana/grafana-openapi-client-go",
            "github.com/grafana/incident-go",
            "github.com/invopop/jsonschema",
            "github.com/mark3labs/mcp-go",
            "github.com/prometheus/client_golang",
            "github.com/prometheus/common",
            "github.com/prometheus/prometheus",
            "github.com/stretchr/testify"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Build stage\nFROM golang:1.24-bullseye AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy go.mod and go.sum files\nCOPY go.mod go.sum ./\n\n# Download dependencies\nRUN go mod download\n\n# Copy the source code\nCOPY . .\n\n# Build the application\nRUN go build -o mcp-grafana ./cmd/mcp-grafana\n\n# Final stage\nFROM debian:bullseye-slim\n\n# Install ca-certificates for HTTPS requests\nRUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*\n\n# Create a non-root user\nRUN useradd -r -u 1000 -m mcp-grafana\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the binary from the builder stage\nCOPY --from=builder --chown=1000:1000 /app/mcp-grafana /app/\n\n# Use the non-root user\nUSER mcp-grafana\n\n# Expose the port the app runs on\nEXPOSE 8000\n\n# Run the application\nENTRYPOINT [\"/app/mcp-grafana\", \"--transport\", \"sse\", \"--sse-address\", \"0.0.0.0:8000\"]\n",
        "base_docker_image": "golang:1.24-bullseye"
      }
    },
    {
      "name": "Graphlit",
      "repo_url": "https://github.com/graphlit/graphlit-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:34:16.389969+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 152,
        "forks": 21,
        "watchers": 152,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This server integrates Model Context Protocol (MCP) clients with the Graphlit service, enabling ingestion from various sources (Slack, Drive, email, etc.) and knowledge retrieval within MCP clients.",
        "tools_exposed": [
          "Query Contents",
          "Query Collections",
          "Query Feeds",
          "Retrieve Relevant Sources",
          "Retrieve Similar Images",
          "Visually Describe Image",
          "Extract Structured JSON from Text",
          "Files",
          "Web Pages",
          "Messages",
          "Posts",
          "Emails",
          "Issues",
          "Text",
          "Microsoft Outlook email",
          "Google Mail",
          "Notion",
          "Reddit",
          "Linear",
          "Jira",
          "GitHub Issues",
          "Google Drive",
          "OneDrive",
          "SharePoint",
          "Dropbox",
          "Box",
          "GitHub",
          "Slack",
          "Microsoft Teams",
          "Discord",
          "Twitter/X",
          "Podcasts (RSS)",
          "Web Crawling",
          "Web Search",
          "Web Mapping",
          "Screenshot Page",
          "Slack",
          "Email",
          "Webhook",
          "Twitter/X",
          "Configure Project",
          "Create Collection",
          "Add Contents to Collection",
          "Remove Contents from Collection",
          "Delete Collection(s)",
          "Delete Feed(s)",
          "Delete Content(s)",
          "Is Feed Done?",
          "Is Content Done?",
          "List Slack Channels",
          "List Microsoft Teams Teams",
          "List Microsoft Teams Channels",
          "List SharePoint Libraries",
          "List SharePoint Folders",
          "List Linear Projects",
          "List Notion Databases"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "graphlit-client": "^1.0.20250407001"
          },
          "devDependencies": {
            "@types/mime-types": "^2.1.4",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\n# Create app directory\nWORKDIR /usr/src/app\n\n# Install app dependencies\nCOPY package*.json ./\nRUN npm install --production --ignore-scripts\n\n# Copy app source code\nCOPY . .\n\n# Build the project\nRUN npm run build\n\n# Expose port if needed (adjust if your server listens on a port)\n# EXPOSE 3000\n\n# Start the server\nCMD [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "Graphlit",
      "repo_url": "https://www.graphlit.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:34:16.390256+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.graphlit.com"
      }
    },
    {
      "name": "GreptimeDB",
      "repo_url": "https://github.com/GreptimeTeam/greptimedb-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:34:33.051877+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 3,
        "watchers": 12,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server implementation for GreptimeDB, providing AI assistants with a secure and structured way to explore and analyze databases, list tables, read data, and execute SQL queries.",
        "tools_exposed": [
          "list_resources",
          "read_resource",
          "list_tools",
          "call_tool",
          "list_prompts",
          "get_prompt"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "mysql-connector-python>=9.1.0",
            "pyyaml>=6.0.2"
          ],
          "devDependencies": [
            "pyright",
            "black",
            "flake8",
            "pytest",
            "pytest-asyncio",
            "pytest-cov"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "GreptimeDB",
      "repo_url": "https://github.com/GreptimeTeam/greptimedb",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:35:18.943535+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4831,
        "forks": 353,
        "watchers": 4831,
        "language_stack": [
          "Rust"
        ],
        "package_manager": [
          "Cargo"
        ],
        "dependencies_file": "Cargo.toml",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "GreptimeDB is an open-source, unified, and cost-effective observability database designed for handling metrics, logs, and events, enabling real-time insights from edge to cloud.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            {
              "name": "ahash",
              "version": "0.8",
              "source": null
            },
            {
              "name": "aquamarine",
              "version": "0.6",
              "source": null
            },
            {
              "name": "arrow",
              "version": "53.0.0",
              "source": null
            },
            {
              "name": "arrow-array",
              "version": "53.0.0",
              "source": null
            },
            {
              "name": "arrow-flight",
              "version": "53.0",
              "source": null
            },
            {
              "name": "arrow-ipc",
              "version": "53.0.0",
              "source": null
            },
            {
              "name": "arrow-schema",
              "version": "53.0",
              "source": null
            },
            {
              "name": "async-stream",
              "version": "0.3",
              "source": null
            },
            {
              "name": "async-trait",
              "version": "0.1",
              "source": null
            },
            {
              "name": "axum",
              "version": "0.8",
              "source": null
            },
            {
              "name": "axum-extra",
              "version": "0.10",
              "source": null
            },
            {
              "name": "axum-macros",
              "version": "0.5",
              "source": null
            },
            {
              "name": "backon",
              "version": "1",
              "source": null
            },
            {
              "name": "base64",
              "version": "0.22",
              "source": null
            },
            {
              "name": "bigdecimal",
              "version": "0.4.2",
              "source": null
            },
            {
              "name": "bitflags",
              "version": "2.4.1",
              "source": null
            },
            {
              "name": "bytemuck",
              "version": "1.12",
              "source": null
            },
            {
              "name": "bytes",
              "version": "1.7",
              "source": null
            },
            {
              "name": "chrono",
              "version": "0.4",
              "source": null
            },
            {
              "name": "chrono-tz",
              "version": "0.10.1",
              "source": null
            },
            {
              "name": "clap",
              "version": "4.4",
              "source": null
            },
            {
              "name": "config",
              "version": "0.13.0",
              "source": null
            },
            {
              "name": "crossbeam-utils",
              "version": "0.8",
              "source": null
            },
            {
              "name": "dashmap",
              "version": "6.1",
              "source": null
            },
            {
              "name": "datafusion",
              "version": null,
              "source": "git+https://github.com/apache/datafusion.git#2464703c84c400a09cc59277018813f0e797bb4e"
            },
            {
              "name": "datafusion-common",
              "version": null,
              "source": "git+https://github.com/apache/datafusion.git#2464703c84c400a09cc59277018813f0e797bb4e"
            },
            {
              "name": "datafusion-expr",
              "version": null,
              "source": "git+https://github.com/apache/datafusion.git#2464703c84c400a09cc59277018813f0e797bb4e"
            },
            {
              "name": "datafusion-functions",
              "version": null,
              "source": "git+https://github.com/apache/datafusion.git#2464703c84c400a09cc59277018813f0e797bb4e"
            },
            {
              "name": "datafusion-optimizer",
              "version": null,
              "source": "git+https://github.com/apache/datafusion.git#2464703c84c400a09cc59277018813f0e797bb4e"
            },
            {
              "name": "datafusion-physical-expr",
              "version": null,
              "source": "git+https://github.com/apache/datafusion.git#2464703c84c400a09cc59277018813f0e797bb4e"
            },
            {
              "name": "datafusion-physical-plan",
              "version": null,
              "source": "git+https://github.com/apache/datafusion.git#2464703c84c400a09cc59277"
            }
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Hologres",
      "repo_url": "https://github.com/aliyun/alibabacloud-hologres-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:35:37.555673+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 1,
        "watchers": 12,
        "language_stack": [
          "Python",
          "Node.js"
        ],
        "package_manager": [
          "uv",
          "npm"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Serves as a universal interface for AI Agents to interact with Hologres databases, enabling metadata retrieval and SQL execution.",
        "tools_exposed": [
          "execute_select_sql",
          "execute_dml_sql",
          "execute_ddl_sql",
          "gather_table_statistics",
          "get_query_plan",
          "get_execution_plan"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp>=1.4.1",
            "python-dotenv>=1.0.1",
            "psycopg>=3.1.0",
            "psycopg-binary>=3.1.0",
            "pglast>=7.5"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Hologres",
      "repo_url": "https://www.alibabacloud.com/en/product/hologres",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:35:37.555902+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.alibabacloud.com/en/product/hologres"
      }
    },
    {
      "name": "Hyperbrowser",
      "repo_url": "https://github.com/hyperbrowserai/mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:35:54.491475+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 190,
        "forks": 10,
        "watchers": 190,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides tools to scrape, extract structured data, and crawl webpages, as well as access to general purpose browser agents like OpenAI's CUA, Anthropic's Claude Computer Use, and Browser Use.",
        "tools_exposed": [
          "scrape_webpage",
          "crawl_webpages",
          "extract_structured_data",
          "search_with_bing",
          "browser_use_agent",
          "openai_computer_use_agent",
          "claude_computer_use_agent"
        ],
        "packages": {
          "dependencies": {
            "@hyperbrowser/sdk": "^0.39.0",
            "@modelcontextprotocol/sdk": "^1.6.0",
            "ajv": "^8.17.1",
            "axios": "^1.8.3",
            "dotenv": "^16.4.7",
            "express": "^4.21.2"
          },
          "devDependencies": {
            "@types/express": "^5.0.0",
            "@types/node": "^16.11.7",
            "openai": "^4.87.3",
            "ts-node": "^10.9.2",
            "typescript": "^4.5.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\n# Create app directory\nWORKDIR /usr/src/app\n\n# Install app dependencies\nCOPY package*.json ./\n\n# Use npm ci if package-lock.json exists\nRUN npm install --ignore-scripts\n\n# Bundle app source\nCOPY . .\n\n# Build the project\nRUN npm run build\n\n# Expose port if necessary (assuming the server listens on a port, if not, remove it)\n# EXPOSE 3000\n\n# Run the server\nCMD [\"node\", \"dist/server.js\"]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "Hyperbrowser",
      "repo_url": "https://www.hyperbrowser.ai/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:35:54.491697+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.hyperbrowser.ai/"
      }
    },
    {
      "name": "IBM wxflows",
      "repo_url": "https://github.com/IBM/wxflows/tree/main/examples/mcp/javascript",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:36:10.282856+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 71,
        "forks": 24,
        "watchers": 71,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server demonstrating integration with the watsonx.ai Flows Engine (`wxflows`) to expose external tools like `google_books` and `wikipedia`.",
        "tools_exposed": [
          "google_books",
          "wikipedia"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "@wxflows/sdk": "^0.2.0-beta.6",
            "dotenv": "^16.4.5"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ForeverVM",
      "repo_url": "https://github.com/jamsocket/forevervm/tree/main/javascript/mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:36:21.549222+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 170,
        "forks": 9,
        "watchers": 170,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Server for ForeverVM, enabling Claude to execute code in a Python REPL.",
        "tools_exposed": [
          "create-python-repl",
          "run-python-in-repl"
        ],
        "packages": {
          "dependencies": {
            "@forevervm/sdk": "^0.1.22",
            "@modelcontextprotocol/sdk": "^1.3.1",
            "commander": "^13.1.0",
            "prettier": "^3.4.2",
            "shx": "^0.3.4",
            "yaml": "^2.7.0",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/node": "^22.10.7",
            "tsx": "^4.19.2",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Inbox Zero",
      "repo_url": "https://github.com/elie222/inbox-zero/tree/main/apps/mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:36:35.854269+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5246,
        "forks": 560,
        "watchers": 5246,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server designed to manage your inbox efficiently and interact with an Inbox Zero personal assistant within environments like Cursor, Windsurf, or Claude desktop.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.8.0",
            "zod": "3.24.2"
          },
          "devDependencies": {
            "@types/node": "22.13.14",
            "typescript": "5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Inbox Zero",
      "repo_url": "https://www.getinboxzero.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:36:35.854549+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.getinboxzero.com"
      }
    },
    {
      "name": "Inkeep",
      "repo_url": "https://github.com/inkeep/mcp-server-python",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:36:57.649668+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 1,
        "watchers": 5,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Inkeep MCP Server powered by your docs and product content.",
        "tools_exposed": [
          "search-product-content"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0",
            "openai>=1.66.3",
            "pydantic-settings>=2.8.1"
          ],
          "devDependencies": [
            "black>=25.1.0",
            "ipython>=8.34.0",
            "isort>=6.0.1"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Inkeep",
      "repo_url": "https://inkeep.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:36:57.649943+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://inkeep.com"
      }
    },
    {
      "name": "Integration App",
      "repo_url": "https://github.com/integration-app/mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:37:19.928888+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 14,
        "forks": 2,
        "watchers": 14,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that exposes tools defined as Actions within an Integration App workspace.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@integration-app/sdk": "^1.5.1",
            "@modelcontextprotocol/sdk": "^1.1.1"
          },
          "devDependencies": {
            "@types/eslint": "^8.56.12",
            "@types/node": "^22.10.1",
            "@typescript-eslint/eslint-plugin": "^7.18.0",
            "@typescript-eslint/parser": "^7.18.0",
            "eslint": "^8.57.1",
            "eslint-config-prettier": "^9.1.0",
            "eslint-plugin-prettier": "^5.2.1",
            "eslint-plugin-unused-imports": "^3.0.0",
            "prettier": "^3.3.3",
            "tsx": "^4.19.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "JetBrains",
      "repo_url": "https://github.com/JetBrains/mcp-jetbrains",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:37:36.380523+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 427,
        "forks": 37,
        "watchers": 427,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "The server proxies requests from a client to a JetBrains IDE.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.7.0",
            "node-fetch": "^3.3.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.13",
            "shx": "^0.4.0",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Kagi Search",
      "repo_url": "https://github.com/kagisearch/kagimcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:37:54.988524+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 55,
        "forks": 11,
        "watchers": 55,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides access to Kagi's search and summarization tools, requiring a Kagi API key.",
        "tools_exposed": [
          "search",
          "summarizer"
        ],
        "packages": {
          "dependencies": [
            "kagiapi~=0.2.1",
            "mcp[cli]~=1.6.0",
            "pydantic~=2.10.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into /app\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy the lock file and pyproject.toml for dependency management\nCOPY uv.lock pyproject.toml /app/\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\n# Create the final image\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim\n\nWORKDIR /app\n\n# Copy the virtual environment directly\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Create app user\nRUN useradd -m app\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Environment variable for the Kagi API key\nENV KAGI_API_KEY=YOUR_API_KEY_HERE\n\n# Switch to non-root user\nUSER app\n\n# Run the MCP server\nENTRYPOINT [\"uv\", \"run\", \"kagimcp\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Keboola",
      "repo_url": "https://github.com/keboola/keboola-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:38:14.986844+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 3,
        "watchers": 9,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server for interacting with Keboola Connection. This server provides tools for listing and accessing data from Keboola Storage API.",
        "tools_exposed": [
          "List buckets and tables",
          "Get bucket and table information",
          "Preview table data",
          "Export table data to CSV",
          "List components and configurations"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli] ~= 1.6",
            "kbcstorage ~= 0.9",
            "httpx ~= 0.28"
          ],
          "devDependencies": [
            "pytest ~= 8.3",
            "pytest-asyncio ~= 0.25",
            "pytest-cov ~= 6.0",
            "pytest-mock ~= 3.14",
            "black ~= 25.1",
            "isort ~= 6.0",
            "mypy ~= 1.5"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into /app\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nCOPY uv.lock pyproject.toml /app/\nRUN --mount=type=cache,target=/root/.cache/uv     uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD src /app/src\nRUN --mount=type=cache,target=/root/.cache/uv     uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --api-url and a bind mount to the host's db file\nENTRYPOINT [\"python\", \"-m\", \"keboola_mcp_server.cli\", \"--api-url\", \"https://connection.YOUR_REGION.keboola.com\", \"--log-level\", \"DEBUG\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Lara Translate",
      "repo_url": "https://github.com/translated/lara-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:38:34.552374+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 35,
        "forks": 1,
        "watchers": 35,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) Server for Lara Translate API, enabling powerful translation capabilities with support for language detection and context-aware translations.",
        "tools_exposed": [
          "translate"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "@translated/lara": "^1.4.0",
            "zod": "^3.24.2",
            "zod-to-json-schema": "^3.24.5"
          },
          "devDependencies": {
            "@types/node": "^22.13.14",
            "ts-node": "^10.9.2",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "FROM node:22.13.1-alpine AS builder\n\nWORKDIR /app\n\nCOPY package.json pnpm-lock.yaml ./\nRUN npm install -g pnpm@latest-10\nRUN pnpm install --frozen-lockfile\n\nCOPY . .\nRUN pnpm run build\n\n\nFROM node:22.13.1-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/pnpm-lock.yaml /app/pnpm-lock.yaml\n\nENV NODE_ENV=production\n\nRUN npm install -g pnpm@latest-10\nRUN pnpm install --frozen-lockfile --prod\n\nENTRYPOINT [\"node\", \"/app/dist/index.js\"]\n",
        "base_docker_image": "node:22.13.1-alpine"
      }
    },
    {
      "name": "Logfire",
      "repo_url": "https://github.com/pydantic/logfire-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:38:49.375286+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 42,
        "forks": 1,
        "watchers": 42,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables LLMs to retrieve application telemetry data (OpenTelemetry traces and metrics) from Logfire, analyze distributed traces, and execute arbitrary SQL queries using Logfire APIs.",
        "tools_exposed": [
          "find_exceptions",
          "find_exceptions_in_file",
          "arbitrary_query",
          "get_logfire_records_schema"
        ],
        "packages": {
          "dependencies": [
            "logfire>=3.7.1",
            "mcp[cli]>=1.4.1"
          ],
          "devDependencies": [
            "ruff"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Langfuse Prompt Management",
      "repo_url": "https://github.com/langfuse/mcp-server-langfuse",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:39:05.305695+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 44,
        "forks": 9,
        "watchers": 44,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a Model Context Protocol (MCP) Server for Langfuse Prompt Management, allowing users to access and manage Langfuse prompts through the MCP.",
        "tools_exposed": [
          "get-prompts",
          "get-prompt"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.5.0",
            "langfuse": "^3.35.2",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.4",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Lingo.dev",
      "repo_url": "https://github.com/lingodotdev/lingo.dev/blob/main/mcp.md",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:39:23.851112+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1441,
        "forks": 71,
        "watchers": 1441,
        "language_stack": [
          "Node.js",
          "JavaScript"
        ],
        "package_manager": [
          "pnpm",
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An AI localization toolkit for automating software translation in web & mobile development, integrated with CI/CD pipelines using LLM models.",
        "tools_exposed": [
          "init",
          "i18n"
        ],
        "packages": {
          "dependencies": {
            "@changesets/changelog-github": "^0.5.0",
            "@changesets/cli": "^2.27.10"
          },
          "devDependencies": {
            "@commitlint/cli": "^19.6.1",
            "@commitlint/config-conventional": "^19.6.0",
            "commitlint": "^19.7.1",
            "husky": "^9.1.7",
            "turbo": "^2.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Lingo.dev",
      "repo_url": "https://lingo.dev",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:39:23.851405+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://lingo.dev"
      }
    },
    {
      "name": "Mailgun",
      "repo_url": "https://github.com/mailgun/mailgun-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:39:40.222804+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 3,
        "watchers": 9,
        "language_stack": [
          "Node.js",
          "JavaScript"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server implementation for Mailgun, enabling MCP-compatible AI clients like Claude Desktop to interact with the Mailgun service.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "js-yaml": "^4.1.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@jest/globals": "^29.0.0",
            "jest": "^29.0.0"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Make",
      "repo_url": "https://github.com/integromat/make-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:40:03.062875+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 58,
        "forks": 10,
        "watchers": 58,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server enables Make scenarios (configured with 'On-Demand' scheduling) to be utilized as tools by AI assistants, allowing AI systems to trigger and interact with Make automation workflows.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1"
          },
          "devDependencies": {
            "@jest/globals": "^29.7.0",
            "@types/node": "^22.13.10",
            "jest": "^29.7.0",
            "jest-fetch-mock": "^3.0.3",
            "ts-jest": "^29.2.6",
            "ts-node": "^10.9.2",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "FROM node:22-alpine AS builder\n\nCOPY . /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "Make",
      "repo_url": "https://www.make.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:40:03.063152+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.make.com/"
      }
    },
    {
      "name": "Meilisearch",
      "repo_url": "https://github.com/meilisearch/meilisearch-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:40:23.732870+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 70,
        "forks": 7,
        "watchers": 70,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server designed for interacting with Meilisearch through Large Language Model (LLM) interfaces such as Claude.",
        "tools_exposed": [
          "get-connection-settings",
          "update-connection-settings",
          "create-index",
          "list-indexes",
          "get-index-metrics",
          "get-documents",
          "add-documents",
          "search",
          "get-settings",
          "update-settings",
          "get-keys",
          "create-key",
          "delete-key",
          "get-task",
          "get-tasks",
          "cancel-tasks",
          "delete-tasks",
          "health-check",
          "get-health-status",
          "get-version",
          "get-stats",
          "get-system-info"
        ],
        "packages": {
          "dependencies": [
            "meilisearch>=0.33.0",
            "mcp>=0.1.0",
            "httpx>=0.24.0",
            "pydantic>=2.0.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Metoro",
      "repo_url": "https://github.com/metoro-io/metoro-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:40:52.097080+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 33,
        "forks": 7,
        "watchers": 33,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "Go Modules"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP Server allows interaction with a Kubernetes cluster via the Claude Desktop App by exposing Metoro observability platform APIs to an LLM.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "github.com/google/uuid": "v1.6.0",
            "github.com/metoro-io/mcp-golang": "v0.7.0",
            "github.com/gin-gonic/gin": "v1.10.0"
          },
          "devDependencies": {
            "github.com/bytedance/sonic": "v1.11.6",
            "github.com/bytedance/sonic/loader": "v0.1.1",
            "github.com/cloudwego/base64x": "v0.1.4",
            "github.com/cloudwego/iasm": "v0.2.0",
            "github.com/gabriel-vasile/mimetype": "v1.4.3",
            "github.com/gin-contrib/sse": "v0.1.0",
            "github.com/go-playground/locales": "v0.14.1",
            "github.com/go-playground/universal-translator": "v0.18.1",
            "github.com/go-playground/validator/v10": "v10.20.0",
            "github.com/goccy/go-json": "v0.10.2",
            "github.com/json-iterator/go": "v1.1.12",
            "github.com/klauspost/cpuid/v2": "v2.2.7",
            "github.com/leodido/go-urn": "v1.4.0",
            "github.com/mattn/go-isatty": "v0.0.20",
            "github.com/modern-go/concurrent": "v0.0.0-20180306012644-bacd9c7ef1dd",
            "github.com/modern-go/reflect2": "v1.0.2",
            "github.com/pelletier/go-toml/v2": "v2.2.2",
            "github.com/twitchyliquid64/golang-asm": "v0.15.1",
            "github.com/ugorji/go/codec": "v1.2.12",
            "golang.org/x/arch": "v0.8.0",
            "golang.org/x/crypto": "v0.23.0",
            "golang.org/x/net": "v0.25.0",
            "golang.org/x/sys": "v0.20.0",
            "golang.org/x/text": "v0.15.0",
            "google.golang.org/protobuf": "v1.34.1",
            "github.com/bahlo/generic-list-go": "v0.2.0",
            "github.com/buger/jsonparser": "v1.1.1",
            "github.com/invopop/jsonschema": "v0.12.0",
            "github.com/mailru/easyjson": "v0.7.7",
            "github.com/pkg/errors": "v0.9.1",
            "github.com/tidwall/gjson": "v1.18.0",
            "github.com/tidwall/match": "v1.1.1",
            "github.com/tidwall/pretty": "v1.2.1",
            "github.com/tidwall/sjson": "v1.2.5",
            "github.com/wk8/go-ordered-map/v2": "v2.1.8",
            "gopkg.in/yaml.v3": "v3.0.1"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Milvus",
      "repo_url": "https://github.com/zilliztech/mcp-server-milvus",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:41:10.537195+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 63,
        "forks": 11,
        "watchers": 63,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides access to Milvus vector database functionality, enabling LLM applications to interact with a Milvus instance.",
        "tools_exposed": [
          "milvus_text_search",
          "milvus_vector_search",
          "milvus_query",
          "milvus_list_collections",
          "milvus_create_collection",
          "milvus_load_collection",
          "milvus_release_collection",
          "milvus_insert_data",
          "milvus_delete_entities"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.1.2",
            "pymilvus>=2.5.1",
            "click>=8.0.0",
            "ruff>=0.11.0",
            "dotenv>=0.9.9"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "MotherDuck",
      "repo_url": "https://github.com/motherduckdb/mcp-server-motherduck",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:41:26.379734+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 70,
        "forks": 9,
        "watchers": 70,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that integrates MotherDuck and local DuckDB, providing SQL analytics capabilities to Claude.",
        "tools_exposed": [
          "query"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.3.0",
            "duckdb>=1.2.1",
            "pandas>=2.0.0",
            "tabulate>=0.9.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Needle",
      "repo_url": "https://github.com/needle-ai/needle-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:41:45.268188+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 31,
        "forks": 16,
        "watchers": 31,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server manages documents (adding, organizing) and performs searches within them using Needle, integrated with Claude's Desktop Application.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "needle-python>=0.4.0",
            "mcp>=1.1.0",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Neo4j",
      "repo_url": "https://github.com/neo4j-contrib/mcp-neo4j/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:41:57.552092+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 180,
        "forks": 40,
        "watchers": 180,
        "language_stack": [
          "JavaScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This repository provides multiple MCP servers enabling natural language interaction with Neo4j databases (schema, queries, memory) and the Neo4j Aura cloud platform (instance management) through various MCP clients.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Neon",
      "repo_url": "https://github.com/neondatabase/mcp-server-neon",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:41:57.862869+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/neondatabase/mcp-server-neon'\nRedirect location: 'https://api.github.com/repositories/896203400'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "OceanBase",
      "repo_url": "https://github.com/oceanbase/mcp-oceanbase",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:42:14.973552+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 5,
        "watchers": 4,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This is a Model Context Protocol (MCP) server designed for OceanBase databases and their tools, enabling secure interaction.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.0.0",
            "mysql-connector-python>=9.1.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Octagon",
      "repo_url": "https://github.com/OctagonAI/octagon-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:42:28.947693+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6,
        "forks": 2,
        "watchers": 6,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation that integrates with the Octagon Market Intelligence API, providing specialized AI agents for market intelligence.",
        "tools_exposed": [
          "octagon-sec-agent",
          "octagon-transcripts-agent",
          "octagon-financials-agent",
          "octagon-stock-data-agent",
          "octagon-companies-agent",
          "octagon-funding-agent",
          "octagon-deals-agent",
          "octagon-investors-agent",
          "octagon-debts-agent",
          "octagon-scraper-agent",
          "octagon-deep-research-agent"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.0",
            "dotenv": "^16.3.1",
            "openai": "^4.20.1",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.10.0",
            "ts-node": "^10.9.2",
            "typescript": "^5.3.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Oxylabs",
      "repo_url": "https://github.com/oxylabs/oxylabs-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:42:51.026702+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 11,
        "forks": 3,
        "watchers": 11,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server that enables AI assistants like Claude to seamlessly access web data through Oxylabs' web scraping technology, supporting features like rendering, parsing, and bypassing geo-restrictions.",
        "tools_exposed": [
          "oxylabs_scraper",
          "oxylabs_web_unblocker"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "lxml>=5.3.0",
            "lxml-html-clean>=0.4.1",
            "markdownify>=0.14.1",
            "mcp[cli]>=1.6.0",
            "pydantic>=2.10.5"
          ],
          "devDependencies": [
            "mypy>=1.14.1",
            "pytest>=8.3.4",
            "pytest-asyncio>=0.25.2",
            "pytest-mock>=3.14.0",
            "ruff>=0.9.1"
          ]
        },
        "dockerfile_content": "FROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim\n\nENV UV_COMPILE_BYTECODE=1\nENV UV_LINK_MODE=copy\nENV UV_CACHE_DIR=/opt/uv-cache/\n\nRUN apt-get update && apt-get install -y --no-install-recommends git\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=UV_CACHE_DIR \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\nADD . /app\n\nRUN --mount=type=cache,target=UV_CACHE_DIR \\\n    uv sync --frozen --no-dev --no-editable\n\n# Add virtual environment to PATH\nENV PATH=\"/app/.venv/bin:$PATH\"\n\nENTRYPOINT [\"oxylabs-mcp\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "PayPal",
      "repo_url": "https://mcp.paypal.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:42:51.027127+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://mcp.paypal.com"
      }
    },
    {
      "name": "Perplexity",
      "repo_url": "https://github.com/ppl-ai/modelcontextprotocol",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:42:59.890882+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 843,
        "forks": 91,
        "watchers": 843,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that integrates the Sonar API to provide Claude with real-time, web-wide research capabilities.",
        "tools_exposed": [
          "perplexity_ask"
        ],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Qdrant",
      "repo_url": "https://github.com/qdrant/mcp-server-qdrant/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:43:18.187639+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 402,
        "forks": 46,
        "watchers": 402,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An official Model Context Protocol server for storing and retrieving information (memories) in the Qdrant vector search engine, acting as a semantic memory layer.",
        "tools_exposed": [
          "qdrant-store",
          "qdrant-find"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0",
            "fastembed>=0.6.0",
            "qdrant-client>=1.12.0",
            "pydantic>=2.10.6"
          ],
          "devDependencies": [
            "isort>=6.0.1",
            "pre-commit>=4.1.0",
            "pyright>=1.1.389",
            "pytest>=8.3.3",
            "pytest-asyncio>=0.23.0",
            "ruff>=0.8.0"
          ]
        },
        "dockerfile_content": "FROM python:3.11-slim\n\nWORKDIR /app\n\n# Install uv for package management\nRUN pip install --no-cache-dir uv\n\n# Install the mcp-server-qdrant package\nRUN uv pip install --system --no-cache-dir mcp-server-qdrant\n\n# Expose the default port for SSE transport\nEXPOSE 8000\n\n# Set environment variables with defaults that can be overridden at runtime\nENV QDRANT_URL=\"\"\nENV QDRANT_API_KEY=\"\"\nENV COLLECTION_NAME=\"default-collection\"\nENV EMBEDDING_MODEL=\"sentence-transformers/all-MiniLM-L6-v2\"\n\n# Run the server with SSE transport\nCMD uvx mcp-server-qdrant --transport sse\n",
        "base_docker_image": "python:3.11-slim"
      }
    },
    {
      "name": "Ramp",
      "repo_url": "https://github.com/ramp-public/ramp-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:43:36.086421+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 0,
        "watchers": 10,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for retrieving, analyzing, and processing Ramp data via its Developer API, using an in-memory ETL pipeline and database to overcome API limitations.",
        "tools_exposed": [
          "process_data",
          "execute_query",
          "clear_table",
          "get_ramp_categories",
          "get_currencies",
          "load_transactions",
          "load_reimbursements",
          "load_bills",
          "load_locations",
          "load_departments",
          "load_bank_accounts",
          "load_vendors",
          "load_vendor_bank_accounts",
          "load_entities",
          "load_spend_limits",
          "load_spend_programs",
          "load_users"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.3.0",
            "uuid>=1.30.0",
            "iso4217>=1.12.20240625",
            "flatten-json>=0.1.14"
          ],
          "devDependencies": [
            "ruff>=0.8.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.10"
      }
    },
    {
      "name": "Ramp",
      "repo_url": "https://ramp.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:43:36.086839+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://ramp.com"
      }
    },
    {
      "name": "Raygun",
      "repo_url": "https://github.com/MindscapeHQ/mcp-server-raygun",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:43:59.453477+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 5,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP Server providing access to Raygun's API V3 endpoints for interacting with Crash Reporting and Real User Monitoring applications via the Model Context Protocol.",
        "tools_exposed": [
          "list_applications",
          "get_application",
          "get_application_by_api_key",
          "regenerate_application_api_key",
          "list_error_groups",
          "get_error_group",
          "resolve_error_group",
          "activate_error_group",
          "ignore_error_group",
          "permanently_ignore_error_group",
          "list_deployments",
          "get_deployment",
          "delete_deployment",
          "update_deployment",
          "reprocess_deployment_commits",
          "list_customers",
          "list_sessions",
          "get_session",
          "list_pages",
          "get_page_metrics_time_series",
          "get_page_metrics_histogram",
          "get_error_metrics_time_series",
          "list_source_maps",
          "get_source_map",
          "update_source_map",
          "delete_source_map",
          "upload_source_map",
          "delete_all_source_maps",
          "list_invitations",
          "send_invitation",
          "get_invitation",
          "revoke_invitation"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "zod-to-json-schema": "^3.23.5"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "shx": "^0.3.4",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Rember",
      "repo_url": "https://github.com/rember/rember-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:44:20.389097+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 24,
        "forks": 2,
        "watchers": 24,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server allows Claude to create flashcards in Rember, a spaced repetition study tool. It can generate flashcards based on chat conversations or provided documents like PDFs.",
        "tools_exposed": [
          "create_flashcards"
        ],
        "packages": {
          "dependencies": {
            "@effect/ai": "^0.12.1",
            "@effect/cli": "^0.58.1",
            "@effect/platform-node": "^0.75.1",
            "@effect/platform": "^0.79.1",
            "@modelcontextprotocol/sdk": "^1.7.0",
            "effect": "^3.13.10",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@effect/ai-anthropic": "^0.2.1",
            "@effect/eslint-plugin": "^0.2.0",
            "@effect/language-service": "^0.4.0",
            "@effect/vitest": "^0.19.8",
            "@eslint/compat": "1.1.1",
            "@eslint/eslintrc": "3.1.0",
            "@eslint/js": "9.10.0",
            "@modelcontextprotocol/inspector": "^0.6.0",
            "@types/node": "^22.13.10",
            "@typescript-eslint/eslint-plugin": "^8.26.1",
            "@typescript-eslint/parser": "^8.26.1",
            "eslint-import-resolver-typescript": "^3.8.6",
            "eslint-plugin-codegen": "0.28.0",
            "eslint-plugin-deprecation": "^3.0.0",
            "eslint-plugin-import": "^2.31.0",
            "eslint-plugin-simple-import-sort": "^12.1.1",
            "eslint-plugin-sort-destructure-keys": "^2.0.0",
            "eslint": "^9.22.0",
            "tailwindcss": "^4.0.13",
            "tsup": "^8.4.0",
            "tsx": "^4.19.3",
            "typescript": "^5.8.2",
            "vitest": "^3.0.8"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Rember",
      "repo_url": "https://rember.com",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:44:20.389345+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://rember.com"
      }
    },
    {
      "name": "Riza",
      "repo_url": "https://github.com/riza-io/riza-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:44:29.545117+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 2,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server wraps the Riza API, exposing Riza's isolated code interpreter functions as tools. It allows LLMs to securely create, manage, and execute code tools and arbitrary code snippets.",
        "tools_exposed": [
          "create_tool",
          "fetch_tool",
          "execute_tool",
          "edit_tool",
          "list_tools",
          "execute_code"
        ],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Riza",
      "repo_url": "https://riza.io",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:44:29.545331+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://riza.io"
      }
    },
    {
      "name": "Search1API",
      "repo_url": "https://github.com/fatwang2/search1api-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:44:43.361050+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 111,
        "forks": 23,
        "watchers": 111,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that provides search and crawl functionality using Search1API.",
        "tools_exposed": [
          "search",
          "news"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "axios": "1.8.4",
            "dotenv": "^16.4.5"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": "node:18"
      }
    },
    {
      "name": "ScreenshotOne",
      "repo_url": "https://github.com/screenshotone/mcp/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:44:56.843446+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 11,
        "forks": 3,
        "watchers": 11,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An official MCP server implementation for ScreenshotOne.",
        "tools_exposed": [
          "render-website-screenshot"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.5.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.4",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ScreenshotOne",
      "repo_url": "https://screenshotone.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:44:56.843734+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://screenshotone.com/"
      }
    },
    {
      "name": "Semgrep",
      "repo_url": "https://github.com/semgrep/mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:45:16.302513+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 68,
        "forks": 10,
        "watchers": 68,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server for using Semgrep to scan code for security vulnerabilities.",
        "tools_exposed": [
          "security_check",
          "semgrep_scan",
          "semgrep_scan_with_custom_rule",
          "get_abstract_syntax_tree",
          "supported_languages",
          "semgrep_rule_schema"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.6.0",
            "semgrep>=1.117.0"
          ],
          "devDependencies": [
            "mcp[cli]>=1.6.0",
            "ruff>=0.11.4",
            "mypy>=1.15.0",
            "pytest>=8.1.1",
            "tomli>=2.0.1",
            "tomli-w>=1.0.0"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.13-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install .\n\nFROM python:3.13-slim-bookworm\n\nWORKDIR /app\n\n# Create non-root user\nRUN useradd -m app\n\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\" \\\n    PYTHONUNBUFFERED=1\n\n# Switch to non-root user\nUSER app\n\nEXPOSE 8000\n\nENTRYPOINT [\"semgrep-mcp\"]\nCMD [\"-t\", \"sse\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.13-bookworm-slim"
      }
    },
    {
      "name": "Semgrep",
      "repo_url": "https://semgrep.dev/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:45:16.302890+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://semgrep.dev/"
      }
    },
    {
      "name": "SingleStore",
      "repo_url": "https://github.com/singlestore-labs/mcp-server-singlestore",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:45:36.124313+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 0,
        "watchers": 8,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables interaction with SingleStore databases and management APIs using natural language through MCP clients like Claude Desktop, leveraging the Model Context Protocol.",
        "tools_exposed": [
          "workspace_groups_info",
          "workspaces_info",
          "organization_info",
          "list_of_regions",
          "execute_sql",
          "list_virtual_workspaces",
          "create_virtual_workspace",
          "execute_sql_on_virtual_workspace",
          "list_notebook_samples",
          "create_notebook",
          "list_personal_files",
          "create_scheduled_job",
          "get_job_details",
          "list_job_executions"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.3.0",
            "singlestoredb>=1.12.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM python:3.11-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Install build dependencies\nRUN apk add --no-cache gcc musl-dev linux-headers\n\n# Copy requirements and project files\nCOPY pyproject.toml ./\nCOPY requirements.txt ./\nCOPY README.md ./\nCOPY src/ ./src/\nCOPY uv.lock ./\n\n# Install pipenv system dependencies\n# Install project dependencies using pip\nRUN pip install --upgrade pip \\\n    && pip install --ignore-installed -r requirements.txt || true\n\n# Install project using Hatchling build\nRUN pip install hatchling \\\n    && pip install .\n\n# Expose any port if needed (not strictly needed for stdio based server)\n\nCMD [\"python\", \"src/server/server.py\"]\n",
        "base_docker_image": "python:3.11-alpine"
      }
    },
    {
      "name": "StarRocks",
      "repo_url": "https://github.com/StarRocks/mcp-server-starrocks",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:45:52.382170+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 6,
        "watchers": 12,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Acts as a bridge between AI assistants and StarRocks databases, allowing for direct SQL execution and database exploration without complex setup or configuration.",
        "tools_exposed": [
          "read_query",
          "write_query"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "mysql-connector-python>=9.2.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "StarRocks",
      "repo_url": "https://www.starrocks.io/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:45:52.382426+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.starrocks.io/"
      }
    },
    {
      "name": "Stripe",
      "repo_url": "https://github.com/stripe/agent-toolkit",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:46:07.241474+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 619,
        "forks": 78,
        "watchers": 619,
        "language_stack": [
          "Python",
          "TypeScript"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables agent frameworks supporting the Model Context Protocol to integrate with a subset of Stripe APIs via function calling.",
        "tools_exposed": [
          "customers.create",
          "customers.list",
          "products.create",
          "products.list",
          "prices.create",
          "prices.list",
          "payment_links.create",
          "invoices.create",
          "invoiceitems.create",
          "invoices.finalize",
          "balance.retrieve",
          "subscriptions.list",
          "subscriptions.update",
          "subscriptions.cancel",
          "refunds.create"
        ],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Tavily",
      "repo_url": "https://github.com/tavily-ai/tavily-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:46:27.697773+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 232,
        "forks": 28,
        "watchers": 232,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates Tavily's advanced search (tavily-search) and data extraction (tavily-extract) capabilities with AI assistants via the Model Context Protocol (MCP), enabling real-time web access and information retrieval.",
        "tools_exposed": [
          "tavily-search",
          "tavily-extract"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "dotenv": "^16.4.5",
            "axios": "^1.6.7"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY . /app\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\nENV TAVILY_API_KEY=your-api-key-here\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Tavily",
      "repo_url": "https://tavily.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:46:27.698108+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://tavily.com/"
      }
    },
    {
      "name": "Thirdweb",
      "repo_url": "https://github.com/thirdweb-dev/ai/tree/main/python/thirdweb-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:46:48.187863+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 2,
        "watchers": 9,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation for integrating thirdweb services (Nebula, Insight, Engine, Storage) with any MCP-compatible client.",
        "tools_exposed": [
          "Nebula",
          "Insight",
          "Engine",
          "Storage"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.3.0,<2",
            "click>=8.1.8,<9",
            "thirdweb-ai[mcp]==0.1.9"
          ],
          "devDependencies": [
            "ruff>=0.9.10,<0.10",
            "pyright>=1.1.396,<2"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Thirdweb",
      "repo_url": "https://thirdweb.com/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:46:48.188134+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://thirdweb.com/"
      }
    },
    {
      "name": "Tinybird",
      "repo_url": "https://github.com/tinybirdco/mcp-tinybird",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:47:05.673946+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 56,
        "forks": 9,
        "watchers": 56,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "An MCP server that allows interaction with a Tinybird Workspace from any MCP client. It supports querying Data Sources, getting results from API Endpoints, and pushing data files.",
        "tools_exposed": [
          "list-data-sources",
          "list-pipes",
          "get-data-source",
          "get-pipe",
          "request-pipe-data",
          "run-select-query",
          "append-insight",
          "llms-tinybird-docs",
          "save-event",
          "analyze-pipe",
          "push-datafile"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.27.2",
            "mcp>=1.0.0",
            "python-dotenv>=1.0.1",
            "tinybird-python-sdk>=0.1.6",
            "uvicorn>=0.27.0",
            "starlette>=0.36.0"
          ],
          "devDependencies": [
            "black>=23.12.1",
            "pyproject-toml>=0.0.10"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "UnifAI",
      "repo_url": "https://github.com/unifai-network/unifai-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:47:12.707775+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1,
        "forks": 1,
        "watchers": 1,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This README indicates that UnifAI MCP servers are now integrated into the UnifAI TypeScript and Python SDKs, redirecting users to those repositories for details.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "UnifAI Network",
      "repo_url": "https://unifai.network",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:47:12.708046+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://unifai.network"
      }
    },
    {
      "name": "Unstructured",
      "repo_url": "https://github.com/Unstructured-IO/UNS-MCP",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:47:32.825567+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 18,
        "forks": 4,
        "watchers": 18,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server implementation for interacting with the Unstructured API, providing tools to manage sources, destinations, workflows, and jobs.",
        "tools_exposed": [
          "list_sources",
          "get_source_info",
          "create_[connector]_source",
          "update_[connector]_source",
          "delete_[connector]_source",
          "list_destinations",
          "get_destination_info",
          "create_[connector]_destination",
          "update_[connector]_destination",
          "delete_[connector]_destination",
          "list_workflows",
          "get_workflow_info",
          "create_workflow",
          "run_workflow",
          "update_workflow",
          "delete_workflow",
          "list_jobs",
          "get_job_info",
          "cancel_job",
          "invoke_firecrawl_crawlhtml",
          "check_crawlhtml_status",
          "invoke_firecrawl_llmtxt",
          "check_llmtxt_status",
          "cancel_crawlhtml_job",
          "cancel_llmtxt_job"
        ],
        "packages": {
          "dependencies": [
            "anthropic>=0.49.0",
            "boto3>=1.37.14",
            "firecrawl-py>=1.14.1",
            "mcp[cli]>=1.3.0",
            "python-dotenv>=1.0.1",
            "unstructured-client>=0.32.0",
            "pip"
          ],
          "devDependencies": [
            "pre-commit",
            "pytest>=8.3.5",
            "pytest-asyncio>=0.25.3",
            "notebook>=7.3.3",
            "ipykernel>=6.29.5",
            "jupyter>=1.1.1"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Unstructured Platform",
      "repo_url": "https://unstructured.io",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:47:32.825853+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://unstructured.io"
      }
    },
    {
      "name": "Vectorize",
      "repo_url": "https://github.com/vectorize-io/vectorize-mcp-server/",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:47:49.404919+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 33,
        "forks": 4,
        "watchers": 33,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation that integrates with Vectorize for advanced Vector retrieval and text extraction.",
        "tools_exposed": [
          "retrieve",
          "extract",
          "deep-research"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.4.1",
            "@vectorize-io/vectorize-client": "^0.1.3",
            "dotenv": "^16.4.7",
            "p-queue": "^8.0.1",
            "shx": "^0.3.4"
          },
          "devDependencies": {
            "@types/jest": "^29.5.14",
            "@types/node": "^20.10.5",
            "@typescript-eslint/eslint-plugin": "^7.0.0",
            "@typescript-eslint/parser": "^7.0.0",
            "eslint": "^8.56.0",
            "eslint-config-prettier": "^9.1.0",
            "prettier": "^3.1.1",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Vectorize",
      "repo_url": "https://vectorize.io",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:47:49.405215+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://vectorize.io"
      }
    },
    {
      "name": "Verodat",
      "repo_url": "https://github.com/Verodat/verodat-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:48:07.136720+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1,
        "forks": 1,
        "watchers": 1,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server implementation for Verodat, enabling seamless integration of Verodat's data management capabilities with AI systems like Claude Desktop.",
        "tools_exposed": [
          "get-accounts",
          "get-workspaces",
          "get-queries",
          "create-dataset",
          "get-datasets",
          "get-dataset-output",
          "get-dataset-targetfields",
          "upload-dataset-rows",
          "get-ai-context",
          "execute-ai-query"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.3"
          },
          "devDependencies": {
            "@types/chai": "^5.0.1",
            "@types/mocha": "^10.0.10",
            "@types/node": "^22.10.5",
            "@types/sinon": "^17.0.3",
            "chai": "^5.1.2",
            "mocha": "^11.0.1",
            "sinon": "^19.0.2",
            "ts-node": "^10.9.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image for building the project\nFROM node:18-alpine AS builder\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the package.json and package-lock.json to the working directory\nCOPY package.json package-lock.json ./\n\n# Install the dependencies\nRUN npm install\n\n# Copy the rest of the source files to the container\nCOPY . .\n\n# Build the TypeScript project\nRUN npm run build\n\n# Use a minimal Node.js runtime image for running the application\nFROM node:18-alpine\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy only the build output and node_modules from the builder stage\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY package.json ./\n\n# Set environment variables\nENV VERODAT_AI_API_KEY=your-verodat-ai-api-key\n\n# Expose any ports if necessary (this depends on how the MCP server operates, e.g., if it needs to listen on a network port)\n# EXPOSE 3000\n\n# Define the command to run the application\nCMD [\"node\", \"build/src/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "VeyraX",
      "repo_url": "https://github.com/VeyraX/veyrax-mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:48:27.434707+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 20,
        "forks": 6,
        "watchers": 20,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "VeyraX MCP acts as a single connection point using the Model Context Protocol, allowing users to access their VeyraX-integrated tools across multiple MCP-compatible clients (like Claude, Cursor, VS Code) with one authentication.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.5.0",
            "@types/axios": "^0.9.36",
            "axios": "^1.7.9",
            "dotenv": "^16.4.7",
            "typescript": "^5.7.3",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.4"
          }
        },
        "dockerfile_content": "FROM node:22.14.0-alpine\n\nWORKDIR /app\n\nCOPY package.json package-lock.json ./\n\nRUN npm install\n\nCOPY . .\n\nRUN npm run build\n\nCMD [\"node\", \"dist/index.js\"] ",
        "base_docker_image": "node:22.14.0-alpine"
      }
    },
    {
      "name": "Xero",
      "repo_url": "https://github.com/XeroAPI/xero-mcp-server",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:48:45.807934+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32,
        "forks": 9,
        "watchers": 32,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "An MCP server implementation for Xero that provides a bridge between the MCP protocol and Xero's API, allowing for standardized access to Xero's accounting and business features.",
        "tools_exposed": [
          "list-contacts",
          "list-invoices",
          "list-accounts",
          "list-tax-rates",
          "list-quotes",
          "list-credit-notes",
          "list-trial-balance",
          "create-contact",
          "create-invoice",
          "create-quote",
          "create-credit-note",
          "update-contact",
          "update-invoice",
          "update-quote"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.0",
            "dotenv": "^16.4.7",
            "openid-client": "^6.3.4",
            "xero-node": "^10.0.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@eslint/js": "^9.22.0",
            "@types/node": "^22.13.10",
            "eslint": "^9.22.0",
            "eslint-config-prettier": "^10.1.1",
            "globals": "^16.0.0",
            "prettier": "3.5.3",
            "shx": "^0.3.4",
            "typescript": "^5.8.2",
            "typescript-eslint": "^8.26.1"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Zapier",
      "repo_url": "https://zapier.com/mcp",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:48:45.808225+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://zapier.com/mcp"
      }
    },
    {
      "name": "ZenML",
      "repo_url": "https://github.com/zenml-io/mcp-zenml",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:49:00.076964+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 16,
        "forks": 4,
        "watchers": 16,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "requirements.txt",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This project implements a Model Context Protocol (MCP) server for interacting with the ZenML API, providing MCP tools to access core read functionality and trigger new pipeline runs.",
        "tools_exposed": [
          "Users",
          "Stacks",
          "Pipelines",
          "Pipeline runs",
          "Pipeline steps",
          "Services",
          "Stack components",
          "Flavors",
          "Pipeline run templates",
          "Schedules",
          "Artifacts",
          "Service Connectors",
          "Step code",
          "Step logs",
          "Trigger pipeline runs"
        ],
        "packages": {
          "dependencies": [
            "httpx",
            "mcp[cli]",
            "zenml"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ZenML",
      "repo_url": "https://www.zenml.io",
      "type": "official",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:49:00.077188+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.zenml.io"
      }
    },
    {
      "name": "Ableton Live",
      "repo_url": "https://github.com/Simon-Kansara/ableton-live-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:49:16.068516+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 187,
        "forks": 30,
        "watchers": 187,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementing the Model Context Protocol (MCP) to facilitate communication between LLMs and Ableton Live using OSC (Open Sound Control).",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "fastmcp>=0.4.1",
            "python-osc>=1.9.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.10"
      }
    },
    {
      "name": "Airbnb",
      "repo_url": "https://github.com/openbnb-org/mcp-server-airbnb",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:49:31.776986+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 67,
        "forks": 22,
        "watchers": 67,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP Server is designed for searching Airbnb listings and retrieving detailed information about specific listings.",
        "tools_exposed": [
          "airbnb_search",
          "airbnb_listing_details"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.1",
            "cheerio": "^1.0.0",
            "node-fetch": "^3.3.2",
            "robots-parser": "^3.0.1"
          },
          "devDependencies": {
            "@types/node": "^22.13.9",
            "@types/node-fetch": "^2.6.12",
            "shx": "^0.3.4",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\nWORKDIR /app\n\n# Copy package files and install dependencies without running prepare scripts\nCOPY package*.json ./\nRUN npm install --ignore-scripts\n\n# Copy rest of the source code\nCOPY . .\n\n# Build the project explicitly\nRUN npm run build\n\n# Expose the MCP server on stdio\nCMD [ \"node\", \"dist/index.js\" ]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "AI Agent Marketplace Index",
      "repo_url": "https://github.com/AI-Agent-Hub/ai-agent-marketplace-index-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:49:49.836038+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1,
        "forks": 0,
        "watchers": 1,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows AI assistants to search the AI Agent Marketplace Index by keywords or category to find available AI agents, tools, or use cases.",
        "tools_exposed": [
          "search_ai_agent"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.6.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "AI Agent Marketplace Index",
      "repo_url": "http://www.deepnlp.org/store/ai-agent",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:49:49.836286+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: http://www.deepnlp.org/store/ai-agent"
      }
    },
    {
      "name": "Algorand",
      "repo_url": "https://github.com/GoPlausible/algorand-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:50:08.129634+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 23,
        "forks": 3,
        "watchers": 23,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server implementation enables applications to interact with the Algorand blockchain, providing tools and resources for blockchain operations, wallet management, and transaction handling.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "algosdk": "2.9.0",
            "qrcode": "^1.5.4"
          },
          "devDependencies": {
            "@types/node": "^20.0.0",
            "@types/qrcode": "^1.5.5",
            "typescript": "^5.0.0"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Airflow",
      "repo_url": "https://github.com/yangkyeongmo/mcp-server-apache-airflow",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:50:30.260535+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 16,
        "forks": 4,
        "watchers": 16,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for Apache Airflow, providing a standardized way for MCP clients to interact with Apache Airflow's REST API.",
        "tools_exposed": [
          "config",
          "connections",
          "dag",
          "dagrun",
          "dagstats",
          "dataset",
          "eventlog",
          "importerror",
          "monitoring",
          "plugin",
          "pool",
          "provider",
          "taskinstance",
          "variable",
          "xcom"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.24.1",
            "click>=8.1.7",
            "mcp>=0.1.0",
            "apache-airflow-client>=2.7.0"
          ],
          "devDependencies": [
            "build>=1.2.2.post1",
            "twine>=6.1.0",
            "ruff>=0.11.0"
          ]
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python base image\nFROM python:3.10-slim\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the contents of the repository to the working directory\nCOPY . .\n\n# Install the project dependencies\nRUN pip install uv\nRUN uv sync\n\n# Expose the port that the server will run on\nEXPOSE 8000\n\n# Command to run the server\nCMD [\"uv\", \"run\", \"src\", \"--transport\", \"sse\"]\n",
        "base_docker_image": "python:3.10-slim"
      }
    },
    {
      "name": "Apache Airflow",
      "repo_url": "https://airflow.apache.org/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:50:30.260907+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://airflow.apache.org/"
      }
    },
    {
      "name": "Airtable",
      "repo_url": "https://github.com/domdomegg/airtable-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:50:49.154771+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 97,
        "forks": 31,
        "watchers": 97,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server that provides read and write access to Airtable databases. This server enables LLMs to inspect database schemas, then read and write records.",
        "tools_exposed": [
          "list_records",
          "search_records",
          "list_bases",
          "list_tables",
          "describe_table",
          "get_record",
          "create_record",
          "update_records",
          "delete_records",
          "create_table",
          "update_table",
          "create_field",
          "update_field"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.3",
            "node-fetch": "^3.3.2",
            "zod": "^3.24.1",
            "zod-to-json-schema": "^3.24.1"
          },
          "devDependencies": {
            "@tsconfig/node-lts": "^20.1.3",
            "@types/node": "^22.10.2",
            "eslint": "^8.57.0",
            "eslint-config-domdomegg": "^1.2.3",
            "nodemon": "^3.1.7",
            "shx": "^0.3.4",
            "tsconfig-domdomegg": "^1.0.0",
            "typescript": "^5.7.2",
            "vitest": "^3.0.7"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image\nFROM node:18-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json to the working directory\nCOPY package.json package-lock.json ./\n\n# Install project dependencies\nRUN npm install\n\n# Copy the entire project directory\nCOPY . .\n\n# Build the project\nRUN npm run build\n\n# Start a new stage for the final image\nFROM node:18-alpine AS release\n\n# Set working directory\nWORKDIR /app\n\n# Copy the build files from the previous stage\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package-lock.json /app/node_modules /app/\n\n# Set the entry point to run the server\nENTRYPOINT [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "Airtable",
      "repo_url": "https://airtable.com/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:50:49.155125+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://airtable.com/"
      }
    },
    {
      "name": "Airtable",
      "repo_url": "https://github.com/felores/airtable-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:51:05.533423+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 27,
        "forks": 8,
        "watchers": 27,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing tools to interact with Airtable's API, enabling programmatic management of Airtable bases, tables, fields, and records through Claude Desktop or other MCP clients.",
        "tools_exposed": [
          "list_bases",
          "list_tables",
          "create_table",
          "update_table",
          "create_field",
          "update_field",
          "list_records",
          "create_record",
          "update_record",
          "delete_record",
          "search_records",
          "get_record"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "axios": "^1.7.9"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "AlphaVantage",
      "repo_url": "https://github.com/calvernaz/alphavantage",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:51:22.890927+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 25,
        "forks": 6,
        "watchers": 25,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides access to the Alphavantage API for stock market data.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "bump2version>=1.0.1",
            "load-dotenv>=0.1.0",
            "mcp>=1.0.0",
            "toml>=0.10.2"
          ],
          "devDependencies": [
            "ruff>=0.9.9"
          ]
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into /app\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n\nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Set the API key environment variable (This needs to be provided at runtime)\nENV ALPHAVANTAGE_API_KEY=your_api_key_here\n\n# When running the container, start the MCP server\nENTRYPOINT [\"alphavantage\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "AlphaVantage",
      "repo_url": "https://www.alphavantage.co",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:51:22.891203+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.alphavantage.co"
      }
    },
    {
      "name": "Anki",
      "repo_url": "https://github.com/scorzeth/anki-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:51:34.749102+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 66,
        "forks": 5,
        "watchers": 66,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that connects to a locally running Anki, providing card review and creation.",
        "tools_exposed": [
          "update_cards",
          "add_card",
          "get_due_cards",
          "get_new_cards"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.0.3",
            "yanki-connect": "^2.1.8"
          },
          "devDependencies": {
            "@types/node": "^20.17.10",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Anki",
      "repo_url": "https://apps.ankiweb.net",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:51:34.749345+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://apps.ankiweb.net"
      }
    },
    {
      "name": "Any Chat Completions",
      "repo_url": "https://github.com/pyroprompts/any-chat-completions-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:51:51.830239+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 95,
        "forks": 16,
        "watchers": 95,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates Claude with any OpenAI SDK-compatible Chat Completion API (like OpenAI, Perplexity, Groq, etc.), allowing Claude to relay questions to a configured AI chat provider.",
        "tools_exposed": [
          "chat"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "dotenv": "^16.4.5",
            "openai": "^4.73.1"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Apple Calendar",
      "repo_url": "https://github.com/Omar-v2/mcp-ical",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:52:08.565622+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 42,
        "forks": 18,
        "watchers": 42,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server enables natural language interaction with the macOS Calendar app, allowing users to manage events, check schedules, and find availability through conversation.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "loguru>=0.7.3",
            "mcp[cli]>=1.2.1",
            "pyobjc>=11.0"
          ],
          "devDependencies": [
            "pytest>=8.3.4",
            "pytest-mock>=3.14.0",
            "pytest-random-order>=1.1.1"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ArangoDB",
      "repo_url": "https://github.com/ravenwits/mcp-server-arangodb",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:52:25.255761+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 4,
        "watchers": 10,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A TypeScript-based Model Context Protocol server that provides database interaction capabilities through ArangoDB. It implements core database operations for seamless integration.",
        "tools_exposed": [
          "arango_query",
          "arango_insert",
          "arango_update",
          "arango_remove",
          "arango_backup",
          "arango_list_collections",
          "arango_create_collection"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "arangojs": "^9.2.0"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image\nFROM node:22.12-alpine AS builder\n\n# Create app directory\nWORKDIR /app\n\n# Install app dependencies\nCOPY package.json package-lock.json ./\nRUN npm install --ignore-scripts\n\n# Copy source code and build the project\nCOPY . .\nRUN npm run build\n\n# Use a smaller base image for the final build\nFROM node:22-alpine AS release\n\n# Create app directory\nWORKDIR /app\n\n# Copy the built files and node_modules from the builder stage\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\nCOPY --from=builder /app/node_modules /app/node_modules\n\n# Expose the default ArangoDB port\nEXPOSE 8529\n\n# Set environment variables (these should be overridden at runtime)\nENV ARANGO_URL=http://localhost:8529\nENV ARANGO_DATABASE=your_database_name\nENV ARANGO_USERNAME=your_username\nENV ARANGO_PASSWORD=your_password\n\n# Command to run the server\nCMD [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "ArangoDB",
      "repo_url": "https://arangodb.com/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:52:25.256008+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://arangodb.com/"
      }
    },
    {
      "name": "Arduino",
      "repo_url": "https://github.com/vishalmysore/choturobo",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:52:41.856878+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 18,
        "forks": 4,
        "watchers": 18,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server acts as a robotic server ('Chotu Robo'), integrating Arduino-based hardware (ESP32/Nano 368) with AI systems like Claude. It allows remote control of components such as LEDs, motors, servos, and sensors via AI commands.",
        "tools_exposed": [
          "blinkLED",
          "buzz",
          "runMotor",
          "moveServo",
          "controlFan",
          "toggleRelay",
          "readTemperature",
          "readDistance",
          "move-chotu",
          "start-chotu",
          "stop-chotu",
          "turn-chotu",
          "set-chotu-speed"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "@types/johnny-five": "^2.1.11",
            "axios": "^1.8.3",
            "johnny-five": "^2.1.0",
            "zod-to-json-schema": "^3.24.3"
          },
          "devDependencies": {
            "@types/node": "^20.17.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Atlassian",
      "repo_url": "https://github.com/sooperset/mcp-atlassian",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:53:04.870928+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 712,
        "forks": 118,
        "watchers": 712,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "Model Context Protocol (MCP) server for Atlassian products (Confluence and Jira), supporting both Cloud and Server/Data Center deployments.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "atlassian-python-api>=3.41.16",
            "beautifulsoup4>=4.12.3",
            "httpx>=0.28.0",
            "mcp>=1.3.0",
            "python-dotenv>=1.0.1",
            "markdownify>=0.11.6",
            "markdown>=3.7.0",
            "markdown-to-confluence>=0.3.0",
            "pydantic>=2.10.6",
            "trio>=0.29.0",
            "click>=8.1.7",
            "uvicorn>=0.27.1",
            "starlette>=0.37.1"
          ],
          "devDependencies": [
            "uv>=0.1.0",
            "pytest>=8.0.0",
            "pytest-cov>=4.1.0",
            "pre-commit>=3.6.0",
            "ruff>=0.3.0",
            "black>=24.2.0",
            "mypy>=1.8.0",
            "mcp[cli]>=1.3.0"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.10-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Generate proper TOML lockfile first\nRUN --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv lock\n\n# Install the project's dependencies using the lockfile\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.10-slim\n\nWORKDIR /app\n\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\nENTRYPOINT [\"mcp-atlassian\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.10-bookworm-slim"
      }
    },
    {
      "name": "AWS",
      "repo_url": "https://github.com/rishikavikondala/mcp-server-aws",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:53:27.579385+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 90,
        "forks": 13,
        "watchers": 90,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server implementation for AWS operations that currently supports S3 and DynamoDB services. Operations are logged and accessible via an audit endpoint.",
        "tools_exposed": [
          "s3_bucket_create",
          "s3_bucket_list",
          "s3_bucket_delete",
          "s3_object_upload",
          "s3_object_delete",
          "s3_object_list",
          "s3_object_read",
          "dynamodb_table_create",
          "dynamodb_table_describe",
          "dynamodb_table_delete",
          "dynamodb_table_update",
          "dynamodb_item_put",
          "dynamodb_item_get",
          "dynamodb_item_update",
          "dynamodb_item_delete",
          "dynamodb_item_query",
          "dynamodb_item_scan",
          "dynamodb_batch_get",
          "dynamodb_item_batch_write",
          "dynamodb_batch_execute",
          "dynamodb_describe_ttl",
          "dynamodb_update_ttl"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "python-dotenv>=1.0.1",
            "boto3>=1.35.53"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use an official Python image\nFROM python:3.13-slim\n\n# Set environment variables\nENV PYTHONDONTWRITEBYTECODE=1\nENV PYTHONUNBUFFERED=1\n\n# Create and set working directory\nWORKDIR /app\n\n# Install build system and dependencies\nRUN pip install --upgrade pip && \\\n    pip install hatchling\n\n# Copy the project files into the container\nCOPY . /app\n\n# Install the project in editable mode (if necessary)\nRUN hatch build && pip install .\n\n# Set up environment variables for AWS credentials\nENV AWS_ACCESS_KEY_ID=your_access_key_id\nENV AWS_SECRET_ACCESS_KEY=your_secret_access_key\nENV AWS_REGION=us-east-1\n\n# Run the MCP server\nCMD [\"hatch\", \"run\", \"mcp-server-aws\"]\n",
        "base_docker_image": "python:3.13-slim"
      }
    },
    {
      "name": "AWS Athena",
      "repo_url": "https://github.com/lishenxydlgzs/aws-athena-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:53:44.402756+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 7,
        "forks": 5,
        "watchers": 7,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server for running AWS Athena queries. This server enables AI assistants to execute SQL queries against your AWS Athena databases and retrieve results.",
        "tools_exposed": [
          "run_query",
          "get_status",
          "get_result",
          "list_saved_queries",
          "run_saved_query"
        ],
        "packages": {
          "dependencies": {
            "@aws-sdk/client-athena": "^3.0.0",
            "@aws-sdk/credential-provider-node": "^3.0.0",
            "@modelcontextprotocol/sdk": "^1.6.0"
          },
          "devDependencies": {
            "@types/node": "^20.0.0",
            "typescript": "^5.0.0"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\nWORKDIR /app\n\n# Copy package files\nCOPY package.json package-lock.json ./\n\n# Install dependencies without running scripts\nRUN npm install --ignore-scripts\n\n# Copy the source code\nCOPY tsconfig.json ./\nCOPY src ./src\n\n# Build the project\nRUN npm run build\n\n# Expose port if needed (not really used for stdio, but optional)\nEXPOSE 8080\n\n# Run the MCP server\nCMD [ \"node\", \"build/index.js\" ]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "AWS Cost Explorer",
      "repo_url": "https://github.com/aarora79/aws-cost-explorer-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:54:04.323228+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 77,
        "forks": 19,
        "watchers": 77,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for retrieving AWS spend data via Cost Explorer and Amazon Bedrock usage data via CloudWatch Model Invocation Logs, enabling natural language queries about AWS costs.",
        "tools_exposed": [
          "get_bedrock_daily_usage_stats"
        ],
        "packages": {
          "dependencies": [
            "boto3>=1.37.9",
            "botocore>=1.37.9",
            "chainlit>=2.4.1",
            "jmespath>=1.0.1",
            "langchain>=0.3.20",
            "langchain-anthropic>=0.3.9",
            "langchain-aws>=0.2.15",
            "langchain-mcp-adapters>=0.0.4",
            "langgraph>=0.3.10",
            "mcp>=1.3.0",
            "pandas>=2.2.3",
            "pydantic>=2.10.6",
            "tabulate>=0.9.0",
            "typing-extensions>=4.12.2"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM python:3.12-slim\n\nWORKDIR /app\n\n# install astral uv for Python dependencies\nRUN pip install uv\n\n# Copy project files\nCOPY pyproject.toml .\nCOPY server.py .\n\n# Install dependencies using uv\nRUN uv pip install --no-cache --system -e .\n\n# Add AWS configuration directory\nRUN mkdir -p /root/.aws\n\n# Expose port for SSE transport\nEXPOSE 8000\n\n# Run the MCP server\nCMD [\"python\", \"server.py\"]",
        "base_docker_image": "python:3.12-slim"
      }
    },
    {
      "name": "demo video",
      "repo_url": "https://www.youtube.com/watch?v=WuVOmYLRFmI&feature=youtu.be",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:54:04.323446+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.youtube.com/watch?v=WuVOmYLRFmI&feature=youtu.be"
      }
    },
    {
      "name": "AWS Resources Operations",
      "repo_url": "https://github.com/baryhuang/mcp-server-aws-resources-python",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:54:20.260749+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 5,
        "watchers": 4,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that allows running generated Python code to query and potentially manage AWS resources using the boto3 library.",
        "tools_exposed": [
          "query_aws_resources"
        ],
        "packages": {
          "dependencies": [
            "boto3",
            "mcp",
            "pydantic",
            "pytz"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Use Python base image\nFROM python:3.10-slim-bookworm\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Copy the entire project\nCOPY . /app\n\n# Install dependencies first for better caching\nRUN pip install --no-cache-dir boto3 mcp pydantic\n\n# Install the package in development mode\nRUN pip install -e .\n\n# Run the server\nENTRYPOINT [\"python\", \"-m\", \"mcp_server_aws_resources.server\"] ",
        "base_docker_image": "python:3.10-slim-bookworm"
      }
    },
    {
      "name": "AWS S3",
      "repo_url": "https://github.com/aws-samples/sample-mcp-server-s3",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:54:38.082409+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 27,
        "forks": 6,
        "watchers": 27,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving data such as PDF's from S3. It exposes AWS S3 data through Resources, currently supporting PDF documents.",
        "tools_exposed": [
          "ListBuckets",
          "ListObjectsV2",
          "GetObject"
        ],
        "packages": {
          "dependencies": [
            "aioboto3>=13.2.0",
            "mcp>=1.0.0",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Azure ADX",
      "repo_url": "https://github.com/pab1it0/adx-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:54:57.864424+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 4,
        "watchers": 12,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This is a Model Context Protocol (MCP) server for Azure Data Explorer, providing access to clusters and databases through standardized MCP interfaces. It allows AI assistants to execute KQL queries and explore data.",
        "tools_exposed": [
          "execute_query",
          "list_tables",
          "get_table_schema",
          "sample_table_data"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]",
            "azure-kusto-data",
            "azure-identity",
            "python-dotenv",
            "pyproject-toml>=0.1.0"
          ],
          "devDependencies": [
            "pytest>=7.0.0",
            "pytest-cov>=4.0.0",
            "pytest-asyncio>=0.21.0",
            "pytest-mock>=3.10.0"
          ]
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Set environment variables for ADX MCP Server\nENV PYTHONUNBUFFERED=1\n\n# when running the container, add ADX_CLUSTER_URL and ADX_DATABASE environment variables\nENTRYPOINT [\"adx-mcp-server\"]\n\n# Label the image\nLABEL maintainer=\"pab1it0\" \\\n      description=\"Azure Data Explorer MCP Server\" \\\n      version=\"1.0.5\"\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Azure DevOps",
      "repo_url": "https://github.com/Vortiago/mcp-azure-devops",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:55:19.446893+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 15,
        "forks": 12,
        "watchers": 15,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server that enables AI assistants to interact with Azure DevOps services, bridging natural language requests to the Azure DevOps REST API.",
        "tools_exposed": [
          "Query Work Items",
          "Get Work Item Details",
          "Create Work Items",
          "Update Work Items",
          "Add Comments",
          "View Comments",
          "Parent-Child Relationships",
          "Get Projects",
          "Get Teams",
          "Team Members",
          "Team Area Paths",
          "Team Iterations"
        ],
        "packages": {
          "dependencies": [
            "azure-devops>=7.1.0b4",
            "mcp>=0.1.0"
          ],
          "devDependencies": [
            "mcp[cli]>=0.1.0",
            "pytest>=7.0.0",
            "pytest-asyncio>=0.21.0",
            "ruff>=0.0.267",
            "anyio>=3.6.2",
            "pyright>=1.1.350"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Baidu AI Search",
      "repo_url": "https://github.com/baidubce/app-builder/tree/master/python/mcp_server/ai_search",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:55:27.503674+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 506,
        "forks": 127,
        "watchers": 506,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Combines Baidu's search capabilities with large language model technology to provide intelligent responses using real-time web information references for various application scenarios.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Base Free USDC Transfer",
      "repo_url": "https://github.com/magnetai/mcp-free-usdc-transfer",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:55:44.512499+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 13,
        "forks": 3,
        "watchers": 13,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation enabling free USDC transfers on Base with Coinbase CDP MPC Wallet integration for secure, feeless transactions.",
        "tools_exposed": [
          "tranfer-usdc",
          "create_coinbase_mpc_wallet"
        ],
        "packages": {
          "dependencies": {
            "@coinbase/coinbase-sdk": "^0.13.0",
            "@ensdomains/ensjs": "^4.0.2",
            "@modelcontextprotocol/sdk": "^1.1.0",
            "@types/global-agent": "^2.1.3",
            "ethers": "^6.13.5",
            "global-agent": "^3.0.0",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/node": "^22.10.5",
            "ts-node": "^10.9.2",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Base",
      "repo_url": "https://base.org",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:55:44.512814+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://base.org"
      }
    },
    {
      "name": "Coinbase CDP",
      "repo_url": "https://docs.cdp.coinbase.com/mpc-wallet/docs/welcome",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:55:44.512991+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://docs.cdp.coinbase.com/mpc-wallet/docs/welcome"
      }
    },
    {
      "name": "Basic Memory",
      "repo_url": "https://github.com/basicmachines-co/basic-memory",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:56:07.989476+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 419,
        "forks": 33,
        "watchers": 419,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": true,
        "has_tests": true,
        "server_description": "This server enables LLMs, via the Model Context Protocol (MCP), to read from and write to a local knowledge base stored as Markdown files, facilitating persistent knowledge building through natural conversations.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "sqlalchemy>=2.0.0",
            "pyyaml>=6.0.1",
            "typer>=0.9.0",
            "aiosqlite>=0.20.0",
            "greenlet>=3.1.1",
            "pydantic[email,timezone]>=2.10.3",
            "icecream>=2.1.3",
            "mcp>=1.2.0",
            "pydantic-settings>=2.6.1",
            "loguru>=0.7.3",
            "pyright>=1.1.390",
            "markdown-it-py>=3.0.0",
            "python-frontmatter>=1.1.0",
            "rich>=13.9.4",
            "unidecode>=1.3.8",
            "dateparser>=1.2.0",
            "watchfiles>=1.0.4",
            "fastapi[standard]>=0.115.8",
            "alembic>=1.14.1",
            "qasync>=0.27.1",
            "pillow>=11.1.0"
          ],
          "devDependencies": [
            "gevent>=24.11.1",
            "icecream>=2.1.3",
            "pytest>=8.3.4",
            "pytest-cov>=4.1.0",
            "pytest-mock>=3.12.0",
            "pytest-asyncio>=0.24.0",
            "ruff>=0.1.6",
            "pytest>=8.3.4",
            "pytest-cov>=4.1.0",
            "pytest-mock>=3.12.0",
            "pytest-asyncio>=0.24.0",
            "ruff>=0.1.6",
            "cx-freeze>=7.2.10",
            "pyqt6>=6.8.1"
          ]
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM python:3.12-slim\n\nWORKDIR /app\n\n# Copy the project files\nCOPY . .\n\n# Install pip and build dependencies\nRUN pip install --upgrade pip \\\n&& pip install . --no-cache-dir --ignore-installed\n\n# Expose port if necessary (e.g., uv might use a port, but MCP over stdio so not needed here)\n\n# Use the basic-memory entrypoint to run the MCP server\nCMD [\"basic-memory\", \"mcp\"]",
        "base_docker_image": "python:3.12-slim"
      }
    },
    {
      "name": "BigQuery",
      "repo_url": "https://github.com/LucasHild/mcp-server-bigquery",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:56:23.972355+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 54,
        "forks": 9,
        "watchers": 54,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server that provides access to BigQuery. This server enables LLMs to inspect database schemas and execute queries.",
        "tools_exposed": [
          "execute-query",
          "list-tables",
          "describe-table"
        ],
        "packages": {
          "dependencies": [
            "google-cloud-bigquery>=3.27.0",
            "mcp>=1.0.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "BigQuery",
      "repo_url": "https://github.com/ergut/mcp-bigquery-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:56:41.569201+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 38,
        "forks": 10,
        "watchers": 38,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows Large Language Models (LLMs) like Claude to interact directly with Google BigQuery data by translating natural language questions into SQL queries against datasets and views.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@google-cloud/bigquery": "^7.3.0",
            "@modelcontextprotocol/sdk": "0.6.0"
          },
          "devDependencies": {
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Bing Web Search API",
      "repo_url": "https://github.com/leehanchung/bing-search-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:57:01.879057+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 19,
        "forks": 1,
        "watchers": 19,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for Microsoft Bing Search API integration, allowing AI assistants to perform web, news, and image searches.",
        "tools_exposed": [
          "bing_web_search",
          "bing_news_search",
          "bing_image_search"
        ],
        "packages": {
          "dependencies": [
            "python-dotenv>=1.0.1",
            "httpx>=0.28.1",
            "mcp[cli]>=1.4.1"
          ],
          "devDependencies": [
            "pyright>=1.1.398",
            "ruff>=0.11.0",
            "mypy>=1.9.0",
            "pytest>=8.0.0",
            "pytest-asyncio>=0.23.5",
            "pytest-cov>=4.1.0"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.10-bookworm-slim AS uv\n\n# Install the project into /app\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.10-slim-bookworm\n\nWORKDIR /app\n \n# COPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n\n# Default command to run the Bing Search MCP server\nENTRYPOINT [\"mcp-server-bing\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.10-bookworm-slim"
      }
    },
    {
      "name": "Bitable MCP",
      "repo_url": "https://github.com/lloydzhou/bitable-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:57:17.047942+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 1,
        "watchers": 2,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides access to Lark Bitable through the Model Context Protocol, allowing users to interact with Bitable tables using predefined tools.",
        "tools_exposed": [
          "list_table",
          "describe_table",
          "read_query"
        ],
        "packages": {
          "dependencies": [
            "pybitable",
            "mcp==1.3.0",
            "typer"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Blender",
      "repo_url": "https://github.com/ahujasid/blender-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:57:39.052661+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9583,
        "forks": 831,
        "watchers": 9583,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Connects Blender to Claude AI via the Model Context Protocol (MCP), allowing Claude to directly interact with and control Blender for prompt-assisted 3D modeling, scene creation, and manipulation.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "browser-use",
      "repo_url": "https://github.com/co-browser/browser-use-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:58:02.201074+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 181,
        "forks": 18,
        "watchers": 181,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for the browser-use project, enabling browser automation tasks via an LLM, using SSE for transport.",
        "tools_exposed": [
          "browser_use",
          "browser_get_result"
        ],
        "packages": {
          "dependencies": [
            "asyncio>=3.4.3",
            "browser-use>=0.1.40",
            "click>=8.1.8",
            "httpx>=0.28.1",
            "langchain-openai>=0.3.1",
            "mcp>=1.3.0",
            "pydantic>=2.10.6",
            "anyio",
            "python-dotenv",
            "starlette",
            "uvicorn",
            "playwright>=1.50.0"
          ],
          "devDependencies": [
            "pytest>=7.0.0",
            "pytest-asyncio>=0.21.0",
            "black>=23.0.0",
            "isort>=5.12.0",
            "mypy>=1.0.0",
            "pytest-cov>=4.1.0"
          ]
        },
        "dockerfile_content": "FROM ghcr.io/astral-sh/uv:bookworm-slim AS builder\n\nENV UV_COMPILE_BYTECODE=1 \\\n    UV_LINK_MODE=copy \\\n    UV_PYTHON_INSTALL_DIR=/python \\\n    UV_PYTHON_PREFERENCE=only-managed\n\n# Install build dependencies and clean up in the same layer\nRUN apt-get update -y && \\\n    apt-get install --no-install-recommends -y clang && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Install Python before the project for caching\nRUN uv python install 3.13\n\nWORKDIR /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev\n\nFROM debian:bookworm-slim AS runtime\n\n# VNC password will be read from Docker secrets or fallback to default\n# Create a fallback default password file\nRUN mkdir -p /run/secrets && \\\n    echo \"browser-use\" > /run/secrets/vnc_password_default\n\n# Install required packages including Chromium and clean up in the same layer\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y \\\n    xfce4 \\\n    xfce4-terminal \\\n    dbus-x11 \\\n    tigervnc-standalone-server \\\n    tigervnc-tools \\\n    nodejs \\\n    npm \\\n    fonts-freefont-ttf \\\n    fonts-ipafont-gothic \\\n    fonts-wqy-zenhei \\\n    fonts-thai-tlwg \\\n    fonts-kacst \\\n    fonts-symbola \\\n    fonts-noto-color-emoji && \\\n    npm i -g proxy-login-automator && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/* && \\\n    rm -rf /var/cache/apt/*\n\n# Copy only necessary files from builder\nCOPY --from=builder --chown=python:python /python /python\nCOPY --from=builder --chown=app:app /app /app\n\nENV PATH=\"/app/.venv/bin:$PATH\" \\\n    DISPLAY=:0 \\\n    CHROME_BIN=/usr/bin/chromium \\\n    CHROMIUM_FLAGS=\"--no-sandbox --headless --disable-gpu --disable-software-rasterizer --disable-dev-shm-usage\"\n\n# Combine VNC setup commands to reduce layers\nRUN mkdir -p ~/.vnc && \\\n    printf '#!/bin/sh\\nunset SESSION_MANAGER\\nunset DBUS_SESSION_BUS_ADDRESS\\nstartxfce4' > /root/.vnc/xstartup && \\\n    chmod +x /root/.vnc/xstartup && \\\n    printf '#!/bin/bash\\n\\n# Use Docker secret for VNC password if available, else fallback to default\\nif [ -f \"/run/secrets/vnc_password\" ]; then\\n  cat /run/secrets/vnc_password | vncpasswd -f > /root/.vnc/passwd\\nelse\\n  cat /run/secrets/vnc_password_default | vncpasswd -f > /root/.vnc/passwd\\nfi\\n\\nchmod 600 /root/.vnc/passwd\\nvncserver -depth 24 -geometry 1920x1080 -localhost no -PasswordFile /root/.vnc/passwd :0\\nproxy-login-automator\\npython /app/server --port 8000' > /app/boot.sh && \\\n    chmod +x /app/boot.sh\n\nRUN playwright install --with-deps --no-shell chromium\n\nEXPOSE 8000\n\nENTRYPOINT [\"/bin/bash\", \"/app/boot.sh\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:bookworm-slim"
      }
    },
    {
      "name": "Bsc-mcp",
      "repo_url": "https://github.com/TermiX-official/bsc-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:58:19.431469+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 65,
        "forks": 9,
        "watchers": 65,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP tool server designed for the Binance Smart Chain (BSC) to send BNB, transfer/deploy BEP-20 tokens, interact with smart contracts, and integrate with PancakeSwap. It's built for Claude Desktop, AI agents, and developers.",
        "tools_exposed": [
          "transferNativeToken",
          "transferBEP20Token",
          "pancakeSwap",
          "createFourMeme",
          "createBEP20Token",
          "getBalance",
          "callContractFunction",
          "getWalletInfo",
          "securityCheck",
          "pancakeAddLiquidity",
          "pancakeMyPosition",
          "pancakeRemovePosition",
          "sellMemeToken"
        ],
        "packages": {
          "dependencies": {
            "@goplus/sdk-node": "^1.0.12",
            "@modelcontextprotocol/sdk": "^1.4.0",
            "@pancakeswap/sdk": "^5.8.8",
            "@pancakeswap/smart-router": "6.1.6",
            "@pancakeswap/tokens": "^0.6.24",
            "chalk": "^5.4.1",
            "dotenv": "^16.4.7",
            "figlet": "^1.8.0",
            "fs-extra": "^11.3.0",
            "graphql-request": "^7.1.2",
            "moralis": "^2.27.2",
            "ora": "^8.2.0",
            "prompts": "^2.4.2",
            "viem": "^2.23.11"
          },
          "devDependencies": {
            "@types/figlet": "^1.7.0",
            "@types/fs-extra": "^11.0.4",
            "@types/node": "^22.10.0",
            "@types/prompts": "^2.4.9",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Calculator",
      "repo_url": "https://github.com/githejie/mcp-server-calculator",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:58:36.971446+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 18,
        "forks": 1,
        "watchers": 18,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol server for calculating, enabling LLMs to use a calculator for precise numerical calculations.",
        "tools_exposed": [
          "calculate"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.4.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\nWORKDIR /app\n\nENV UV_COMPILE_BYTECODE=1\n\nENV UV_LINK_MODE=copy\n\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\nENV PATH=\"/app/.venv/bin:$PATH\"\n\nENTRYPOINT [\"mcp-server-calculator\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "CFBD API",
      "repo_url": "https://github.com/lenwood/cfbd-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:58:57.096517+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 6,
        "watchers": 9,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing access to comprehensive college football statistics sourced from the College Football Data API, enabling queries on games, teams, players, plays, rankings, and metrics within AI assistants like Claude Desktop.",
        "tools_exposed": [
          "get-games",
          "get-records",
          "get-games-teams",
          "get-plays",
          "get-drives",
          "get-play-stats",
          "get-rankings",
          "get-pregame-win-probability",
          "get-advanced-box-score"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.1.2",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "College Football Data API",
      "repo_url": "https://collegefootballdata.com/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:58:57.096828+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://collegefootballdata.com/"
      }
    },
    {
      "name": "ChatMCP",
      "repo_url": "https://github.com/AI-QL/chat-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:59:16.655417+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 147,
        "forks": 21,
        "watchers": 147,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A cross-platform desktop application built with Electron using the MCP protocol to connect to and interact with various LLMs. It aims to provide a simple codebase for understanding MCP and testing servers/LLMs.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0"
          },
          "devDependencies": {
            "@types/node-notifier": "^8.0.5",
            "copyfiles": "^2.4.1",
            "electron": "^34.0.0",
            "electron-builder": "^25.1.8",
            "electron-debug": "^4.1.0",
            "node-notifier": "^10.0.1",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "AIQL",
      "repo_url": "https://github.com/AI-QL",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:59:16.655756+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://github.com/AI-QL"
      }
    },
    {
      "name": "ChatSum",
      "repo_url": "https://github.com/mcpso/mcp-server-chatsum",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:59:16.907535+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/mcpso/mcp-server-chatsum'\nRedirect location: 'https://api.github.com/repositories/898004429'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "mcpso",
      "repo_url": "https://mcp.so",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:59:16.907665+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://mcp.so"
      }
    },
    {
      "name": "Chroma",
      "repo_url": "https://github.com/privetin/chroma",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:59:33.806834+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 24,
        "forks": 7,
        "watchers": 24,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation providing vector database capabilities through Chroma, enabling semantic document search, metadata filtering, and document management with persistent storage.",
        "tools_exposed": [
          "create_document",
          "read_document",
          "update_document",
          "delete_document",
          "list_documents",
          "search_similar"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.1.2",
            "chromadb>=0.4.22",
            "sentence-transformers>=2.2.2"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ClaudePost",
      "repo_url": "https://github.com/ZilongXue/claude-post",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T01:59:50.936767+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 56,
        "forks": 7,
        "watchers": 56,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing an email management interface through Claude, enabling users to handle emails (search, read, send) via natural language conversations.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp>=1.1.2",
            "python-dotenv>=1.0.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.12"
      }
    },
    {
      "name": "Cloudinary",
      "repo_url": "https://github.com/felores/cloudinary-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:00:08.092378+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 4,
        "watchers": 4,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides tools for uploading images and videos to Cloudinary through Claude Desktop and compatible MCP clients.",
        "tools_exposed": [
          "upload"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "latest",
            "cloudinary": "^1.41.0"
          },
          "devDependencies": {
            "@types/node": "^20.8.0",
            "typescript": "^5.2.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "code-assistant",
      "repo_url": "https://github.com/stippi/code-assistant",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:00:36.782584+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 22,
        "forks": 4,
        "watchers": 22,
        "language_stack": [
          "Rust"
        ],
        "package_manager": [
          "Cargo"
        ],
        "dependencies_file": "Cargo.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Runs as a Model Context Protocol (MCP) server, providing tools (like `list_projects` and file operations) and project resources to LLMs running in an MCP client.",
        "tools_exposed": [
          "list_projects"
        ],
        "packages": {
          "dependencies": {
            "glob": "0.3",
            "ignore": "0.4",
            "walkdir": "2.5",
            "tokio": "1.44",
            "tempfile": "3.18",
            "rustyline": "12.0.0",
            "crossterm": "0.27.0",
            "gpui": "git",
            "smallvec": "1.14",
            "rust-embed": "8.4",
            "chromiumoxide": "0.5",
            "reqwest": "0.11",
            "futures": "0.3",
            "percent-encoding": "2.3",
            "scraper": "0.18",
            "url": "2.5",
            "htmd": "0.1.6",
            "oauth2": "4.4",
            "base64": "0.21",
            "tokio-tungstenite": "0.24",
            "serde": "1.0",
            "serde_json": "1.0",
            "anyhow": "1.0",
            "thiserror": "1.0",
            "regex": "1.11",
            "tracing": "0.1",
            "tracing-subscriber": "0.3",
            "clap": "4.5",
            "async-trait": "0.1",
            "dotenv": "0.15",
            "dirs": "5.0",
            "keyring": "2.3",
            "chrono": "0.4",
            "content_inspector": "0.2",
            "encoding_rs": "0.8.35",
            "unicode-segmentation": "1.12.0",
            "rand": "0.8.5",
            "similar": "2.5.0"
          },
          "devDependencies": {
            "axum": "0.7",
            "bytes": "1.10"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "code-executor",
      "repo_url": "https://github.com/bazinga012/mcp_code_executor",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:00:58.334542+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 43,
        "forks": 11,
        "watchers": 43,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that allows LLMs to execute Python code within a specified Conda environment, enabling access to libraries and dependencies defined therein.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "mcp-framework": "^0.1.12"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Start with a Node.js base image\nFROM node:18-alpine AS builder\n\n# Create a directory for the app\nWORKDIR /app\n\n# Copy package.json and package-lock.json for installing dependencies\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN npm install --ignore-scripts\n\n# Copy the rest of the application source code\nCOPY . .\n\n# Build the project\nRUN npm run build\n\n# Use the same Node.js base image for the final container\nFROM node:18-alpine\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the build output and necessary files from the builder stage\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\n# Install only production dependencies\nRUN npm ci --omit=dev\n\n# Set the environment variables for the Conda environment\nENV CODE_STORAGE_DIR=/path/to/code/storage\nENV CONDA_ENV_NAME=your-conda-env\n\n# Specify the command to run the MCP Code Executor server\nENTRYPOINT [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "code-sandbox-mcp",
      "repo_url": "https://github.com/Automata-Labs-team/code-sandbox-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:01:09.836836+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 103,
        "forks": 14,
        "watchers": 103,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A secure sandbox environment using Docker containers for AI applications to safely execute code. It allows container management, file operations, command execution, and real-time logging.",
        "tools_exposed": [
          "sandbox_initialize",
          "copy_project",
          "write_file",
          "sandbox_exec",
          "copy_file",
          "sandbox_stop"
        ],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "cognee-mcp",
      "repo_url": "https://github.com/topoteretes/cognee/tree/main/cognee-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:01:27.545398+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1841,
        "forks": 149,
        "watchers": 1841,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A MCP server project.",
        "tools_exposed": [
          "cognify"
        ],
        "packages": {
          "dependencies": [
            "cognee[postgres,codegraph,gemini,huggingface]==0.1.36",
            "mcp==1.5.0",
            "uv>=0.6.3"
          ],
          "devDependencies": [
            "debugpy>=1.8.12"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\n# ENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Set build argument\nARG DEBUG\n\n# Set environment variable based on the build argument\nENV DEBUG=${DEBUG}\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    gcc \\\n    libpq-dev\n\n# Copy pyproject.toml and lockfile first for better caching\nCOPY pyproject.toml uv.lock ./\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Copy .env file first if it exists (for environment variables)\nCOPY .env* /app/\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nCOPY . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv /app /app\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Set environment variables for MCP server\nENV PYTHONUNBUFFERED=1\nENV MCP_LOG_LEVEL=DEBUG\nENV PYTHONPATH=/app\n\n# Use the application name from pyproject.toml for normal operation\n# For testing, we'll override this with a direct command\nENTRYPOINT [\"cognee\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "coin_api_mcp",
      "repo_url": "https://github.com/longmans/coin_api_mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:01:46.475149+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 18,
        "forks": 2,
        "watchers": 18,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server that provides access to CoinMarketCap's cryptocurrency data, enabling AI-powered applications to retrieve cryptocurrency listings, quotes, and detailed information.",
        "tools_exposed": [
          "listing-coins",
          "get-coin-info",
          "get-coin-quotes"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp>=1.1.2"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into /app\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv     --mount=type=bind,source=uv.lock,target=uv.lock     --mount=type=bind,source=pyproject.toml,target=pyproject.toml     uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv     uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Environment variable for the CoinMarketCap API Key\nENV COINMARKETCAP_API_KEY=your_api_key_here\n\nENTRYPOINT [\"python\", \"-m\", \"coin_api_mcp\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "coinmarketcap",
      "repo_url": "https://coinmarketcap.com/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:01:46.475433+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://coinmarketcap.com/"
      }
    },
    {
      "name": "Contentful-mcp",
      "repo_url": "https://github.com/ivo-toby/contentful-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:02:04.171419+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 20,
        "forks": 5,
        "watchers": 20,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server implementation that integrates with Contentful's Content Management API, providing comprehensive content management capabilities.",
        "tools_exposed": [
          "search_entries",
          "create_entry",
          "get_entry",
          "update_entry",
          "delete_entry",
          "publish_entry",
          "unpublish_entry",
          "bulk_publish",
          "bulk_unpublish",
          "bulk_validate",
          "list_assets",
          "upload_asset",
          "get_asset",
          "update_asset",
          "delete_asset",
          "publish_asset",
          "unpublish_asset",
          "list_spaces",
          "get_space",
          "list_environments",
          "create_environment",
          "delete_environment",
          "list_content_types",
          "get_content_type",
          "create_content_type",
          "update_content_type",
          "delete_content_type",
          "publish_content_type"
        ],
        "packages": {
          "dependencies": {
            "@contentful/node-apps-toolkit": "^3.10.2",
            "@modelcontextprotocol/sdk": "1.0.1",
            "contentful-management": "^10.46.4",
            "dotenv": "^16.4.7",
            "zod": "^3.22.4",
            "zod-to-json-schema": "^3.22.1"
          },
          "devDependencies": {
            "@eslint/js": "^9.19.0",
            "@semantic-release/commit-analyzer": "^11.1.0",
            "@semantic-release/github": "^9.2.6",
            "@semantic-release/npm": "^11.0.3",
            "@semantic-release/release-notes-generator": "^12.1.0",
            "@types/chai": "^4.3.11",
            "@types/mocha": "^10.0.6",
            "@types/node": "^20.10.0",
            "@types/sinon": "^17.0.3",
            "@typescript-eslint/eslint-plugin": "^6.12.0",
            "@typescript-eslint/parser": "^6.12.0",
            "chai": "^5.0.0",
            "esbuild": "^0.19.9",
            "eslint": "^8.57.1",
            "eslint-plugin-perfectionist": "^4.7.0",
            "mocha": "^10.2.0",
            "msw": "^2.7.0",
            "nodemon": "^3.1.9",
            "prettier": "^3.4.2",
            "semantic-release": "^22.0.12",
            "sinon": "^17.0.1",
            "ts-node": "^10.9.2",
            "typescript": "^5.6.2",
            "typescript-eslint": "^8.22.0",
            "vitest": "^2.1.8"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use an official Node.js image as the base image\nFROM node:22-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN --mount=type=cache,target=/root/.npm npm install\n\n# Copy the rest of the application's source code\nCOPY . .\n\n# Build the application\nRUN npm run build\n\n# Use a smaller Node.js image for the runtime\nFROM node:22-alpine AS runtime\n\n# Set the working directory\nWORKDIR /app\n\n# Copy built files from the builder stage\nCOPY --from=builder /app/bin /app/bin\nCOPY --from=builder /app/node_modules /app/node_modules\n\n# Environment variable for Contentful Management API token\nENV CONTENTFUL_MANAGEMENT_ACCESS_TOKEN=your_contentful_management_api_token\n\n# Expose any required ports (if needed by the application)\n# EXPOSE 3000\n\n# Start the server\nENTRYPOINT [\"node\", \"bin/mcp-server.js\"]",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "Contentful",
      "repo_url": "https://contentful.com",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:02:04.171758+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://contentful.com"
      }
    },
    {
      "name": "crypto-feargreed-mcp",
      "repo_url": "https://github.com/kukapay/crypto-feargreed-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:02:20.401443+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 2,
        "watchers": 10,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides real-time and historical Crypto Fear & Greed Index data from Alternative.me, exposing tools for fetching and analyzing the index within MCP-compatible clients.",
        "tools_exposed": [
          "get_current_fng_tool",
          "get_historical_fng_tool",
          "analyze_fng_trend"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.4.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "cryptopanic-mcp-server",
      "repo_url": "https://github.com/kukapay/cryptopanic-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:02:35.403288+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 15,
        "forks": 5,
        "watchers": 15,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Provides the latest cryptocurrency news to AI agents, powered by the CryptoPanic API.",
        "tools_exposed": [
          "get_crypto_news"
        ],
        "packages": {
          "dependencies": [
            "dotenv>=0.9.9",
            "mcp[cli]>=1.3.0",
            "requests>=2.32.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Dappier",
      "repo_url": "https://github.com/DappierAI/dappier-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:02:52.860837+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 3,
        "watchers": 4,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server connects AI models to real-time, rights-cleared, proprietary data from Dappier, including web search, news, sports, financial data, and premium content.",
        "tools_exposed": [
          "dappier_real_time_search",
          "dappier_ai_recommendations"
        ],
        "packages": {
          "dependencies": [
            "dappier>=0.3.3",
            "mcp[cli]>=1.2.1",
            "pydantic>=2.10.2"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "marketplace.dappier.com",
      "repo_url": "https://marketplace.dappier.com/marketplace",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:02:52.861056+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://marketplace.dappier.com/marketplace"
      }
    },
    {
      "name": "Databricks",
      "repo_url": "https://github.com/JordiNeil/mcp-databricks-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:03:06.533976+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 15,
        "forks": 5,
        "watchers": 15,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "requirements.txt",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that connects to the Databricks API, allowing LLMs to run SQL queries, list jobs, and get job status/details.",
        "tools_exposed": [
          "run_sql_query",
          "list_jobs",
          "get_job_status",
          "get_job_details"
        ],
        "packages": {
          "dependencies": [
            "fastapi",
            "uvicorn",
            "databricks-sql-connector",
            "python-dotenv",
            "pydantic",
            "mcp",
            "pyarrow",
            "requests"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Datadog",
      "repo_url": "https://github.com/GeLi2001/datadog-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:03:19.629319+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 0,
        "watchers": 5,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server for interacting with the Datadog API, allowing access to monitors, dashboards, metrics, events, logs, and incidents.",
        "tools_exposed": [
          "get-monitors",
          "get-monitor",
          "get-dashboards",
          "get-dashboard",
          "get-metrics",
          "get-metric-metadata",
          "get-events",
          "get-incidents",
          "search-logs",
          "aggregate-logs"
        ],
        "packages": {
          "dependencies": {
            "@datadog/datadog-api-client": "^1.33.1",
            "@modelcontextprotocol/sdk": "^1.8.0",
            "dotenv": "^16.4.7",
            "minimist": "^1.2.8",
            "typescript": "^5.8.2",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/minimist": "^1.2.5"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Data Exploration",
      "repo_url": "https://github.com/reading-plus-ai/mcp-server-data-exploration",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:03:35.563357+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 232,
        "forks": 28,
        "watchers": 232,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP Server is designed for interactive data exploration, acting as a personal data scientist assistant to turn complex datasets into clear, actionable insights.",
        "tools_exposed": [
          "load-csv",
          "run-script"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "numpy>=2.1.3",
            "pandas>=2.2.3",
            "scikit-learn>=1.5.2",
            "scipy>=1.14.1",
            "statsmodels>=0.14.4"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Dataset Viewer",
      "repo_url": "https://github.com/privetin/dataset-viewer",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:03:50.660046+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 7,
        "watchers": 10,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for interacting with the Hugging Face Dataset Viewer API, providing capabilities to browse and analyze datasets hosted on the Hugging Face Hub.",
        "tools_exposed": [
          "validate",
          "get_info",
          "get_rows",
          "get_first_rows",
          "get_statistics",
          "search_dataset",
          "filter",
          "get_parquet"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.1.2",
            "httpx>=0.28.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "DBHub",
      "repo_url": "https://github.com/bytebase/dbhub/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:04:18.257703+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 164,
        "forks": 20,
        "watchers": 164,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "DBHub is a universal database gateway implementing the Model Context Protocol (MCP) server interface. It allows MCP-compatible clients to connect to and explore different databases.",
        "tools_exposed": [
          "run_query",
          "list_connectors",
          "generate_sql",
          "explain_db"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "better-sqlite3": "^11.9.0",
            "dotenv": "^16.4.7",
            "express": "^4.18.2",
            "mssql": "^11.0.1",
            "mysql2": "^3.13.0",
            "pg": "^8.13.3",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/better-sqlite3": "^7.6.12",
            "@types/express": "^4.17.21",
            "@types/mssql": "^9.1.7",
            "@types/node": "^22.13.10",
            "@types/pg": "^8.11.11",
            "cross-env": "^7.0.3",
            "ts-node": "^10.9.2",
            "tsup": "^8.4.0",
            "tsx": "^4.19.3",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "FROM node:22-alpine AS builder\n\nWORKDIR /app\n\n# Copy package.json and pnpm-lock.yaml\nCOPY package.json pnpm-lock.yaml ./\n\n# Install pnpm\nRUN corepack enable && corepack prepare pnpm@latest --activate\n\n# Install dependencies\nRUN pnpm install\n\n# Copy source code\nCOPY . .\n\n# Build the application\nRUN pnpm run build\n\n# Production stage\nFROM node:22-alpine\n\nWORKDIR /app\n\n# Copy only production files\nCOPY --from=builder /app/package.json /app/pnpm-lock.yaml ./\n\n# Install pnpm\nRUN corepack enable && corepack prepare pnpm@latest --activate\n\n# Install production dependencies only\nRUN pnpm install --prod\n\n# Copy built application from builder stage\nCOPY --from=builder /app/dist ./dist\n\n# Expose ports\nEXPOSE 8080\n\n# Set environment variables\nENV NODE_ENV=production\n\n# Run the server\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "DeepSeek MCP Server",
      "repo_url": "https://github.com/DMontgomery40/deepseek-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:04:34.203961+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 180,
        "forks": 16,
        "watchers": 180,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for the DeepSeek API, allowing seamless integration of DeepSeek's language models with MCP-compatible applications like Claude Desktop, featuring anonymous proxy usage.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "latest",
            "axios": "^1.6.0",
            "dotenv": "^16.3.1"
          },
          "devDependencies": {
            "@types/node": "^20.8.0",
            "typescript": "^5.2.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:18-alpine AS builder\n\nWORKDIR /app\n\n# Copy the necessary files\nCOPY package.json package-lock.json ./\nCOPY tsconfig.json ./\nCOPY src ./src\n\n# Install dependencies and build the project\nRUN npm install && npm run build\n\n# Use a smaller base image for the release\nFROM node:18-alpine AS release\n\nWORKDIR /app\n\n# Copy only the built output and necessary files\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/package.json ./package.json\nCOPY --from=builder /app/package-lock.json ./package-lock.json\n\n# Install production dependencies only\nRUN npm install --production\n\n# Set environment variable\nENV NODE_ENV=production\n\n# Entry point\nENTRYPOINT [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "other useful API endpoints",
      "repo_url": "https://github.com/DMontgomery40/deepseek-mcp-server?tab=readme-ov-file#features",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:04:34.489296+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 180,
        "forks": 16,
        "watchers": 180,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "File fetch error: Repository contents is not a directory; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "Deepseek_R1",
      "repo_url": "https://github.com/66julienmartin/MCP-server-Deepseek_R1",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:04:52.282926+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 48,
        "forks": 8,
        "watchers": 48,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation for the Deepseek R1 language model, optimized for reasoning tasks with an 8192 token context window.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "dotenv": "^16.4.7",
            "openai": "^4.80.1"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use Node.js 18-alpine as the base image\nFROM node:18-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN npm install --ignore-scripts\n\n# Copy the rest of the application\nCOPY . .\n\n# Build the application\nRUN npm run build\n\n# Prepare the runtime image\nFROM node:18-alpine\n\n# Set the working directory\nWORKDIR /app\n\n# Copy built application from the builder stage\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\n# Install only production dependencies\nRUN npm ci --only=production\n\n# Set environment variables (ensure to replace with your actual API key)\nENV DEEPSEEK_API_KEY=your-api-key-here\n\n# Expose necessary ports (if applicable)\n# EXPOSE 8080  # Example: adjust according to your needs\n\n# Command to run the server\nCMD [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "deepseek-thinker-mcp",
      "repo_url": "https://github.com/ruixingshi/deepseek-thinker-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:05:11.358033+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 37,
        "forks": 9,
        "watchers": 37,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Provides Deepseek model reasoning content and thought processes to MCP clients, supporting access via the Deepseek API service or a local Ollama server.",
        "tools_exposed": [
          "get-deepseek-thinker"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "ollama": "^0.5.12",
            "openai": "^4.83.0",
            "os": "^0.1.2",
            "path": "^0.12.7",
            "zod": "^3.24.1",
            "zod-to-json-schema": "^3.24.1"
          },
          "devDependencies": {
            "@types/node": "^22.10.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image for building the application\nFROM node:20-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package files and install dependencies\nCOPY package.json package-lock.json ./\nRUN npm install\n\n# Copy the source code and build the application\nCOPY src ./src\nCOPY tsconfig.json ./\nRUN npm run build\n\n# Use a lighter Node.js image for running the application\nFROM node:20-alpine AS release\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the built application and node_modules from the builder stage\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/node_modules ./node_modules\n\n# Set environment variables\nENV NODE_ENV=production\n\n# Command to run the application\nENTRYPOINT [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:20-alpine"
      }
    },
    {
      "name": "Descope",
      "repo_url": "https://github.com/descope-sample-apps/descope-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:05:11.717846+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/descope-sample-apps/descope-mcp-server'\nRedirect location: 'https://api.github.com/repositories/921929368'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "Descope",
      "repo_url": "https://descope.com",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:05:11.718025+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://descope.com"
      }
    },
    {
      "name": "DevRev",
      "repo_url": "https://github.com/kpsunil97/devrev-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:05:24.586908+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 4,
        "watchers": 2,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server for DevRev, used to search and retrieve information using the DevRev APIs.",
        "tools_exposed": [
          "search",
          "get_object"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "requests"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "here",
      "repo_url": "https://devrev.ai/docs/import#available-sources",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:05:24.587196+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://devrev.ai/docs/import#available-sources"
      }
    },
    {
      "name": "Dicom",
      "repo_url": "https://github.com/ChristianHinge/dicom-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:05:43.879505+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 20,
        "forks": 4,
        "watchers": 20,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol server for DICOM interactions, providing tools to query DICOM servers, enabling Large Language Models to access medical imaging metadata and extract text from encapsulated PDFs.",
        "tools_exposed": [
          "list_dicom_nodes",
          "switch_dicom_node",
          "switch_calling_aet",
          "verify_connection",
          "query_patients",
          "query_studies",
          "query_series",
          "query_instances",
          "get_attribute_presets",
          "retrieve_instance",
          "extract_pdf_text_from_dicom"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.3.0",
            "pynetdicom>=2.1.1",
            "pypdf2>=3.0.1",
            "pyyaml>=6.0.2"
          ],
          "devDependencies": [
            "pytest>=7.4.0",
            "requests>=2.31.0",
            "pydicom>=2.4.0",
            "pytest-cov>=6.0.0",
            "reportlab"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Dify",
      "repo_url": "https://github.com/YanxingLiu/dify-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:06:04.085399+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 174,
        "forks": 21,
        "watchers": 174,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that allows invoking configured Dify workflows as tools through the Model Context Protocol.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp>=1.1.2",
            "omegaconf>=2.3.0",
            "pip>=24.3.1",
            "python-dotenv>=1.0.1",
            "requests"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image\nFROM python:3.12-slim\n\n# Set the working directory\nWORKDIR /app\n\n# Copy pyproject.toml and uv.lock to the working directory\nCOPY pyproject.toml uv.lock /app/\n\n# Install the project's dependencies using a package manager that understands pyproject.toml\nRUN pip install --no-cache-dir hatchling && hatch build && pip install --no-cache-dir dist/*.whl\n\n# Copy the source files to the container\nCOPY src/dify_mcp_server /app/src/dify_mcp_server\n\n# Set environment variables, you should provide CONFIG_PATH during container run\nENV CONFIG_PATH=/path/to/config.yaml\n\n# Set the entrypoint\nENTRYPOINT [\"dify_mcp_server\"]\n\n# The command to run the server\nCMD [\"run\"]",
        "base_docker_image": "python:3.12-slim"
      }
    },
    {
      "name": "Discord",
      "repo_url": "https://github.com/v-3/discordmcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:06:18.176653+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 48,
        "forks": 19,
        "watchers": 48,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server enabling LLMs to interact with Discord channels by sending and reading messages via the Discord API, facilitating direct interaction while maintaining user control and security.",
        "tools_exposed": [
          "send-message",
          "read-messages"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.2.0",
            "discord.js": "^14.14.1",
            "dotenv": "^16.4.7",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.11.16",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Discord",
      "repo_url": "https://github.com/SaseQ/discord-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:06:35.027824+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 2,
        "watchers": 10,
        "language_stack": [
          "Java"
        ],
        "package_manager": [
          "maven"
        ],
        "dependencies_file": "pom.xml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for the Discord API (using JDA) that enables integrating Discord Bots with MCP applications like Claude Desktop.",
        "tools_exposed": [
          "get_server_info",
          "send_message",
          "edit_message",
          "delete_message",
          "read_messages",
          "send_private_message",
          "edit_private_message",
          "delete_private_message",
          "read_private_messages",
          "add_reaction",
          "remove_reaction",
          "find_text_channel",
          "create_webhook",
          "delete_webhook",
          "list_webhooks",
          "send_webhook_message"
        ],
        "packages": {
          "dependencies": [
            "org.springframework:spring-web",
            "org.springframework.ai:spring-ai-starter-mcp-server",
            "net.dv8tion:JDA:5.3.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM maven:3.9.6-amazoncorretto-17 AS build\n\nWORKDIR /app\n\nCOPY pom.xml .\nCOPY src ./src\n\nRUN mvn clean package -DskipTests\n\nFROM amazoncorretto:17-alpine\n\nWORKDIR /app\n\nCOPY --from=build /app/target/*.jar app.jar\n\nENV DISCORD_TOKEN=\"\"\n\nEXPOSE 8080\n\nENTRYPOINT [\"java\", \"-jar\", \"app.jar\"]\n",
        "base_docker_image": "maven:3.9.6-amazoncorretto-17"
      }
    },
    {
      "name": "Discourse",
      "repo_url": "https://github.com/AshDevFr/discourse-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:06:50.687271+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 1,
        "watchers": 2,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Node.js server implementing Model Context Protocol (MCP) for Discourse search operation.",
        "tools_exposed": [
          "search_posts"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "discourse2": "^1.1.26",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@biomejs/biome": "1.9.4",
            "@types/node": "^22.13.10",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "FROM node:22.14-alpine AS builder\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nRUN --mount=type=cache,target=/root/.npm-production npm ci --ignore-scripts --omit-dev\n\nRUN npm run build\n\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"/app/build/index.js\"]\n",
        "base_docker_image": "node:22.14-alpine"
      }
    },
    {
      "name": "Docker",
      "repo_url": "https://github.com/ckreiling/mcp-server-docker",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:07:09.861010+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 249,
        "forks": 30,
        "watchers": 249,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for managing Docker containers, images, networks, and volumes using natural language commands.",
        "tools_exposed": [
          "list_containers",
          "create_container",
          "run_container",
          "recreate_container",
          "start_container",
          "fetch_container_logs",
          "stop_container",
          "remove_container",
          "list_images",
          "pull_image",
          "push_image",
          "build_image",
          "remove_image",
          "list_networks",
          "create_network",
          "remove_network",
          "list_volumes",
          "create_volume",
          "remove_volume"
        ],
        "packages": {
          "dependencies": [
            "docker>=7.1.0",
            "mcp>=1.1.0",
            "pydantic-settings>=2.6.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\nWORKDIR /app\n\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\nCOPY uv.lock pyproject.toml /app/\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\nCOPY ./src /app/src\nCOPY README.md ./README.md\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Ensure executables in the venv take precedence over system executables\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"mcp-server-docker\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Drupal",
      "repo_url": "https://github.com/Omedia/mcp-server-drupal",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:07:26.204645+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32,
        "forks": 2,
        "watchers": 32,
        "language_stack": [
          "TypeScript",
          "JavaScript"
        ],
        "package_manager": [
          "Deno"
        ],
        "dependencies_file": "deno.jsonc",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Typescript-based Model Context Protocol (MCP) companion server for the Drupal MCP module, designed specifically for the STDIO transport.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "npm:@modelcontextprotocol/sdk@^1.6.1",
            "@std/assert": "jsr:@std/assert@1",
            "@std/cli": "jsr:@std/cli@^1.0.9",
            "@std/dotenv": "jsr:@std/dotenv@^0.225.3",
            "@std/fmt": "jsr:@std/fmt@^1.0.3",
            "@std/fs": "jsr:@std/fs@^1.0.8",
            "@std/path": "jsr:@std/path@^1.0.8",
            "zod": "npm:zod@^3.24.1"
          },
          "devDependencies": {}
        },
        "dockerfile_content": "FROM denoland/deno:2.1.5\n\nWORKDIR /app\n\nCOPY deno.jsonc deno.lock ./\nCOPY src ./src\n\nUSER deno\n\nRUN deno cache src/mod.ts\n\nENTRYPOINT [\"deno\", \"run\", \"--allow-net\", \"--allow-read\",\"--allow-env\" ,\"src/mod.ts\"]\n",
        "base_docker_image": "denoland/deno:2.1.5"
      }
    },
    {
      "name": "Drupal",
      "repo_url": "https://www.drupal.org/project/mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:07:26.204907+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.drupal.org/project/mcp"
      }
    },
    {
      "name": "dune-analytics-mcp",
      "repo_url": "https://github.com/kukapay/dune-analytics-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:07:41.226404+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 13,
        "forks": 1,
        "watchers": 13,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that bridges Dune Analytics data to AI agents, returning results as CSV.",
        "tools_exposed": [
          "get_latest_result",
          "run_query"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.4.1",
            "pandas>=2.2.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.13"
      }
    },
    {
      "name": "Elasticsearch",
      "repo_url": "https://github.com/cr7258/elasticsearch-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:08:03.101582+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 84,
        "forks": 16,
        "watchers": 84,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation providing Elasticsearch and OpenSearch interaction, enabling document search, index analysis, and cluster management through various tools.",
        "tools_exposed": [
          "list_indices",
          "get_index",
          "create_index",
          "delete_index",
          "search_documents",
          "index_document",
          "get_document",
          "delete_document",
          "delete_by_query",
          "get_cluster_health",
          "get_cluster_stats",
          "list_aliases",
          "get_alias",
          "put_alias",
          "delete_alias"
        ],
        "packages": {
          "dependencies": [
            "elasticsearch>=8.0.0",
            "opensearch-py>=2.0.0",
            "mcp>=1.0.0",
            "python-dotenv>=1.0.0",
            "fastmcp>=0.4.0",
            "anthropic>=0.49.0",
            "tomli>=2.2.1",
            "tomli-w>=1.2.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Start with a Python base image\nFROM python:3.10-slim\n\n# Set working directory\nWORKDIR /app\n\n# Copy necessary files\nCOPY . .\n\n# Install hatch to handle the build\nRUN pip install hatch\n\n# Clean dist directory before build\nRUN rm -rf dist/*\n\n# Use hatch to build the package and install it\nRUN hatch build && pip install dist/*.whl\n\n# Set environment variables required for the MCP server\n# These can be overridden at runtime with docker run --env\nENV ELASTICSEARCH_HOST=\"https://localhost:9200\"\nENV ELASTICSEARCH_USERNAME=\"elastic\"\nENV ELASTICSEARCH_PASSWORD=\"test123\"\n\n# Expose the port the server is running on (if applicable)\nEXPOSE 8000\n\n# Command to run the server\nENTRYPOINT [\"elasticsearch-mcp-server\"]",
        "base_docker_image": "python:3.10-slim"
      }
    },
    {
      "name": "ElevenLabs",
      "repo_url": "https://github.com/mamertofabian/elevenlabs-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:08:27.188072+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 61,
        "forks": 10,
        "watchers": 61,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server that integrates with the ElevenLabs text-to-speech API for managing voice generation tasks, including support for multiple voices and script parts.",
        "tools_exposed": [
          "generate_audio_simple",
          "generate_audio_script",
          "delete_job",
          "get_audio_file",
          "list_voices",
          "get_voiceover_history"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "requests",
            "pydub",
            "python-dotenv",
            "pytest>=8.3.4",
            "tenacity>=9.0.0",
            "aiosqlite>=0.19.0"
          ],
          "devDependencies": [
            "pytest",
            "pytest-asyncio",
            "pyright>=1.1.389",
            "pytest>=8.3.3",
            "ruff>=0.8.1"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Ergo Blockchain MCP",
      "repo_url": "https://github.com/marctheshark3/ergo-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:08:46.488464+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 2,
        "watchers": 5,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "requirements.txt",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server for interacting with the Ergo blockchain, providing tools to explore blocks, transactions, addresses, network statistics, mempool information, and token prices.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp>=0.5.0",
            "httpx>=0.23.0",
            "python-dotenv>=0.21.0",
            "asyncio>=3.4.3",
            "setuptools>=65.0.0",
            "fastapi>=0.95.0",
            "uvicorn>=0.22.0",
            "pydantic>=1.10.0",
            "aiohttp>=3.8.4"
          ],
          "devDependencies": [
            "pytest>=7.3.1",
            "pytest-asyncio>=0.21.0",
            "pytest-cov>=4.1.0",
            "pytest-mock>=3.10.0",
            "black>=23.0.0",
            "flake8>=6.0.0",
            "isort>=5.12.0",
            "mypy>=1.3.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Eunomia",
      "repo_url": "https://github.com/whataboutyou-ai/eunomia-MCP-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:09:03.471203+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 0,
        "watchers": 5,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "This server connects Eunomia instruments with MCP servers, providing a way to orchestrate data governance policies (like PII detection or user access control) and integrate them with external server processes in the MCP ecosystem.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "pip",
            "uv",
            "pydantic>=2.8.0",
            "python-dotenv==1.0.0",
            "pydantic-settings>=2.1.0",
            "mcp>=1.1.2",
            "eunomia-ai"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "EVM MCP Server",
      "repo_url": "https://github.com/mcpdotdirect/evm-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:09:19.334812+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 162,
        "forks": 28,
        "watchers": 162,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "bun"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A comprehensive Model Context Protocol (MCP) server that provides blockchain services across multiple EVM-compatible networks, enabling AI agents to interact with them via a unified interface.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "cors": "^2.8.5",
            "express": "^4.21.2",
            "viem": "^2.23.9",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/bun": "latest",
            "@types/cors": "^2.8.17",
            "@types/express": "^5.0.0",
            "conventional-changelog-cli": "^5.0.0"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Everything Search",
      "repo_url": "https://github.com/mamertofabian/mcp-everything-search",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:09:33.670047+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 102,
        "forks": 7,
        "watchers": 102,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that provides fast file searching capabilities across Windows, macOS, and Linux, utilizing the Everything SDK on Windows, `mdfind` on macOS, and `locate`/`plocate` on Linux.",
        "tools_exposed": [
          "search"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "pydantic>=2.0.0"
          ],
          "devDependencies": [
            "pyright>=1.1.389",
            "pytest>=8.3.3",
            "ruff>=0.8.1"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Everything SDK",
      "repo_url": "https://www.voidtools.com/support/everything/sdk/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:09:33.670360+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.voidtools.com/support/everything/sdk/"
      }
    },
    {
      "name": "Excel",
      "repo_url": "https://github.com/haris-musa/excel-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:09:49.004509+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 180,
        "forks": 18,
        "watchers": 180,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing Excel file manipulation capabilities (creation, data handling, formatting, charts, pivot tables) using OpenPyXL, without requiring Microsoft Excel installation.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.2.0",
            "openpyxl>=3.1.2"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Fantasy PL",
      "repo_url": "https://github.com/rishijatia/fantasy-pl-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:10:23.667429+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 3,
        "watchers": 10,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server providing access to Fantasy Premier League (FPL) data and tools, allowing interaction with FPL data in MCP-compatible clients like Claude for Desktop.",
        "tools_exposed": [
          "get_gameweek_status",
          "analyze_player_fixtures",
          "get_blank_gameweeks",
          "get_double_gameweeks",
          "analyze_players",
          "analyze_fixtures",
          "compare_players",
          "check_fpl_authentication",
          "get_my_team",
          "get_team",
          "get_manager_info"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.2.0",
            "httpx>=0.24.0",
            "python-dotenv",
            "diskcache",
            "jsonschema"
          ],
          "devDependencies": [
            "pytest>=7.0.0",
            "black>=23.0.0",
            "flake8>=6.0.0",
            "isort>=5.10.0",
            "mypy>=1.0.0",
            "build",
            "twine",
            "mcp[cli]>=1.2.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "fastn.ai \u2013 Unified API MCP Server",
      "repo_url": "https://github.com/fastnai/mcp-fastn",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:10:40.493424+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 7,
        "forks": 0,
        "watchers": 7,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "The Fastn server enables dynamic tool registration and execution based on API definitions, integrating with external services and AI assistants like Claude.ai and Cursor.ai.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.2.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Fetch",
      "repo_url": "https://github.com/zcaceres/fetch-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:10:57.154254+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 232,
        "forks": 32,
        "watchers": 232,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Provides functionality to fetch web content in various formats, including HTML, JSON, plain text, and Markdown.",
        "tools_exposed": [
          "fetch_html",
          "fetch_json",
          "fetch_txt",
          "fetch_markdown"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "jsdom": "^25.0.1",
            "turndown": "^7.2.0",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/jest": "^29.5.14",
            "@types/jsdom": "^21.1.7",
            "@types/node": "^22.10.2",
            "@types/turndown": "^5.0.5",
            "jest": "^29.7.0",
            "ts-jest": "^29.2.5",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Fingertip",
      "repo_url": "https://github.com/fingertip-com/fingertip-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:10:57.299251+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Client error '404 Not Found' for url 'https://api.github.com/repos/fingertip-com/fingertip-mcp'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404; File fetch error: Failed to fetch repository contents: 404; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "Figma",
      "repo_url": "https://github.com/GLips/Figma-Context-MCP",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:11:20.367212+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4465,
        "forks": 342,
        "watchers": 4465,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows AI coding tools (like Cursor) to access simplified Figma design metadata (layout, styling) by processing Figma file/frame/group links, facilitating accurate design implementation.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@figma/rest-api-spec": "^0.24.0",
            "@modelcontextprotocol/sdk": "^1.8.0",
            "@types/yargs": "^17.0.33",
            "cross-env": "^7.0.3",
            "dotenv": "^16.4.7",
            "express": "^4.21.2",
            "js-yaml": "^4.1.0",
            "remeda": "^2.20.1",
            "yargs": "^17.7.2",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/express": "^5.0.0",
            "@types/jest": "^29.5.14",
            "@types/js-yaml": "^4.0.9",
            "@types/node": "^20.17.0",
            "@typescript-eslint/eslint-plugin": "^8.24.0",
            "@typescript-eslint/parser": "^8.24.0",
            "eslint": "^9.20.1",
            "eslint-config-prettier": "^10.0.1",
            "jest": "^29.7.0",
            "prettier": "^3.5.0",
            "ts-jest": "^29.2.5",
            "tsup": "^8.4.0",
            "tsx": "^4.19.2",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Firebase",
      "repo_url": "https://github.com/gannonh/firebase-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:11:38.303233+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 62,
        "forks": 14,
        "watchers": 62,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables LLM clients using the Model Context Protocol (MCP) to interact with Firebase services, including Authentication, Firestore, and Storage, by exposing them as MCP tools.",
        "tools_exposed": [
          "auth_get_user",
          "firestore_add_document",
          "firestore_list_collections",
          "firestore_list_documents",
          "firestore_get_document",
          "firestore_update_document",
          "firestore_delete_document",
          "firestore_query_collection_group",
          "storage_list_files",
          "storage_get_file_info"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "firebase-admin": "^13.2.0"
          },
          "devDependencies": {
            "@types/express": "^5.0.1",
            "@types/node": "^22.13.17",
            "@vitest/coverage-v8": "^1.6.1",
            "typescript": "^5.8.2",
            "vitest": "^1.6.1"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\n# Stage 1: Build the project\nFROM node:lts-alpine AS builder\nWORKDIR /app\n\n# Copy dependency definitions\nCOPY package.json package-lock.json ./\n\n# Install dependencies without running scripts\nRUN npm install --ignore-scripts\n\n# Copy all project files\nCOPY . .\n\n# Build the project\nRUN npm run build\n\n# Stage 2: Package the build\nFROM node:lts-alpine\nWORKDIR /app\n\n# Copy only the production build and necessary files\nCOPY --from=builder /app/dist ./dist\nCOPY package.json ./\n\n# Install only production dependencies\nRUN npm install --production --ignore-scripts\n\n# Expose port if needed (for example 8080) - adjust as necessary\n# EXPOSE 8080\n\n# Run the MCP server\nCMD [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "FireCrawl",
      "repo_url": "https://github.com/vrknetha/mcp-server-firecrawl",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:11:38.612649+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/vrknetha/mcp-server-firecrawl'\nRedirect location: 'https://api.github.com/repositories/899407931'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "FlightRadar24",
      "repo_url": "https://github.com/sunsetcoder/flightradar24-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:11:55.927052+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 16,
        "forks": 4,
        "watchers": 16,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Claude Desktop MCP server that helps you track flights in real-time using Flightradar24 data, including arrival/departure times, airport status, and emergency flights.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "latest",
            "axios": "^1.6.0",
            "dotenv": "^16.4.7",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/express": "^4.17.21",
            "@types/node": "^20.10.4",
            "tsc-watch": "^6.0.4",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Ghost",
      "repo_url": "https://github.com/MFYDev/ghost-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:12:15.227446+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 34,
        "forks": 11,
        "watchers": 34,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for interacting with Ghost CMS through LLM interfaces like Claude, providing secure and comprehensive access to a Ghost blog using JWT authentication and tools for managing posts, users, members, tiers, offers, and newsletters.",
        "tools_exposed": [
          "ghost"
        ],
        "packages": {
          "dependencies": [
            "httpx",
            "pyjwt",
            "mcp[cli]>=1.2.1",
            "pytz"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into /app\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv     --mount=type=bind,source=uv.lock,target=uv.lock     --mount=type=bind,source=pyproject.toml,target=pyproject.toml     uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv     uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\n# Create non-root user for security\nRUN useradd --create-home app \\\n    && mkdir -p /app \\\n    && chown app:app /app\n\nWORKDIR /app\n \nCOPY --from=uv /app/.venv /app/.venv\nRUN chown -R app:app /app/.venv\n\nUSER app\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Environment variables for Ghost CMS connection\nENV GHOST_API_URL=<YOUR_GHOST_API_URL>\nENV GHOST_STAFF_API_KEY=<YOUR_STAFF_API_KEY>\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"uv\", \"--directory\", \"/app\", \"run\", \"src/main.py\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Github Actions",
      "repo_url": "https://github.com/ko1ynnky/github-actions-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:12:36.382687+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 7,
        "watchers": 12,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Server for the GitHub Actions API, enabling AI assistants to manage and operate GitHub Actions workflows.",
        "tools_exposed": [
          "list_workflows",
          "get_workflow",
          "get_workflow_usage",
          "list_workflow_runs",
          "get_workflow_run",
          "get_workflow_run_jobs",
          "trigger_workflow",
          "cancel_workflow_run",
          "rerun_workflow"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.8.0",
            "@types/node": "22.13.14",
            "node-fetch": "^3.3.2",
            "universal-user-agent": "^7.0.2",
            "zod": "^3.22.4",
            "zod-to-json-schema": "^3.24.5"
          },
          "devDependencies": {
            "typescript": "^5.8.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Glean",
      "repo_url": "https://github.com/longyi1207/glean-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:12:49.680148+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6,
        "forks": 3,
        "watchers": 6,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation integrating the Glean API to provide search results and chatbot Q&A functionalities.",
        "tools_exposed": [
          "Search",
          "Chat"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "node-fetch": "^3.3.2",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/node": "^22",
            "@types/node-fetch": "^2.6.12",
            "shx": "^0.3.4",
            "ts-node": "^10.9.2",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine as builder\n\nCOPY src/glean/ /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Gmail",
      "repo_url": "https://github.com/GongRzhe/Gmail-MCP-Server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:13:13.509470+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 129,
        "forks": 33,
        "watchers": 129,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for Gmail integration in Claude Desktop with auto authentication support, enabling AI assistants to manage Gmail through natural language interactions.",
        "tools_exposed": [
          "send_email",
          "draft_email",
          "read_email",
          "search_emails",
          "modify_email",
          "delete_email",
          "list_email_labels",
          "create_label",
          "update_label",
          "delete_label",
          "get_or_create_label"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.4.0",
            "googleapis": "^129.0.0",
            "google-auth-library": "^9.4.1",
            "open": "^10.0.0",
            "zod": "^3.22.4",
            "zod-to-json-schema": "^3.22.1"
          },
          "devDependencies": {
            "@types/node": "^20.10.5",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "FROM node:20-alpine\n\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm install\n\n# Copy source code\nCOPY . .\n\n# Build the application\nRUN npm run build\n\n# Create data directory\nRUN mkdir -p /app/calendar-data\n\n# Set permissions for the data directory\nRUN chown -R node:node /app/calendar-data\n\n# Switch to non-root user\nUSER node\n\n# Start the server\nCMD [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:20-alpine"
      }
    },
    {
      "name": "Gmail Headless",
      "repo_url": "https://github.com/baryhuang/mcp-headless-gmail",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:13:38.304536+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 13,
        "forks": 5,
        "watchers": 13,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A MCP server providing remote access to get and send Gmails without requiring local credential or token setup, featuring a decoupled architecture where clients handle OAuth.",
        "tools_exposed": [
          "gmail_refresh_token",
          "gmail_get_recent_emails",
          "gmail_get_email_content",
          "gmail_send_email"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.4.1",
            "python-dotenv>=1.0.1",
            "google-api-python-client>=2.127.0",
            "google-auth>=2.34.0",
            "google-auth-oauthlib>=1.2.0",
            "google-auth-httplib2>=0.2.0",
            "python-dateutil>=2.8.2"
          ],
          "devDependencies": [
            "pyright>=1.1.389"
          ]
        },
        "dockerfile_content": "# Use Python base image\nFROM python:3.11-slim\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Copy the entire project\nCOPY . /app\n\n# Install the package\nRUN pip install --no-cache-dir -e .\n\n# Run the server\nENTRYPOINT [\"mcp-server-headless-gmail\"] ",
        "base_docker_image": "python:3.11-slim"
      }
    },
    {
      "name": "Goal Story",
      "repo_url": "https://github.com/hichana/goalstory-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:13:56.963817+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 0,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables interaction with the Goal Story service, an AI-powered platform for managing aspirations through personalized narratives and visualization techniques, focusing on one goal at a time.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.7.0",
            "axios": "^1.7.9",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.11",
            "concurrently": "^9.1.2",
            "shx": "^0.3.4",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image\nFROM node:20-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package.json package-lock.json* ./\n\n# Install dependencies and build the project\nRUN npm install --ignore-scripts && \\\n    npm run build\n\n# Copy the source code and tsconfig\nCOPY tsconfig.json tsconfig.json\nCOPY src/ src/\n\n# Build the project\nRUN npm run build\n\n# Use a minimal image to run the app\nFROM node:20-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy only the necessary files from the builder\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\n# Install only production dependencies\nRUN npm install --omit=dev --ignore-scripts\n\n# Define environment variables\nENV NODE_ENV=production\n\n# Entry point for the container\nENTRYPOINT [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:20-alpine"
      }
    },
    {
      "name": "GOAT",
      "repo_url": "https://github.com/goat-sdk/goat/tree/main/typescript/examples/by-framework/model-context-protocol",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:14:13.315138+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 576,
        "forks": 197,
        "watchers": 576,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server connects GOAT with Claude for Desktop, enabling interaction with EVM (Base Sepolia) and Solana chains.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@goat-sdk/adapter-model-context-protocol": "0.2.11",
            "@goat-sdk/core": "0.4.9",
            "@goat-sdk/plugin-erc20": "0.2.14",
            "@goat-sdk/plugin-spl-token": "0.2.18",
            "@goat-sdk/wallet-evm": "0.2.11",
            "@goat-sdk/wallet-solana": "0.2.16",
            "@goat-sdk/wallet-viem": "0.2.12",
            "@modelcontextprotocol/sdk": "1.0.4",
            "@solana/web3.js": "1.98.0",
            "bip39": "^3.1.0",
            "bs58": "^6.0.0",
            "dotenv": "^16.4.5",
            "viem": "2.23.4",
            "zod": "3.23.8"
          },
          "devDependencies": {
            "@types/node": "22.7.4"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Godot",
      "repo_url": "https://github.com/Coding-Solo/godot-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:14:30.759999+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 228,
        "forks": 21,
        "watchers": 228,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables AI assistants to interact with the Godot game engine, allowing them to launch the editor, run projects, capture debug output, control execution, analyze projects, and manage scenes and UIDs.",
        "tools_exposed": [
          "launch_editor",
          "run_project",
          "get_debug_output",
          "stop_project",
          "get_godot_version",
          "list_projects",
          "get_project_info",
          "create_scene",
          "add_node",
          "load_sprite",
          "export_mesh_library",
          "save_scene",
          "get_uid",
          "update_project_uids"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "axios": "^1.7.9",
            "fs-extra": "^11.2.0"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Golang Filesystem Server",
      "repo_url": "https://github.com/mark3labs/mcp-filesystem-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:14:47.089205+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 183,
        "forks": 26,
        "watchers": 183,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "go mod"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Go server implementing the Model Context Protocol (MCP) to perform common filesystem operations like reading/writing files, managing directories, searching, and retrieving metadata within specified allowed directories.",
        "tools_exposed": [
          "read_file",
          "read_multiple_files",
          "write_file",
          "create_directory",
          "list_directory",
          "move_file",
          "search_files",
          "get_file_info",
          "list_allowed_directories"
        ],
        "packages": {
          "dependencies": [
            {
              "name": "github.com/mark3labs/mcp-go",
              "version": "v0.11.2"
            }
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM golang:1.23-alpine AS builder\n\nWORKDIR /app\n\n# Copy go.mod and go.sum first for caching dependencies\nCOPY go.mod go.sum ./\n\n# Download dependencies\nRUN go mod download\n\n# Copy the source code\nCOPY . .\n\n# Build the application\nRUN go build -ldflags=\"-s -w\" -o server .\n\nFROM alpine:latest\n\nWORKDIR /app\n\n# Copy the built binary from the builder stage\nCOPY --from=builder /app/server ./\n\n# The container will by default pass '/app' as the allowed directory if no other command line arguments are provided\nENTRYPOINT [\"./server\"]\nCMD [\"/app\"]\n",
        "base_docker_image": "golang:1.23-alpine"
      }
    },
    {
      "name": "Goodnews",
      "repo_url": "https://github.com/VectorInstitute/mcp-goodnews",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:15:08.700733+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 31,
        "forks": 0,
        "watchers": 31,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This server provides good, positive, and uplifting news by fetching articles from NewsAPI and ranking them for positive sentiment using a Cohere LLM.",
        "tools_exposed": [
          "fetch_list_of_goodnews"
        ],
        "packages": {
          "dependencies": [
            "asyncio>=3.4.3",
            "cohere>=5.14.0",
            "mcp[cli]>=1.4.1",
            "pydantic>=2.10.6"
          ],
          "devDependencies": [
            "black>=24.10.0",
            "codespell>=2.3.0",
            "fire>=0.7.0",
            "ipykernel>=6.29.5",
            "isort>=5.13.2",
            "mypy>=1.14.1",
            "pre-commit>=4.1.0",
            "pylint>=3.3.3",
            "pytest>=8.3.4",
            "pytest-asyncio>=0.25.2",
            "pytest-cov>=6.0.0",
            "pytest-mock>=3.14.0",
            "ruff>=0.9.2"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Google Calendar",
      "repo_url": "https://github.com/v-3/google-calendar",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:15:23.730513+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 30,
        "forks": 10,
        "watchers": 30,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows Claude to interact with Google Calendar, enabling capabilities like listing events, creating meetings, and finding free time slots.",
        "tools_exposed": [
          "list_events",
          "create_event",
          "update_event",
          "delete_event",
          "find_free_time"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "google-auth-library": "^9.15.0",
            "googleapis": "^144.0.0",
            "open": "^10.1.0",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/node": "^22.10.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Google Calendar",
      "repo_url": "https://github.com/nspady/google-calendar-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:15:40.983190+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 96,
        "forks": 40,
        "watchers": 96,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a Model Context Protocol (MCP) server that provides integration with Google Calendar, allowing LLMs to read, create, update and search for calendar events.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@google-cloud/local-auth": "^3.0.1",
            "@modelcontextprotocol/sdk": "^1.0.3",
            "@types/express": "^4.17.21",
            "esbuild": "^0.25.0",
            "express": "^4.18.2",
            "google-auth-library": "^9.15.0",
            "googleapis": "^144.0.0",
            "install": "^0.13.0",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.10.4",
            "@vitest/coverage-v8": "^3.1.1",
            "typescript": "^5.3.3",
            "vitest": "^3.1.1"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Google Custom Search",
      "repo_url": "https://github.com/adenot/mcp-google-search",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:15:56.388586+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 11,
        "forks": 4,
        "watchers": 11,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server that provides web search capabilities using Google Custom Search API and webpage content extraction functionality.",
        "tools_exposed": [
          "search",
          "read_webpage"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "axios": "^1.7.9",
            "cheerio": "^1.0.0"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use an official Node.js image as a parent image\nFROM node:18-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN npm install --ignore-scripts\n\n# Copy the TypeScript source code\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the TypeScript code\nRUN npm run build\n\n# Use a lightweight image for the final build\nFROM node:18-alpine\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the build files from the builder stage\nCOPY --from=builder /app/build ./build\nCOPY package.json ./\n\n# Install only production dependencies\nRUN npm ci --omit=dev\n\n# Expose the port on which the server will run (if required)\n# EXPOSE 8080\n\n# Define environment variables\nENV GOOGLE_API_KEY=your-api-key-here\nENV GOOGLE_SEARCH_ENGINE_ID=your-search-engine-id-here\n\n# Run the application\nENTRYPOINT [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "Google Tasks",
      "repo_url": "https://github.com/zcaceres/gtasks-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:16:10.932184+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 31,
        "forks": 10,
        "watchers": 31,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates with Google Tasks to allow listing, reading, searching, creating, updating, and deleting tasks.",
        "tools_exposed": [
          "search",
          "list",
          "create",
          "update",
          "delete",
          "clear"
        ],
        "packages": {
          "dependencies": {
            "@google-cloud/local-auth": "^3.0.1",
            "@modelcontextprotocol/sdk": "1.0.1",
            "googleapis": "^144.0.0"
          },
          "devDependencies": {
            "@types/node": "^22.9.3",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Stage 1: Build the TypeScript project\nFROM node:18-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN npm install --ignore-scripts\n\n# Copy the rest of the application code\nCOPY . .\n\n# Build the application\nRUN npm run build\n\n# Stage 2: Create the final image for running the app\nFROM node:18-alpine\n\n# Set the working directory\nWORKDIR /app\n\n# Copy built files from the builder stage\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package-lock.json /app\n\n# Install only production dependencies\nRUN npm ci --omit=dev\n\n# Set the command to run the app\nCMD [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "GraphQL Schema",
      "repo_url": "https://github.com/hannesj/mcp-graphql-schema",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:16:27.562522+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 1,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that exposes GraphQL schema information to Large Language Models (LLMs), allowing them to explore and understand the schema using specialized tools.",
        "tools_exposed": [
          "list-query-fields",
          "get-query-field",
          "list-mutation-fields",
          "get-mutation-field",
          "list-subscription-fields",
          "get-subscription-field",
          "list-types",
          "get-type",
          "get-type-fields",
          "search-schema"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "graphql": "^16.10.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "HDW LinkedIn",
      "repo_url": "https://github.com/horizondatawave/hdw-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:16:43.038507+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 3,
        "watchers": 12,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server providing access to LinkedIn data and functionalities, including user/company search, profile retrieval, and account management (chat, connections, posts), using the HorizonDataWave API.",
        "tools_exposed": [
          "search_linkedin_users",
          "get_linkedin_profile",
          "get_linkedin_email_user",
          "get_linkedin_user_posts",
          "get_linkedin_user_reactions",
          "get_linkedin_chat_messages",
          "send_linkedin_chat_message",
          "send_linkedin_connection",
          "send_linkedin_post_comment",
          "get_linkedin_user_connections",
          "get_linkedin_post_reposts",
          "get_linkedin_post_comments",
          "get_linkedin_google_company",
          "get_linkedin_company",
          "get_linkedin_company_employees"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.6.0",
            "dotenv": "^16.4.7",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^20.17.23",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "HorizonDataWave.ai",
      "repo_url": "https://horizondatawave.ai/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:16:43.038757+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://horizondatawave.ai/"
      }
    },
    {
      "name": "Heurist Mesh Agent",
      "repo_url": "https://github.com/heurist-network/heurist-mesh-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:17:06.012971+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 32,
        "forks": 8,
        "watchers": 32,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server connecting to Heurist Mesh APIs, providing Claude with access to various blockchain and web3 tools.",
        "tools_exposed": [
          "get_coingecko_id",
          "get_token_info",
          "get_trending_coins",
          "get_specific_pair_info",
          "get_token_pairs",
          "get_token_profiles",
          "search_pairs",
          "get_trending_tokens",
          "search_account",
          "search_mentions",
          "answer",
          "search",
          "search_and_answer",
          "execute_search",
          "generate_queries",
          "fetch_security_details"
        ],
        "packages": {
          "dependencies": [
            "anyio>=4.5",
            "click>=8.1.0",
            "httpx>=0.27",
            "mcp",
            "fastapi>=0.104.0",
            "uvicorn>=0.24.0",
            "pydantic>=2.0.0",
            "aiohttp>=3.9.0",
            "python-dotenv>=1.0.0",
            "requests>=2.28.0",
            "colorlog>=6.7.0"
          ],
          "devDependencies": [
            "pyright>=1.1.378",
            "pytest>=8.3.3",
            "ruff>=0.6.9",
            "pytest-asyncio>=0.23.0"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.10-bookworm-slim\n\n# Set the working directory\nWORKDIR /app\n\n# Copy dependency files first (for better caching)\nCOPY uv.lock pyproject.toml README.md ./\n\n# Install dependencies with caching\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install --system .\n\n# Copy the rest of the application files\nCOPY . .\n\n# Set the link mode to copy and compile bytecode\nENV UV_LINK_MODE=copy\nENV UV_COMPILE_BYTECODE=1\n\n# Default environment variables\nENV PORT=8000\nENV TRANSPORT=sse\n\n# Use ENTRYPOINT with sh -c to allow variable expansion\nENTRYPOINT [\"sh\", \"-c\", \"uv run mesh-tool-server --transport ${TRANSPORT} --port ${PORT}\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.10-bookworm-slim"
      }
    },
    {
      "name": "Heurist Mesh network",
      "repo_url": "https://github.com/heurist-network/heurist-agent-framework/tree/main/mesh",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:17:20.352255+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 437,
        "forks": 55,
        "watchers": 437,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This server provides access to Heurist Mesh, an open network of modular and purpose-built AI agents, via REST APIs (synchronous and asynchronous) and the MCP protocol.",
        "tools_exposed": [
          "get_token_info"
        ],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Holaspirit",
      "repo_url": "https://github.com/syucream/holaspirit-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:17:40.917514+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1,
        "forks": 3,
        "watchers": 1,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "This server provides MCP-compatible access to the Holaspirit API, allowing AI assistants to interact with Holaspirit data through a standardized interface.",
        "tools_exposed": [
          "list_tasks",
          "list_metrics",
          "list_circles",
          "get_circle",
          "list_roles",
          "get_role",
          "list_domains",
          "list_policies",
          "list_meetings",
          "get_meeting"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "@types/node": "^20.10.3",
            "dotenv": "^16.4.7",
            "holaspirit-client-typescript-fetch": "^0.0.2-202503270130",
            "typescript": "^5.3.2",
            "zod": "^3.22.4",
            "zod-to-json-schema": "^3.22.4"
          },
          "devDependencies": {
            "@typescript-eslint/eslint-plugin": "^6.19.0",
            "@typescript-eslint/parser": "^6.19.0",
            "eslint": "^8.17.0",
            "eslint-config-prettier": "^9.1.0",
            "prettier": "^3.2.2",
            "shx": "^0.3.4",
            "ts-node": "^10.9.2"
          }
        },
        "dockerfile_content": "FROM node:20-slim AS builder\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\nFROM node:20-slim AS runner\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install --production\nCOPY --from=builder /app/dist ./dist\n\nEXPOSE 3000\nCMD [\"npm\", \"start\"] ",
        "base_docker_image": "node:20-slim"
      }
    },
    {
      "name": "Holaspirit",
      "repo_url": "https://www.holaspirit.com/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:17:40.917821+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.holaspirit.com/"
      }
    },
    {
      "name": "Home Assistant",
      "repo_url": "https://github.com/tevonsb/homeassistant-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:18:01.335056+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 181,
        "forks": 8,
        "watchers": 181,
        "language_stack": [
          "TypeScript",
          "Node.js",
          "JavaScript"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server uses the Model Context Protocol to bridge a local Home Assistant instance with LLM applications, enabling natural language control and monitoring of smart home devices and system management.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@digital-alchemy/core": "^24.11.4",
            "@digital-alchemy/hass": "^24.11.4",
            "ajv": "^8.12.0",
            "dotenv": "^16.3.1",
            "express": "^4.18.2",
            "express-rate-limit": "^7.1.5",
            "helmet": "^7.1.0",
            "litemcp": "^0.7.0",
            "uuid": "^9.0.1",
            "ws": "^8.16.0",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/ajv": "^1.0.0",
            "@types/express": "^4.17.21",
            "@types/express-rate-limit": "^6.0.0",
            "@types/helmet": "^4.0.0",
            "@types/jest": "^29.5.14",
            "@types/node": "^20.17.16",
            "@types/uuid": "^9.0.8",
            "@types/ws": "^8.5.10",
            "jest": "^29.7.0",
            "rimraf": "^5.0.5",
            "ts-jest": "^29.1.2",
            "tsx": "^4.7.0",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Use Node.js 20 as the base image\nFROM node:20-slim\n\n# Install curl for healthcheck\nRUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*\n\n# Set working directory\nWORKDIR /app\n\n# Copy source code first\nCOPY . .\n\n# Install dependencies\nRUN npm install\n\n# Build TypeScript\nRUN npm run build\n\n# Expose the port the app runs on\nEXPOSE 3000\n\n# Start the application\nCMD [\"node\", \"dist/src/index.js\"] ",
        "base_docker_image": "node:20-slim"
      }
    },
    {
      "name": "Home Assistant",
      "repo_url": "https://www.home-assistant.io/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:18:01.335275+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.home-assistant.io/"
      }
    },
    {
      "name": "Home Assistant",
      "repo_url": "https://github.com/voska/hass-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:18:19.894484+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 34,
        "forks": 3,
        "watchers": 34,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server enabling AI assistants like Claude to interact directly with a Home Assistant instance for querying states, controlling entities, getting summaries, troubleshooting, searching, and using guided conversations.",
        "tools_exposed": [
          "get_version",
          "get_entity",
          "entity_action",
          "list_entities",
          "search_entities_tool",
          "domain_summary_tool",
          "list_automations",
          "call_service_tool",
          "restart_ha",
          "get_history",
          "get_error_log"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.4.1",
            "httpx>=0.27.0"
          ],
          "devDependencies": [
            "pytest>=8.3.5"
          ]
        },
        "dockerfile_content": "# MCP server Dockerfile for Claude Desktop integration\nFROM ghcr.io/astral-sh/uv:0.6.6-python3.13-bookworm\n\n# Set working directory\nWORKDIR /app\n\n# Copy project files\nCOPY . .\n\n# Set environment for MCP communication\nENV PYTHONUNBUFFERED=1\nENV PYTHONPATH=/app\n\n# Install package with UV (using --system flag)\nRUN uv pip install --system -e .\n\n# Run the MCP server with stdio communication using the module directly\nENTRYPOINT [\"python\", \"-m\", \"app\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:0.6.6-python3.13-bookworm"
      }
    },
    {
      "name": "HubSpot",
      "repo_url": "https://github.com/buryhuang/mcp-hubspot",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:18:20.150174+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/buryhuang/mcp-hubspot'\nRedirect location: 'https://api.github.com/repositories/908899631'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "HuggingFace Spaces",
      "repo_url": "https://github.com/evalstate/mcp-hfspace",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:18:38.329848+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 193,
        "forks": 31,
        "watchers": 193,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server connects Claude Desktop to Hugging Face Spaces, enabling interaction with various hosted models (e.g., image generation, vision, TTS, STT, chat) with minimal setup.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@gradio/client": "^1.8.0",
            "@modelcontextprotocol/sdk": "0.6.0",
            "mime": "^4.0.6",
            "minimist": "^1.2.8"
          },
          "devDependencies": {
            "@eslint/js": "9.19.0",
            "@types/minimist": "^1.2.5",
            "@types/node": "^20.11.24",
            "@typescript-eslint/eslint-plugin": "latest",
            "@typescript-eslint/parser": "latest",
            "eslint": "9.19.0",
            "globals": "15.14.0",
            "prettier": "latest",
            "rimraf": "^5.0.1",
            "typescript": "^5.3.3",
            "typescript-eslint": "8.21.0",
            "vitest": "^2.1.8"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Hyperliquid",
      "repo_url": "https://github.com/mektigboy/server-hyperliquid",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:19:07.030816+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 2,
        "watchers": 10,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that integrates the Hyperliquid SDK.",
        "tools_exposed": [
          "get_all_mids",
          "get_candle_snapshot",
          "get_l2_book"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.6.1",
            "@nktkas/hyperliquid": "^0.16.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.9",
            "shx": "^0.3.4",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "iFlytek Workflow",
      "repo_url": "https://github.com/iflytek/ifly-workflow-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:19:27.465480+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 18,
        "forks": 1,
        "watchers": 18,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "Poetry",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is an implementation of an MCP server using iFlytek, designed to enable the calling and execution of iFlytek workflows through MCP tools.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "httpx==0.28.1",
            "mcp==1.5.0",
            "pip==25.0.1",
            "pytest==8.3.5",
            "python-dotenv==1.0.1",
            "requests==2.32.3",
            "pyyaml==6.0.2"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Image Generation",
      "repo_url": "https://github.com/GongRzhe/Image-Generation-MCP-Server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:19:41.549307+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 14,
        "forks": 0,
        "watchers": 14,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides image generation capabilities using the Replicate Flux model.",
        "tools_exposed": [
          "generate_image"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.5.0",
            "@types/node": "^22.13.5",
            "axios": "^1.7.9",
            "typescript": "^5.7.3"
          },
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "InfluxDB",
      "repo_url": "https://github.com/idoru/influxdb-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:19:57.879695+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 1,
        "watchers": 4,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server that exposes access to an InfluxDB instance using the InfluxDB OSS API v2.",
        "tools_exposed": [
          "write-data",
          "query-data",
          "create-bucket",
          "create-org"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "node-fetch": "^3.3.2",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@jest/globals": "^29.7.0",
            "@types/dockerode": "^3.3.23",
            "@types/jest": "^29.5.5",
            "@types/node": "^22.13.10",
            "dockerode": "^4.0.0",
            "jest": "^29.7.0",
            "ts-jest": "^29.1.1",
            "typescript": "^5.8.2",
            "wait-for-expect": "^3.0.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Inoyu",
      "repo_url": "https://github.com/sergehuber/inoyu-mcp-unomi-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:20:10.995199+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 3,
        "watchers": 4,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server enabling Claude to maintain user context through Apache Unomi profile management.",
        "tools_exposed": [
          "get_my_profile",
          "update_my_profile",
          "get_profile",
          "search_profiles",
          "create_scope"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "axios": "^1.7.8",
            "dotenv": "^16.4.5"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Intercom",
      "repo_url": "https://github.com/raoulbia-ai/mcp-server-for-intercom",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:20:26.058592+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 3,
        "forks": 2,
        "watchers": 3,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP-compliant server for retrieving customer support tickets from Intercom, enabling AI assistants like Claude Desktop and Cline to access and analyze them.",
        "tools_exposed": [
          "list_tickets"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.3",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/chai": "^5.0.1",
            "@types/mocha": "^10.0.10",
            "@types/node": "^22.10.5",
            "@types/sinon": "^17.0.3",
            "chai": "^5.1.2",
            "mocha": "^11.0.1",
            "rimraf": "^5.0.10",
            "sinon": "^19.0.2",
            "ts-node": "^10.9.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": "node:18"
      }
    },
    {
      "name": "iOS Simulator",
      "repo_url": "https://github.com/InditexTech/mcp-server-simulator-ios-idb",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:20:44.866829+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 34,
        "forks": 2,
        "watchers": 34,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "This MCP server provides a bridge between Large Language Models (LLMs) and iOS simulators, enabling interaction and control through natural language commands.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "uuid": "^9.0.0",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/jest": "^29.5.14",
            "@types/node": "^20.11.0",
            "@types/uuid": "^9.0.0",
            "jest": "^29.7.0",
            "ts-jest": "^29.2.6",
            "typescript": "^5.0.0"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "iTerm MCP",
      "repo_url": "https://github.com/ferrislucas/iterm-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:21:02.830630+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 236,
        "forks": 14,
        "watchers": 236,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This Model Context Protocol (MCP) server provides access to the user's iTerm session, allowing models to interact with the terminal.",
        "tools_exposed": [
          "write_to_terminal",
          "read_terminal_output",
          "send_control_character"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "ts-node": "^10.9.2",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "JavaFX",
      "repo_url": "https://github.com/mcpso/mcp-server-javafx",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:21:02.957989+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Client error '404 Not Found' for url 'https://api.github.com/repos/mcpso/mcp-server-javafx'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404; File fetch error: Failed to fetch repository contents: 404; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "JDBC",
      "repo_url": "https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:21:16.913984+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 81,
        "forks": 21,
        "watchers": 81,
        "language_stack": [
          "Java"
        ],
        "package_manager": [
          "maven"
        ],
        "dependencies_file": "pom.xml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This Model Context Protocol (MCP) server enables Large Language Models (LLMs) to inspect, query, create and modify database content given just a Java Database Connectivity (JDBC) url.",
        "tools_exposed": [
          "read_query",
          "write_query",
          "create_table",
          "list_tables",
          "describe_table"
        ],
        "packages": {
          "dependencies": [
            "io.quarkiverse.mcp.servers:mcp-server-shared",
            "io.quarkus:quarkus-jackson",
            "io.quarkus:quarkus-qute",
            "io.quarkus:quarkus-arc"
          ],
          "devDependencies": [
            "io.quarkus:quarkus-junit5"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "more",
      "repo_url": "https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc#supported-jdbc-variants",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:21:16.914592+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 81,
        "forks": 21,
        "watchers": 81,
        "language_stack": [
          "Java"
        ],
        "package_manager": [
          "maven"
        ],
        "dependencies_file": "pom.xml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This Model Context Protocol (MCP) server enables Large Language Models (LLMs) to inspect, query, create and modify database content given just a Java Database Connectivity (JDBC) url.",
        "tools_exposed": [
          "read_query",
          "write_query",
          "create_table",
          "list_tables",
          "describe_table"
        ],
        "packages": {
          "dependencies": [
            "io.quarkiverse.mcp.servers:mcp-server-shared",
            "io.quarkus:quarkus-jackson",
            "io.quarkus:quarkus-qute",
            "io.quarkus:quarkus-arc"
          ],
          "devDependencies": [
            "io.quarkus:quarkus-junit5"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "JSON",
      "repo_url": "https://github.com/GongRzhe/JSON-MCP-Server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:21:34.027620+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 27,
        "forks": 6,
        "watchers": 27,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A JSON Model Context Protocol (MCP) server implementation for querying and manipulating JSON data. This server enables LLMs to interact with JSON data through a set of standardized tools.",
        "tools_exposed": [
          "query",
          "filter"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "jsonpath": "^1.1.1",
            "node-fetch": "^3.3.0",
            "zod": "^3.21.4"
          },
          "devDependencies": {
            "@types/jsonpath": "^0.2.0",
            "@types/node": "^18.0.0",
            "typescript": "^5.0.0"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "KiCad MCP",
      "repo_url": "https://github.com/lamaalrajih/kicad-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:21:54.319308+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 34,
        "forks": 5,
        "watchers": 34,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "requirements.txt",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This project provides a Model Context Protocol (MCP) server designed for interaction with KiCad projects, compatible with any MCP-compliant client.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp[cli]",
            "httpx",
            "pytest",
            "pandas",
            "kicad-python"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Keycloak MCP",
      "repo_url": "https://github.com/ChristophEnglisch/keycloak-model-context-protocol",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:22:09.201548+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 17,
        "forks": 5,
        "watchers": 17,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server for Keycloak administration, providing tools to manage users and realms.",
        "tools_exposed": [
          "create-user",
          "delete-user",
          "list-realms",
          "list-users"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@keycloak/keycloak-admin-client": "^22.0.5",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^22",
            "shx": "^0.3.4",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Kibela",
      "repo_url": "https://github.com/kiwamizamurai/mcp-kibela-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:22:26.220799+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1,
        "forks": 3,
        "watchers": 1,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP server implementation for Kibela API integration, enabling LLMs to interact with Kibela content.",
        "tools_exposed": [
          "kibela_search_notes",
          "kibela_get_my_notes",
          "kibela_get_note_content"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.0.1",
            "graphql-request": "^6.1.0",
            "express": "^4.18.2",
            "cors": "^2.8.5"
          },
          "devDependencies": {
            "@types/node": "^22",
            "@types/express": "^4.17.21",
            "@types/cors": "^2.8.17",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a node image with version 22.x for building\nFROM node:22-alpine AS builder\n\n# Create app directory\nWORKDIR /app\n\n# Copy source code and package.json into the app directory\nCOPY package.json tsconfig.json ./\nCOPY src ./src\n\n# Install dependencies and build the application\nRUN --mount=type=cache,target=/root/.npm npm install --ignore-scripts\nRUN npm run build\n\n# Use a smaller node image for running the app\nFROM node:22-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy built application from the builder stage\nCOPY --from=builder /app/dist ./dist\nCOPY package.json ./\n\n# Install only production dependencies\nRUN npm install --production\n\n# Set environment variables\nENV KIBELA_TEAM=your-team\nENV KIBELA_TOKEN=your-token\n\n# Expose the port the app runs on\nEXPOSE 3000\n\n# Command to run the executable\nENTRYPOINT [\"node\", \"dist/src/index.js\"]\n",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "kintone",
      "repo_url": "https://github.com/macrat/mcp-server-kintone",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:22:42.370801+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 1,
        "watchers": 9,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "Go Modules"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a Model Context Protocol (MCP) server for kintone. It allows AI tools like Claude Desktop to view and manipulate kintone data.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "github.com/macrat/go-jsonrpc2 v0.2.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM golang:latest AS builder\n\nWORKDIR /app\n\nCOPY go.mod ./\n\nRUN go mod download\n\nCOPY . .\n\nRUN CGO_ENABLED=0 go build -o mcp-server-kintone\n\n\nFROM scratch\n\nCOPY --from=builder /app/mcp-server-kintone /\n\nENTRYPOINT [\"/mcp-server-kintone\"]\n",
        "base_docker_image": "golang:latest"
      }
    },
    {
      "name": "kintone",
      "repo_url": "https://kintone.com",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:22:42.371014+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://kintone.com"
      }
    },
    {
      "name": "Kong Konnect",
      "repo_url": "https://github.com/Kong/mcp-konnect",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:23:00.814588+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 22,
        "forks": 2,
        "watchers": 22,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables AI assistants to interact with Kong Konnect's API Gateway, offering tools to query analytics data, inspect configuration details, and manage control planes through natural language conversation.",
        "tools_exposed": [
          "Query API Requests",
          "Get Consumer Requests",
          "List Services",
          "List Routes",
          "List Consumers",
          "List Plugins",
          "List Control Planes",
          "Get Control Plane",
          "List Control Plane Group Memberships",
          "Check Control Plane Group Membership"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "axios": "^1.6.2",
            "zod": "^3.22.2"
          },
          "devDependencies": {
            "@types/node": "^20.9.0",
            "typescript": "^5.2.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": "node:20"
      }
    },
    {
      "name": "Kubernetes",
      "repo_url": "https://github.com/Flux159/mcp-server-kubernetes",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:23:24.413965+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 315,
        "forks": 36,
        "watchers": 315,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "bun"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "MCP Server that can connect to a Kubernetes cluster and manage it.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@kubernetes/client-node": "0.20.0",
            "@modelcontextprotocol/sdk": "1.7.0",
            "express": "4.21.2",
            "js-yaml": "4.1.0",
            "yaml": "2.7.0",
            "zod": "3.23.8"
          },
          "devDependencies": {
            "@types/express": "5.0.1",
            "@types/js-yaml": "4.0.9",
            "@types/node": "22.9.3",
            "shx": "0.3.4",
            "typescript": "5.6.2",
            "vitest": "2.1.9"
          }
        },
        "dockerfile_content": "FROM node:22-bookworm-slim AS base\nWORKDIR /usr/local/app\nCOPY package.json .\n\n# Installing kubectl and gcloud with gke-gcloud-auth-plugin for accessing GKE\nRUN apt-get update && apt-get install -y curl\nRUN apt-get install -y apt-transport-https ca-certificates curl gnupg\n# Add k8s apt repository\nRUN curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\nRUN chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg\nRUN echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list\nRUN chmod 644 /etc/apt/sources.list.d/kubernetes.list\n# Add gcloud apt repository\nRUN curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\nRUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\nRUN apt-get update\nRUN apt-get install -y kubectl google-cloud-cli google-cloud-cli-gke-gcloud-auth-plugin\n\n# Build the typescript code\nFROM base AS dependencies\nRUN npm install\nCOPY tsconfig.json .\nCOPY src ./src\nRUN npm run build\n\n# Create the final production-ready image\nFROM base AS release\nRUN useradd -m appuser && chown -R appuser /usr/local/app\nENV NODE_ENV=production\nRUN npm install --only=production\nCOPY --from=dependencies /usr/local/app/dist ./dist\nUSER appuser\nCMD [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:22-bookworm-slim"
      }
    },
    {
      "name": "Kubernetes and OpenShift",
      "repo_url": "https://github.com/manusa/kubernetes-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:23:57.030855+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 68,
        "forks": 17,
        "watchers": 68,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "Go Modules",
          "npm"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Kubernetes Model Context Protocol (MCP) server implementation supporting operations on Kubernetes and OpenShift resources, including generic CRUD, pod management (list, get, delete, logs, exec, run), and viewing namespaces, events, and projects.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            {
              "name": "github.com/fsnotify/fsnotify",
              "version": "v1.9.0"
            },
            {
              "name": "github.com/mark3labs/mcp-go",
              "version": "v0.18.0"
            },
            {
              "name": "github.com/spf13/afero",
              "version": "v1.14.0"
            },
            {
              "name": "github.com/spf13/cobra",
              "version": "v1.9.1"
            },
            {
              "name": "github.com/spf13/viper",
              "version": "v1.20.1"
            },
            {
              "name": "golang.org/x/net",
              "version": "v0.38.0"
            },
            {
              "name": "k8s.io/api",
              "version": "v0.32.3"
            },
            {
              "name": "k8s.io/apiextensions-apiserver",
              "version": "v0.32.3"
            },
            {
              "name": "k8s.io/apimachinery",
              "version": "v0.32.3"
            },
            {
              "name": "k8s.io/client-go",
              "version": "v0.32.3"
            },
            {
              "name": "k8s.io/klog/v2",
              "version": "v2.130.1"
            },
            {
              "name": "k8s.io/utils",
              "version": "v0.0.0-20241104100929-3ea5e8cea738"
            },
            {
              "name": "sigs.k8s.io/controller-runtime",
              "version": "v0.20.4"
            },
            {
              "name": "sigs.k8s.io/controller-runtime/tools/setup-envtest",
              "version": "v0.0.0-20250211091558-894df3a7e664"
            },
            {
              "name": "sigs.k8s.io/yaml",
              "version": "v1.4.0"
            }
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM golang:latest AS builder\n\nWORKDIR /app\n\nCOPY ./ ./\nRUN make build\n\nFROM registry.access.redhat.com/ubi9/ubi-minimal:latest\nWORKDIR /app\nCOPY --from=builder /app/kubernetes-mcp-server /app/kubernetes-mcp-server\nENTRYPOINT [\"/app/kubernetes-mcp-server\", \"--sse-port\", \"8080\"]\n\nEXPOSE 8080\n",
        "base_docker_image": "golang:latest"
      }
    },
    {
      "name": "Langflow-DOC-QA-SERVER",
      "repo_url": "https://github.com/GongRzhe/Langflow-DOC-QA-SERVER",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:24:13.255513+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 3,
        "watchers": 5,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a TypeScript-based MCP server that implements a document Q&A system, providing an interface to query documents through a Langflow backend.",
        "tools_exposed": [
          "query_docs"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "axios": "^1.7.9"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Lightdash",
      "repo_url": "https://github.com/syucream/lightdash-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:24:31.654835+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 13,
        "forks": 3,
        "watchers": 13,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "An MCP server providing MCP-compatible access to the Lightdash API, allowing AI assistants to interact with Lightdash data through a standardized interface.",
        "tools_exposed": [
          "list_projects",
          "get_project",
          "list_spaces",
          "list_charts",
          "list_dashboards",
          "get_custom_metrics",
          "get_catalog",
          "get_metrics_catalog",
          "get_charts_as_code",
          "get_dashboards_as_code"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "@types/express": "^5.0.0",
            "@types/node": "^22.10.3",
            "dotenv": "^16.4.7",
            "express": "^4.21.2",
            "lightdash-client-typescript-fetch": "^0.0.4-202503270130",
            "typescript": "^5.7.2",
            "typescript-eslint": "^8.19.0",
            "zod": "^3.24.1",
            "zod-to-json-schema": "^3.24.1"
          },
          "devDependencies": {
            "@typescript-eslint/eslint-plugin": "^8.19.0",
            "@typescript-eslint/parser": "^8.19.0",
            "eslint": "^9.17.0",
            "eslint-config-prettier": "^9.1.0",
            "prettier": "^3.4.2",
            "shx": "^0.3.4",
            "ts-node": "^10.9.2"
          }
        },
        "dockerfile_content": "FROM node:20-slim AS builder\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\nFROM node:20-slim AS runner\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install --production\nCOPY --from=builder /app/dist ./dist\n\nEXPOSE 3000\nCMD [\"npm\", \"start\"] ",
        "base_docker_image": "node:20-slim"
      }
    },
    {
      "name": "Lightdash",
      "repo_url": "https://www.lightdash.com/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:24:31.655076+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.lightdash.com/"
      }
    },
    {
      "name": "Linear",
      "repo_url": "https://github.com/jerhadf/linear-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:24:45.287160+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 224,
        "forks": 41,
        "watchers": 224,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a Model Context Protocol (MCP) server that integrates with the Linear API, enabling Large Language Models (LLMs) to interact with Linear issues.",
        "tools_exposed": [
          "linear_create_issue",
          "linear_update_issue",
          "linear_search_issues",
          "linear_get_user_issues",
          "linear_add_comment"
        ],
        "packages": {
          "dependencies": {
            "@linear/sdk": "^33.0.0",
            "@modelcontextprotocol/sdk": "^1.0.3",
            "dotenv": "^16.4.6",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^20.17.9",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Linear (Go)",
      "repo_url": "https://github.com/geropl/linear-mcp-go",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:25:03.706193+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 1,
        "watchers": 4,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "Go Modules"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server for Linear, written in Go, providing tools for interacting with the Linear API.",
        "tools_exposed": [
          "linear_create_issue",
          "linear_update_issue",
          "linear_search_issues",
          "linear_get_user_issues",
          "linear_get_issue",
          "linear_add_comment",
          "linear_get_teams"
        ],
        "packages": {
          "dependencies": [
            {
              "name": "github.com/google/go-cmp",
              "version": "v0.7.0"
            },
            {
              "name": "github.com/mark3labs/mcp-go",
              "version": "v0.8.5"
            },
            {
              "name": "gopkg.in/dnaeon/go-vcr.v4",
              "version": "v4.0.2"
            }
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "LINE",
      "repo_url": "https://github.com/amornpan/py-mcp-line",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:25:20.748913+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 2,
        "watchers": 8,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "requirements.txt",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Python-based Model Context Protocol server providing access to LINE Bot messages. It enables Language Models to read and analyze LINE conversations via a standardized interface.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "fastapi==0.103.1",
            "line-bot-sdk==3.5.0",
            "python-dotenv==1.0.0",
            "uvicorn==0.23.2",
            "aiohttp==3.8.5",
            "pydantic==2.3.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "LlamaCloud",
      "repo_url": "https://github.com/run-llama/mcp-server-llamacloud",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:25:39.425558+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 68,
        "forks": 11,
        "watchers": 68,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that connects to multiple managed indexes on LlamaCloud, creating a separate tool with a 'query' parameter for each configured index.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "llamaindex": "^0.9.11"
          },
          "devDependencies": {
            "@changesets/cli": "^2.28.1",
            "@eslint/js": "^9.22.0",
            "@types/node": "^22.9.3",
            "eslint": "^9.22.0",
            "eslint-config-prettier": "^9.1.0",
            "globals": "^15.12.0",
            "prettier": "^3.4.2",
            "prettier-plugin-organize-imports": "^4.1.0",
            "typescript": "^5.6.2",
            "typescript-eslint": "^8.18.0"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "LlamaCloud",
      "repo_url": "https://cloud.llamaindex.ai/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:25:39.425732+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://cloud.llamaindex.ai/"
      }
    },
    {
      "name": "llm-context",
      "repo_url": "https://github.com/cyberchitta/llm-context.py",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:26:02.846010+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 175,
        "forks": 15,
        "watchers": 175,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A tool to inject relevant code/text project content into LLM chat interfaces, leveraging .gitignore patterns and supporting direct integration via the Model Context Protocol (MCP).",
        "tools_exposed": [
          "lc-init",
          "lc-set-rule",
          "lc-sel-files",
          "lc-sel-outlines",
          "lc-context",
          "lc-prompt",
          "lc-clip-files",
          "lc-changed",
          "lc-outlines",
          "lc-clip-implementations"
        ],
        "packages": {
          "dependencies": [
            "jinja2>=3.1.6, <4.0",
            "mcp>=1.3.0",
            "packaging>=24.1, <25.0",
            "pathspec>=0.12.1, <0.13.0",
            "pyperclip>=1.9.0, <2.0.0",
            "pyyaml>=6.0.2",
            "tree-sitter-language-pack>=0.6.0",
            "tree-sitter>=0.24"
          ],
          "devDependencies": [
            "git-cliff>=2.6.1, <3.0",
            "isort>=6.0.1, <7.0",
            "mypy>=1.11.2, <2.0",
            "pytest>=8.3.5, <9.0",
            "types-pyyaml>=6.0.12.20241230",
            "ruff>=0.9.10, <1.0",
            "taplo>=0.9.3, <1.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "mac-messages-mcp",
      "repo_url": "https://github.com/carterlasalle/mac_messages_mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:26:17.568044+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 43,
        "forks": 2,
        "watchers": 43,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Python bridge for interacting with the macOS Messages app using MCP (Multiple Context Protocol). It allows reading recent messages and sending new messages.",
        "tools_exposed": [
          "get_recent_messages",
          "send_message"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]"
          ],
          "devDependencies": [
            "pytest>=7.0.0",
            "black>=23.0.0",
            "isort>=5.10.0",
            "mypy>=1.0.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.11"
      }
    },
    {
      "name": "MariaDB",
      "repo_url": "https://github.com/abel9851/mcp-server-mariadb",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:26:33.375428+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 7,
        "forks": 1,
        "watchers": 7,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server implementation for retrieving data from mariadb.",
        "tools_exposed": [
          "query_database"
        ],
        "packages": {
          "dependencies": [
            "mariadb>=1.1.12",
            "mcp[cli]>=1.3.0",
            "mysql-connector-python>=9.2.0",
            "pytest>=8.3.4",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Maton",
      "repo_url": "https://github.com/maton-ai/agent-toolkit/tree/main/modelcontextprotocol",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:27:01.621997+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 24,
        "forks": 3,
        "watchers": 24,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This server allows integration with Maton APIs using the Model Context Protocol, enabling function calls to interact with various connected applications and perform specific actions.",
        "tools_exposed": [
          "list-bases",
          "list-records",
          "list-tables",
          "create-task",
          "get-task",
          "list-projects",
          "list-tasks",
          "list-workspaces",
          "get-s3-object",
          "list-s3-buckets",
          "list-s3-objects",
          "get-event",
          "list-event-invitees",
          "list-event-types",
          "list-events",
          "create-task",
          "delete-task",
          "get-task",
          "list-folders",
          "list-lists",
          "list-spaces",
          "list-tasks",
          "list-workspaces",
          "create-event",
          "delete-event",
          "get-calendar",
          "get-event",
          "list-calendars",
          "list-events",
          "update-event",
          "append-text",
          "create-document",
          "find-document",
          "get-document",
          "create-file",
          "create-folder",
          "delete-file",
          "find-file",
          "find-folder",
          "get-file",
          "list-files",
          "add-label-to-email",
          "create-draft",
          "find-email",
          "list-labels",
          "send-email",
          "add-column",
          "add-multiple-rows",
          "clear-cell",
          "clear-rows",
          "create-spreadsheet",
          "create-worksheet",
          "delete-rows",
          "delete-worksheet",
          "find-row",
          "get-cell",
          "get-spreadsheet",
          "get-values-in-range",
          "list-worksheets",
          "update-cell",
          "update-multiple-rows",
          "update-row",
          "create-contact",
          "get-contact",
          "list-contacts",
          "search-contacts",
          "merge-contacts",
          "update-contact",
          "delete-contact",
          "create-deal",
          "get-deal",
          "list-deals",
          "search-deals",
          "merge-deals",
          "update-deal",
          "delete-deal",
          "list-clouds",
          "get-issue",
          "list-issues",
          "add-comment-to-issue",
          "list-comments",
          "update-comment",
          "list-projects",
          "get-user",
          "list-users",
          "list-forms",
          "list-submissions",
          "add-profiles-to-list",
          "assign-template-to-campaign"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.4.1",
            "@maton/agent-toolkit": "latest",
            "colors": "^1.4.0"
          },
          "devDependencies": {
            "@eslint/compat": "^1.2.6",
            "@types/jest": "^29.5.14",
            "@types/node": "^22.13.4",
            "@typescript-eslint/eslint-plugin": "^8.24.1",
            "eslint-config-prettier": "^10.0.1",
            "eslint-plugin-import": "^2.31.0",
            "eslint-plugin-jest": "^28.11.0",
            "eslint-plugin-prettier": "^5.2.3",
            "globals": "^15.15.0",
            "jest": "^29.7.0",
            "prettier": "^3.5.1",
            "ts-jest": "^29.2.5",
            "ts-node": "^10.9.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY modelcontextprotocol /app\nCOPY modelcontextprotocol/tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nRUN --mount=type=cache,target=/root/.npm-production npm ci --ignore-scripts --omit-dev\n\nFROM node:22-alpine AS release\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nWORKDIR /app\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "MCP Compass",
      "repo_url": "https://github.com/liuyoshio/mcp-compass",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:27:15.440341+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 53,
        "forks": 6,
        "watchers": 53,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Compass is a discovery and recommendation service that helps AI assistants find and understand available MCP services using natural language queries.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@liuyoshio/mcp-compass": "^1.0.7",
            "@modelcontextprotocol/sdk": "^1.0.3",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/node": "^22.10.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "MCP Create",
      "repo_url": "https://github.com/tesla0225/mcp-create",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:27:31.403886+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 42,
        "forks": 6,
        "watchers": 42,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This service is an MCP server that dynamically creates, runs, and manages other Model Context Protocol (MCP) servers as child processes.",
        "tools_exposed": [
          "create-server-from-template",
          "execute-tool",
          "get-server-tools",
          "delete-server",
          "list-servers"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.0",
            "uuid": "^9.0.1",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.10.0",
            "@types/uuid": "^9.0.8",
            "typescript": "^5.3.2"
          }
        },
        "dockerfile_content": "# \u30d3\u30eb\u30c9\u30b9\u30c6\u30fc\u30b8\nFROM node:20-slim AS builder\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\n# \u5b9f\u884c\u30b9\u30c6\u30fc\u30b8\nFROM node:20-slim\n\nRUN apt-get update && \\\n    apt-get install -y --no-install-recommends \\\n    python3-minimal \\\n    python3-pip \\\n    curl \\\n    which && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/* && \\\n    ln -sf /usr/bin/python3 /usr/bin/python && \\\n    npm install -g ts-node typescript\n\nENV PATH=\"/usr/local/bin:/usr/bin:/bin:${PATH}\"\nENV NODE_PATH=\"/app/node_modules\"\nENV PYTHONUNBUFFERED=1\n\nWORKDIR /app\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/node_modules ./node_modules\n# package.json\u3092\u30b3\u30d4\u30fc\u3057\u3066\"type\": \"module\"\u8a2d\u5b9a\u3092\u78ba\u5b9f\u306b\u7d99\u627f\nCOPY --from=builder /app/package*.json ./\n\nRUN chmod +x build/index.js && \\\n    mkdir -p /tmp/mcp-create-servers && \\\n    chmod 777 /tmp/mcp-create-servers\n\nCMD [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:20-slim"
      }
    },
    {
      "name": "MCP Installer",
      "repo_url": "https://github.com/anaisbetts/mcp-installer",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:27:44.792297+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 887,
        "forks": 111,
        "watchers": 887,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This server installs other MCP servers (hosted in npm or PyPi) when requested via Claude.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.1",
            "rimraf": "^6.0.1",
            "spawn-rx": "^4.0.0"
          },
          "devDependencies": {
            "shx": "^0.3.4",
            "ts-node": "^10.9.2",
            "typescript": "^5.6.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "mcp-k8s-go",
      "repo_url": "https://github.com/strowk/mcp-k8s-go",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:28:12.398294+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 213,
        "forks": 27,
        "watchers": 213,
        "language_stack": [
          "Go"
        ],
        "package_manager": [
          "Go Modules"
        ],
        "dependencies_file": "go.mod",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Golang-based MCP server designed to connect to and interact with Kubernetes clusters.",
        "tools_exposed": [
          "List Kubernetes contexts",
          "List Kubernetes namespaces",
          "List and get any Kubernetes resources",
          "List Kubernetes nodes",
          "Get Kubernetes events",
          "Get Kubernetes pod logs",
          "Run command in Kubernetes pod"
        ],
        "packages": {
          "dependencies": [
            "github.com/stretchr/testify@v1.10.0",
            "github.com/strowk/foxy-contexts@v0.1.0-beta.4",
            "go.uber.org/fx@v1.23.0",
            "go.uber.org/mock@v0.5.1",
            "go.uber.org/zap@v1.27.0",
            "k8s.io/api@v0.32.3",
            "k8s.io/apimachinery@v0.32.3",
            "k8s.io/client-go@v0.32.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM gcr.io/distroless/static-debian12\nUSER nonroot:nonroot\nCOPY --chown=nonroot:nonroot mcp-k8s-go /\nENTRYPOINT [\"/mcp-k8s-go\"]\n",
        "base_docker_image": "gcr.io/distroless/static-debian12"
      }
    },
    {
      "name": "mcp-local-rag",
      "repo_url": "https://github.com/nkapila6/mcp-local-rag",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:28:30.490025+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 2,
        "watchers": 12,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A primitive RAG-like web search Model Context Protocol (MCP) server that runs locally without requiring external APIs.",
        "tools_exposed": [
          "rag_search"
        ],
        "packages": {
          "dependencies": [
            "aiohttp>=3.11.13",
            "beautifulsoup4>=4.13.3",
            "duckduckgo-search>=7.5.2",
            "mcp[cli]>=1.3.0",
            "mediapipe>=0.10.21",
            "requests>=2.32.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "mcp-proxy",
      "repo_url": "https://github.com/sparfenyuk/mcp-proxy",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:28:52.031102+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 344,
        "forks": 46,
        "watchers": 344,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "The `mcp-proxy` is a tool that lets you switch between server transports, supporting modes for stdio to SSE and SSE to stdio communication.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp>=1.5.0,<2",
            "uvicorn>=0.34.0"
          ],
          "devDependencies": [
            "pytest>=8.3.3",
            "pytest-asyncio>=0.25.0",
            "coverage>=7.6.0",
            "mypy>=1.0.0"
          ]
        },
        "dockerfile_content": "# Build stage with explicit platform specification\nFROM ghcr.io/astral-sh/uv:python3.12-alpine AS uv\n\n# Install the project into /app\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\n# Final stage with explicit platform specification\nFROM python:3.12-alpine\n\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\nENTRYPOINT [\"mcp-proxy\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-alpine"
      }
    },
    {
      "name": "mem0-mcp",
      "repo_url": "https://github.com/mem0ai/mem0-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:29:07.691704+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 79,
        "forks": 12,
        "watchers": 79,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server uses mem0 to manage coding preferences efficiently, providing tools for storing, retrieving, and searching them, primarily intended for use with Cursor.",
        "tools_exposed": [
          "add_coding_preference",
          "get_all_coding_preferences",
          "search_coding_preferences"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.3.0",
            "mem0ai>=0.1.55"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "MSSQL",
      "repo_url": "https://github.com/aekanun2020/mcp-server/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:29:07.846696+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Client error '404 Not Found' for url 'https://api.github.com/repos/aekanun2020/mcp-server'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404; File fetch error: Failed to fetch repository contents: 404; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "MSSQL",
      "repo_url": "https://github.com/JexinSam/mssql_mcp_server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:29:29.647597+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 4,
        "watchers": 9,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server enabling secure, structured interaction with Microsoft SQL Server (MSSQL) databases. It allows AI assistants to list tables, read table contents, and execute SQL queries with controlled access and logging.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.0.0",
            "pyodbc>=5.2.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "MSSQL-Python",
      "repo_url": "https://github.com/amornpan/py-mcp-mssql",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:29:49.894013+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 3,
        "watchers": 12,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "requirements.txt",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Python MCP server implementation providing access to Microsoft SQL Server databases, enabling Language Models to inspect table schemas and execute SQL queries.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "fastapi>=0.104.1",
            "pydantic>=2.10.6",
            "uvicorn>=0.34.0",
            "python-dotenv>=1.0.1",
            "pyodbc>=4.0.35",
            "anyio>=4.5.0",
            "mcp==1.2.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.11-slim"
      }
    },
    {
      "name": "MSSQL-MCP",
      "repo_url": "https://github.com/daobataotie/mssql-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:30:03.318592+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 18,
        "forks": 4,
        "watchers": 18,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "requirements.txt",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MSSQL MCP server provides database interaction and business intelligence capabilities, enabling users to run SQL queries, manage tables, and generate business insight memos.",
        "tools_exposed": [
          "read_query",
          "write_query",
          "create_table",
          "list_tables",
          "describe-table",
          "append_insight"
        ],
        "packages": {
          "dependencies": [
            {
              "name": "pyodbc",
              "version": ">=4.0.39",
              "source": "requirements.txt"
            },
            {
              "name": "pydantic",
              "version": ">=2.0.0",
              "source": "requirements.txt"
            },
            {
              "name": "mcp",
              "version": ">=0.1.0",
              "source": "requirements.txt"
            }
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Markdownify",
      "repo_url": "https://github.com/zcaceres/mcp-markdownify-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:30:03.517514+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/zcaceres/mcp-markdownify-server'\nRedirect location: 'https://api.github.com/repositories/905450127'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "Microsoft Teams",
      "repo_url": "https://github.com/InditexTech/mcp-teams-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:30:27.689752+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 30,
        "forks": 1,
        "watchers": 30,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server implementation for Microsoft Teams integration, providing capabilities to read messages, create messages, reply to messages, and mention members.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "aiohttp==3.10.5",
            "asyncio>=3.4.3",
            "botbuilder-core>=4.16.2",
            "botbuilder-integration-aiohttp>=4.16.2",
            "dotenv>=0.9.9",
            "mcp[cli]>=1.6.0",
            "msgraph-sdk>=1.25.0",
            "multidict==6.2.0"
          ],
          "devDependencies": [
            "mock>=5.2.0",
            "pyproject-parser[cli]>=0.13.0",
            "pyright>=1.1.398",
            "pytest>=8.3.5",
            "pytest-asyncio>=0.25.3",
            "pytest-cov>=6.0.0",
            "reuse>=5.0.2",
            "ruff>=0.11.2"
          ]
        },
        "dockerfile_content": "FROM ghcr.io/astral-sh/uv:python3.10-alpine\n\n# ENV TEAMS_APP_ID=\"\" TEAMS_APP_PASSWORD=\"\" TEAMS_APP_TYPE=\"\" TEAMS_APP_TENANT_ID=\"\" TEAM_ID=\"\" TEAMS_CHANNEL_ID=\"\"\n\nLABEL \\\n  org.opencontainers.image.vendor=\"Industria de Dise\u00f1o Textil, S.A.\" \\\n  org.opencontainers.image.source=\"https://github.com/InditexTech/mcp-teams-server\" \\\n  org.opencontainers.image.authors=\"Open Source Office Team\" \\\n  org.opencontainers.image.title=\"MCP Teams Server\" \\\n  org.opencontainers.image.description=\"MCP Teams Server container image\" \\\n  org.opencontainers.image.licenses=\"Apache-2.0\"\n\n# Settings for faster container start\nENV UV_COMPILE_BYTECODE=0 UV_PYTHON_DOWNLOADS=0 UV_LINK_MODE=copy\n\nCOPY pyproject.toml LICENSE.txt *.md uv.lock src /app/\nWORKDIR /app\nRUN uv sync --frozen --no-dev\n\nCMD [\"uv\", \"run\", \"--frozen\", \"--no-dev\", \"mcp-teams-server\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.10-alpine"
      }
    },
    {
      "name": "Mindmap",
      "repo_url": "https://github.com/YuChenSSR/mindmap-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:30:42.238818+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 45,
        "forks": 5,
        "watchers": 45,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server designed to convert Markdown content into interactive mindmaps, using the markmap-cli library.",
        "tools_exposed": [
          "markdown-to-mindmap-content",
          "markdown-to-mindmap-file"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.2.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Minima",
      "repo_url": "https://github.com/dmayboroda/minima",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:31:04.027248+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 689,
        "forks": 65,
        "watchers": 689,
        "language_stack": [
          "JavaScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Minima is an open-source RAG (Retrieval-Augmented Generation) system deployable via on-premises containers, enabling querying of local documents. It supports fully local operation or integration with ChatGPT and Claude (via MCP).",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Mobile MCP",
      "repo_url": "https://github.com/mobile-next/mobile-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:31:21.980012+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 96,
        "forks": 12,
        "watchers": 96,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server enables scalable, platform-agnostic mobile automation for iOS and Android, allowing Agents and LLMs to interact with native apps via accessibility snapshots or coordinate-based taps.",
        "tools_exposed": [
          "mobile_list_apps",
          "mobile_launch_app",
          "mobile_terminate_app",
          "mobile_get_screen_size",
          "mobile_click_on_screen_at_coordinates",
          "mobile_list_elements_on_screen",
          "mobile_element_tap",
          "mobile_tap",
          "mobile_press_button",
          "mobile_open_url",
          "mobile_type_text",
          "mobile_element_swipe",
          "mobile_swipe"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "fast-xml-parser": "^5.0.9",
            "nyc": "^17.1.0",
            "sharp": "^0.33.5",
            "zod-to-json-schema": "^3.24.4"
          },
          "devDependencies": {
            "@eslint/eslintrc": "^3.2.0",
            "@eslint/js": "^9.19.0",
            "@stylistic/eslint-plugin": "^3.0.1",
            "@types/mocha": "^10.0.10",
            "@types/node": "^22.13.10",
            "@typescript-eslint/eslint-plugin": "^8.28.0",
            "@typescript-eslint/parser": "^8.26.1",
            "@typescript-eslint/utils": "^8.26.1",
            "eslint": "^9.19.0",
            "eslint-plugin": "^1.0.1",
            "eslint-plugin-import": "^2.31.0",
            "eslint-plugin-notice": "^1.0.0",
            "husky": "^9.1.7",
            "mocha": "^11.1.0",
            "ts-node": "^10.9.2",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "MongoDB",
      "repo_url": "https://github.com/kiliczsh/mcp-mongo-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:31:38.991286+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 101,
        "forks": 11,
        "watchers": 101,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server that provides access to MongoDB databases. This server enables LLMs to inspect collection schemas and execute MongoDB operations.",
        "tools_exposed": [
          "query",
          "aggregate",
          "update",
          "serverInfo",
          "insert",
          "createIndex",
          "count"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "@types/mongodb": "^4.0.6",
            "mongodb": "^6.11.0",
            "zod": "^3.23.8"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image for building the project\nFROM node:20-alpine AS builder\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Copy package files\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN --mount=type=cache,target=/root/.npm npm install\n\n# Copy the rest of the project files\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the project\nRUN npm run build\n\n# Use a smaller Node.js image for the runtime\nFROM node:20-alpine\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Copy only the necessary files for running the application\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY --from=builder /app/package.json ./package.json\n\n# Copy an entrypoint script to handle environment variable logic\nCOPY ./docker-entrypoint.sh /app/docker-entrypoint.sh\nRUN chmod +x /app/docker-entrypoint.sh\n\n# Define the entrypoint script\nENTRYPOINT [\"/app/docker-entrypoint.sh\"]\n",
        "base_docker_image": "node:20-alpine"
      }
    },
    {
      "name": "MongoDB Lens",
      "repo_url": "https://github.com/furey/mongodb-lens",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:31:57.615533+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 59,
        "forks": 4,
        "watchers": 59,
        "language_stack": [
          "JavaScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MongoDB Lens is a local Model Context Protocol (MCP) server providing full-featured access to MongoDB databases using natural language via LLMs for queries, aggregations, optimization, and more.",
        "tools_exposed": [
          "add-connection-alias",
          "aggregate-data",
          "analyze-query-patterns",
          "analyze-schema",
          "bulk-operations",
          "clear-cache",
          "collation-query",
          "compare-schemas",
          "connect-mongodb",
          "connect-original",
          "count-documents",
          "create-collection",
          "create-database",
          "create-index",
          "create-timeseries",
          "create-user",
          "current-database",
          "delete-document",
          "distinct-values",
          "drop-collection",
          "drop-database",
          "drop-index",
          "drop-user",
          "explain-query",
          "export-data",
          "find-documents",
          "generate-schema-validator",
          "geo-query",
          "get-stats",
          "gridfs-operation",
          "insert-document",
          "list-collections",
          "list-connections"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "cross-env": "^7.0.3",
            "lodash": "^4.17.21",
            "mongodb": "^6.15.0",
            "strip-json-comments": "^5.0.1",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "mongodb-memory-server": "^10.1.4"
          }
        },
        "dockerfile_content": "FROM node:22-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci --production --no-fund --no-audit\n\nCOPY . .\n\nENTRYPOINT [\"node\", \"mongodb-lens.js\"]\n",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "Monday.com",
      "repo_url": "https://github.com/sakce/mcp-server-monday",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:32:18.490411+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 19,
        "forks": 7,
        "watchers": 19,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Server for monday.com, enabling MCP clients to interact with Monday.com boards, items, updates, and documents.",
        "tools_exposed": [
          "monday-create-item",
          "monday-get-board-groups",
          "monday-create-update",
          "monday-list-boards",
          "monday-list-items-in-groups",
          "monday-list-subitems-in-items",
          "monday-create-board",
          "monday-create-board-group",
          "monday-move-item-to-group",
          "monday-delete-item",
          "monday-archive-item",
          "monday-get-item-updates",
          "monday-get-docs",
          "monday-get-doc-content",
          "monday-create-doc",
          "monday-add-doc-block"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.2.1",
            "monday>=2.0.1",
            "requests>=2.32.3",
            "ruff>=0.9.6"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "FROM ghcr.io/astral-sh/uv:python3.10-bookworm AS uv\n\nWORKDIR /app\n\nENV UV_COMPILE_BYTECODE=1\n\nENV UV_LINK_MODE=copy\n\nRUN --mount=type=cache,target=/root/.cache/uv     --mount=type=bind,source=uv.lock,target=uv.lock     --mount=type=bind,source=pyproject.toml,target=pyproject.toml     uv sync --frozen --no-install-project --no-dev --no-editable\n\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv     uv sync --frozen --no-dev --no-editable\n\nFROM python:3.10-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\nENV PATH=\"/app/.venv/bin:$PATH\"\n\nENTRYPOINT [\"mcp-server-monday\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.10-bookworm"
      }
    },
    {
      "name": "Multicluster-MCP-Sever",
      "repo_url": "https://github.com/yanmxa/multicluster-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:32:37.011935+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 1,
        "watchers": 0,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "The Multi-Cluster MCP Server provides a gateway for Generative AI systems to interact with multiple Kubernetes clusters via the Model Context Protocol (MCP), facilitating Kubernetes resource operations, multi-cluster management, and cluster observability.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@kubernetes/client-node": "^1.0.0",
            "@modelcontextprotocol/sdk": "0.6.0"
          },
          "devDependencies": {
            "@babel/core": "^7.26.9",
            "@babel/preset-env": "^7.26.9",
            "@babel/preset-typescript": "^7.26.0",
            "@types/jest": "^29.5.14",
            "@types/node": "^20.11.24",
            "babel-jest": "^29.7.0",
            "jest": "^29.7.0",
            "ts-jest": "^29.2.6",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "MySQL",
      "repo_url": "https://github.com/benborla/mcp-server-mysql",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:32:56.580242+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 148,
        "forks": 28,
        "watchers": 148,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server for MySQL databases, featuring multi-database connectivity and schema-specific permissions for fine-grained control over database operations (INSERT, UPDATE, DELETE, DDL).",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.8.0",
            "dotenv": "^16.4.7",
            "mysql2": "^3.14.0",
            "node-sql-parser": "^5.3.8"
          },
          "devDependencies": {
            "@types/jest": "^29.5.14",
            "@types/node": "^20.17.28",
            "@typescript-eslint/parser": "^7.18.0",
            "eslint": "^8.57.1",
            "shx": "^0.3.4",
            "ts-node": "^10.9.2",
            "tslib": "^2.8.1",
            "typescript": "^5.8.2",
            "vitest": "^1.6.1"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js Alpine image as the base\nFROM node:22-alpine AS builder\n\n# Install pnpm\nRUN npm install -g pnpm\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the package.json and pnpm-lock.yaml if present\nCOPY package.json pnpm-lock.yaml* /app/\n\n# Install the dependencies\nRUN pnpm install --frozen-lockfile --ignore-scripts\n\n# Copy the rest of the application code\nCOPY . /app\n\n# Build the application\nRUN pnpm run build\n\n# Use a new, clean image for the release\nFROM node:22-alpine\n\n# Install pnpm\nRUN npm install -g pnpm\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the built files from the builder\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/\nCOPY --from=builder /app/pnpm-lock.yaml* /app/\n\n# Set environment variables\nENV MYSQL_HOST=127.0.0.1\nENV MYSQL_PORT=3306\nENV MYSQL_USER=root\nENV MYSQL_PASS=\nENV MYSQL_DB=db_name\nENV ALLOW_INSERT_OPERATION=true\nENV ALLOW_UPDATE_OPERATION=true\nENV ALLOW_DELETE_OPERATION=false\n\n# Install production dependencies only\n# Add --no-optional flag to skip lifecycle scripts like prepare\nRUN pnpm install --prod --frozen-lockfile --ignore-scripts\n\n# Expose any ports if necessary (e.g., 8080)\n# EXPOSE 8080\n\n# Run the server\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22-alpine"
      }
    },
    {
      "name": "MySQL",
      "repo_url": "https://github.com/designcomputer/mysql_mcp_server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:33:14.169047+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 251,
        "forks": 71,
        "watchers": 251,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP implementation enabling secure interaction with MySQL databases. It facilitates communication between AI applications and MySQL databases for safer, structured exploration and analysis via a controlled interface.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "mysql-connector-python>=9.1.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use the official Python image from the Docker Hub\nFROM python:3.11-slim\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the requirements file into the container\nCOPY requirements.txt .\n\n# Install the dependencies specified in the requirements file\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy the current directory contents into the container at /app\nCOPY src/ /app/src\n\n# Set environment variables for MySQL (these can be overwritten with `docker run -e`)\nENV MYSQL_HOST=host.docker.internal\nENV MYSQL_PORT=3306\nENV MYSQL_USER=your_username\nENV MYSQL_PASSWORD=your_password\nENV MYSQL_DATABASE=your_database\nENV PYTHONPATH=/app/src\n\n# Command to run the server\nCMD [\"python\", \"-m\", \"mysql_mcp_server.server\"]",
        "base_docker_image": "python:3.11-slim"
      }
    },
    {
      "name": "n8n",
      "repo_url": "https://github.com/leonardsellem/n8n-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:33:34.486230+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 111,
        "forks": 25,
        "watchers": 111,
        "language_stack": [
          "TypeScript",
          "Node.js",
          "Python"
        ],
        "package_manager": [
          "npm",
          "pip"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server that allows AI assistants to interact with n8n workflows through natural language, enabling management of workflows and executions.",
        "tools_exposed": [
          "run_webhook",
          "workflow_list",
          "workflow_get",
          "workflow_create",
          "workflow_update",
          "workflow_delete",
          "workflow_activate",
          "workflow_deactivate",
          "execution_run",
          "execution_get",
          "execution_list",
          "execution_stop"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.7.0",
            "axios": "^1.6.2",
            "dotenv": "^16.3.1"
          },
          "devDependencies": {
            "@babel/core": "^7.26.10",
            "@babel/plugin-transform-modules-commonjs": "^7.26.3",
            "@babel/preset-env": "^7.26.9",
            "@babel/preset-typescript": "^7.26.0",
            "@types/jest": "^29.5.14",
            "@types/node": "^20.10.0",
            "@typescript-eslint/eslint-plugin": "^6.13.1",
            "@typescript-eslint/parser": "^6.13.1",
            "babel-jest": "^29.7.0",
            "eslint": "^8.54.0",
            "jest": "^29.7.0",
            "ts-jest": "^29.1.1",
            "typescript": "^5.3.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "NASA",
      "repo_url": "https://github.com/ProgramComputer/NASA-MCP-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:33:50.633276+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 2,
        "watchers": 10,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server for NASA APIs, providing a standardized interface for AI models to interact with NASA's vast array of data sources.",
        "tools_exposed": [
          "nasa/apod",
          "nasa/mars-rover",
          "nasa/neo",
          "nasa/gibs",
          "nasa/power"
        ],
        "packages": {
          "dependencies": {
            "@anthropic-ai/sdk": "",
            "@modelcontextprotocol/sdk": "^1.7.0",
            "axios": "",
            "cors": "",
            "dotenv": "",
            "express": "",
            "zod": ""
          },
          "devDependencies": {
            "@types/cors": "",
            "@types/express": "",
            "@types/jest": "",
            "@types/node": "",
            "@typescript-eslint/eslint-plugin": "^7.18.0",
            "@typescript-eslint/parser": "^7.18.0",
            "cross-env": "^7.0.3",
            "eslint": "^8.57.1",
            "jest": "",
            "shx": "^0.4.0",
            "ts-jest": "",
            "ts-node": "",
            "typed-rpc": "^6.1.1",
            "typescript": ""
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Nasdaq Data Link",
      "repo_url": "https://github.com/stefanoamorelli/nasdaq-data-link-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:34:07.651165+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 0,
        "watchers": 2,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A community-developed Model Context Protocol (MCP) server that provides access to Nasdaq Data Link, aiming to make its financial and economic datasets easily accessible via natural language interfaces and LLMs using MCP-compatible clients.",
        "tools_exposed": [
          "get_rtat10",
          "get_rtat",
          "get_indicator_value",
          "country_code",
          "list_worldbank_indicators",
          "search_worldbank_indicators",
          "get_stock_stats",
          "list_stock_stat_fields"
        ],
        "packages": {
          "dependencies": [
            "nasdaq-data-link",
            "pycountry"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "National Parks",
      "repo_url": "https://github.com/KyrieTangSheng/mcp-server-nationalparks",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:34:25.273011+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 1,
        "watchers": 5,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Server for the National Park Service (NPS) API, providing real-time information about U.S. National Parks, including park details, alerts, activities, visitor centers, campgrounds, and events.",
        "tools_exposed": [
          "findParks",
          "getParkDetails",
          "getAlerts",
          "getVisitorCenters",
          "getCampgrounds",
          "getEvents"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "axios": "^1.8.4",
            "dotenv": "^16.4.7",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.10",
            "ts-node": "^10.9.2",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\nWORKDIR /app\n\n# Copy package files and install dependencies\nCOPY package*.json ./\n\nRUN npm install --ignore-scripts\n\n# Copy all files\nCOPY . .\n\n# Build the project\nRUN npm run build\n\nCMD [ \"node\", \"build/index.js\" ]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "NAVER",
      "repo_url": "https://github.com/pfldy2850/py-mcp-naver",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:34:44.068842+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 63,
        "forks": 8,
        "watchers": 63,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A server implementation for Naver OpenAPI using the Model Context Protocol (MCP). This project provides tools to interact with various Naver services, such as searching blogs, news, books, and more.",
        "tools_exposed": [
          "search_blog",
          "search_news",
          "search_book",
          "get_book_adv",
          "adult_check",
          "search_encyc",
          "search_cafe_article",
          "search_kin",
          "search_local",
          "fix_spelling",
          "search_webkr",
          "search_image",
          "search_shop",
          "search_doc"
        ],
        "packages": {
          "dependencies": [
            "fastmcp>=0.4.1",
            "httpx>=0.28.1",
            "pydantic>=2.10.6",
            "xmltodict>=0.14.2"
          ],
          "devDependencies": [
            "build>=1.2.2.post1",
            "ruff>=0.11.2",
            "twine>=6.1.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "NS Travel Information",
      "repo_url": "https://github.com/r-huijts/ns-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:35:04.746733+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 22,
        "forks": 5,
        "watchers": 22,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server connects an AI assistant to real-time NS (Nederlandse Spoorwegen) travel information, enabling it to act as a Dutch railways expert for trip planning and status updates.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.6.0",
            "dotenv": "^16.4.7",
            "axios": "^1.7.9",
            "typescript": "^5.7.2"
          },
          "devDependencies": {
            "@types/dotenv": "^6.1.1",
            "@types/node": "^20.11.24",
            "axios": "^1.7.9",
            "dotenv": "^16.4.7",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Stage 1: Build the application\nFROM node:20-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy source files\nCOPY package.json package-lock.json tsconfig.json ./\nCOPY src ./src\n\n# Install dependencies and build the project\nRUN npm install --ignore-scripts && npm run build\n\n# Stage 2: Create the production image\nFROM node:20-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy built files from the builder stage\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\n# Install only production dependencies\nRUN npm ci --omit=dev\n\n# Environment variables\nENV NS_API_KEY=your_api_key_here\n\n# Define the command to run the application\nENTRYPOINT [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:20-alpine"
      }
    },
    {
      "name": "Neo4j",
      "repo_url": "https://github.com/da-okazaki/mcp-neo4j-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:35:19.627600+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 29,
        "forks": 5,
        "watchers": 29,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing integration between Neo4j graph database and Claude Desktop, enabling graph database operations through natural language interactions.",
        "tools_exposed": [
          "execute_query",
          "create_node",
          "create_relationship"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "neo4j-driver": "^5.27.0"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image as the base\nFROM node:22.12-alpine AS builder\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Copy package.json and package-lock.json to the container\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN --mount=type=cache,target=/root/.npm npm install\n\n# Copy the rest of the application code\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the application\nRUN npm run build\n\n# Use a lightweight Node.js image for the final build\nFROM node:22-alpine\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Copy the build output and node_modules from the builder stage\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/node_modules ./node_modules\n\n# Set environment variables\nENV NEO4J_URI=bolt://localhost:7687\nENV NEO4J_USERNAME=neo4j\n# NEO4J_PASSWORD should be set at runtime\n\n# Specify the command to run the application\nENTRYPOINT [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Neovim",
      "repo_url": "https://github.com/bigcodegen/mcp-neovim-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:35:34.627614+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 101,
        "forks": 8,
        "watchers": 101,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This server integrates clients like Claude Desktop with Neovim via MCP, allowing AI assistance by leveraging Vim's native commands and workflows for text editing.",
        "tools_exposed": [
          "vim_buffer",
          "vim_command",
          "vim_status",
          "vim_edit",
          "vim_window",
          "vim_mark",
          "vim_register",
          "vim_visual"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "neovim": "^5.3.0",
            "ts-node": "^10.9.2"
          },
          "devDependencies": {
            "@types/node": "^20.17.23",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Notion",
      "repo_url": "https://github.com/suekou/mcp-notion-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:35:44.509462+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 482,
        "forks": 85,
        "watchers": 482,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Server for the Notion API, enabling Claude to interact with Notion workspaces.",
        "tools_exposed": [
          "notion_append_block_children",
          "notion_retrieve_block",
          "notion_retrieve_block_children",
          "notion_delete_block",
          "notion_retrieve_page",
          "notion_update_page_properties",
          "notion_create_database",
          "notion_query_database",
          "notion_retrieve_database",
          "notion_update_database",
          "notion_create_database_item",
          "notion_search"
        ],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Notion",
      "repo_url": "https://github.com/v-3/notion-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:36:07.339791+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 65,
        "forks": 16,
        "watchers": 65,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server that provides seamless integration with Notion, enabling Language Models to interact with Notion workspaces using standardized tools for page and database operations (search, read, create, update).",
        "tools_exposed": [
          "search_pages",
          "read_page",
          "create_page",
          "update_page",
          "create_database",
          "query_database"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.3",
            "@notionhq/client": "^2.2.15",
            "body-parser": "^1.20.3",
            "dotenv": "^16.4.7",
            "express": "^4.21.2"
          },
          "devDependencies": {
            "@types/node": "^22.10.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "ntfy-mcp",
      "repo_url": "https://github.com/teddyzxcv/ntfy-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:36:23.935394+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 0,
        "watchers": 12,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates with the Model Context Protocol to send ntfy notifications whenever an AI assistant completes a task.",
        "tools_exposed": [
          "notify_user"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "node-fetch": "^3.3.2",
            "dotenv": "^16.4.7",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^22.13.10",
            "@types/node-fetch": "^2.6.12",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "FROM node:23\n\nWORKDIR /app\n\nCOPY package*.json ./\nCOPY package-lock.json ./\n\nRUN npm install\n\nCOPY build ./build\nCOPY src ./src\n\nCMD [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:23"
      }
    },
    {
      "name": "oatpp-mcp",
      "repo_url": "https://github.com/oatpp/oatpp-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:36:40.657449+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 33,
        "forks": 2,
        "watchers": 33,
        "language_stack": [
          "C++",
          "C"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An implementation of Anthropic's Model Context Protocol (MCP) for the Oat++ C++ web framework, featuring automatic tool generation from API controllers.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Oat++",
      "repo_url": "https://oatpp.io",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:36:40.657702+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://oatpp.io"
      }
    },
    {
      "name": "Obsidian Markdown Notes",
      "repo_url": "https://github.com/calclavia/mcp-obsidian",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:36:41.016161+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/calclavia/mcp-obsidian'\nRedirect location: 'https://api.github.com/repositories/895882011'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "obsidian-mcp",
      "repo_url": "https://github.com/StevenStavrakis/obsidian-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:37:01.537021+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 189,
        "forks": 16,
        "watchers": 189,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "Bun"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that enables AI assistants to interact with Obsidian vaults, providing tools for reading, creating, editing and managing notes and tags.",
        "tools_exposed": [
          "read-note",
          "create-note",
          "edit-note",
          "delete-note",
          "move-note",
          "create-directory",
          "search-vault",
          "add-tags",
          "remove-tags",
          "rename-tag",
          "manage-tags",
          "list-available-vaults"
        ],
        "packages": {
          "dependencies": {
            "yaml": "^2.6.1",
            "zod": "^3.22.4",
            "zod-to-json-schema": "^3.24.1"
          },
          "devDependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "@types/node": "^20.0.0",
            "typescript": "^5.0.0",
            "@types/bun": "latest"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "OceanBase",
      "repo_url": "https://github.com/yuanoOo/oceanbase_mcp_server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:37:17.263689+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 1,
        "watchers": 2,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server that enables secure interaction with OceanBase databases, allowing AI assistants to list tables, read data, and execute SQL queries through a controlled interface.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "mysql-connector-python>=9.1.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Okta",
      "repo_url": "https://github.com/kapilduraphe/okta-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:37:30.113651+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6,
        "forks": 2,
        "watchers": 6,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables Claude to interact with Okta's user management system, providing user and group management capabilities.",
        "tools_exposed": [
          "get_user",
          "list_users",
          "list_groups"
        ],
        "packages": {
          "dependencies": {
            "@okta/okta-sdk-nodejs": "^7.0.1",
            "@modelcontextprotocol/sdk": "^1.0.4",
            "dotenv": "^16.4.1",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.11.5",
            "prettier": "^3.2.4",
            "ts-node": "^10.9.2",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "OneNote",
      "repo_url": "https://github.com/rajvirtual/MCP-Servers/tree/master/onenote",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:37:48.867635+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 2,
        "watchers": 0,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server providing AI assistants access to Microsoft OneNote, enabling them to read from and write to OneNote notebooks, sections, and pages using the Microsoft Graph API.",
        "tools_exposed": [
          "onenote-read",
          "onenote-create"
        ],
        "packages": {
          "dependencies": {
            "@azure/identity": "^3.3.2",
            "@microsoft/microsoft-graph-client": "3.0.7",
            "html-to-text": "^9.0.5"
          },
          "devDependencies": {
            "@microsoft/microsoft-graph-types": "^2.38.0",
            "@modelcontextprotocol/sdk": "^0.4.0",
            "@types/html-to-text": "^9.0.4",
            "@types/node": "^20.11.19",
            "ts-node": "^10.9.2",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "FROM node:20-alpine\n\nWORKDIR /app\n\n# Install dependencies\nCOPY package*.json ./\nRUN npm install\n\n# Copy source code\nCOPY . .\n\n# Build TypeScript code\nRUN npm run build\n\n# Create a directory for token cache and device code\nRUN mkdir -p /app/dist\n\n\n# Set environment variables\nENV NODE_ENV=production\n\n# Run the application\nCMD [\"node\", \"dist/index.js\"] ",
        "base_docker_image": "node:20-alpine"
      }
    },
    {
      "name": "OpenAI WebSearch MCP",
      "repo_url": "https://github.com/ConechoAI/openai-websearch-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:05.647107+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 29,
        "forks": 3,
        "watchers": 29,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides access to OpenAI's websearch functionality through the Model Context Protocol, allowing AI assistants to search the web for up-to-date information.",
        "tools_exposed": [
          "web_search"
        ],
        "packages": {
          "dependencies": [
            "pydantic_extra_types==2.10.3",
            "pydantic==2.10.6",
            "mcp==1.3.0",
            "tzdata==2025.1",
            "openai==1.66.2",
            "typer==0.15.2"
          ],
          "devDependencies": [
            "pydantic_extra_types==2.10.3",
            "pydantic==2.10.6",
            "mcp==1.3.0",
            "tzdata==2025.1",
            "openai==1.66.2",
            "typer==0.15.2"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "OpenAPI",
      "repo_url": "https://github.com/snaggle-ai/openapi-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:05.851329+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/snaggle-ai/openapi-mcp-server'\nRedirect location: 'https://api.github.com/repositories/900049352'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "OpenAPI",
      "repo_url": "https://www.openapis.org/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:05.851480+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.openapis.org/"
      }
    },
    {
      "name": "OpenAPI AnyApi",
      "repo_url": "https://github.com/baryhuang/mcp-server-any-openapi",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:26.327880+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 21,
        "forks": 4,
        "watchers": 21,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server designed to handle large OpenAPI specifications by using semantic search for endpoint discovery and providing a tool to make the actual API requests.",
        "tools_exposed": [
          "{prefix}_api_request_schema",
          "{prefix}_make_request"
        ],
        "packages": {
          "dependencies": [
            "mcp",
            "pydantic",
            "requests",
            "pytz",
            "pyyaml",
            "faiss-cpu",
            "numpy",
            "sentence-transformers",
            "fastapi",
            "uvicorn",
            "huggingface-hub"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# --------\n# Builder stage\n# --------\nFROM python:3.11-slim AS builder\n\n# Install build tools and dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    gcc \\\n    g++ \\\n    libc6-dev \\\n    libffi-dev \\\n    libpq-dev \\\n    make \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set working directory for builder\nWORKDIR /app\n\n# Copy the entire project first\nCOPY . /app/\n\n# Upgrade pip and build wheels for all dependencies\nRUN pip install --upgrade pip \\\n    && mkdir /wheels \\\n    && pip wheel --wheel-dir=/wheels -r requirements.txt\n\n# --------\n# Final runtime stage\n# --------\nFROM python:3.11-slim\n\n# Install runtime dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    libffi-dev \\\n    libpq-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\n# Copy the entire project\nCOPY . /app/\n\n# Copy the wheels built in the builder stage\nCOPY --from=builder /wheels /wheels\n\n# Install Python dependencies from the local wheel cache\nRUN pip install --upgrade pip \\\n    && pip install --no-cache-dir --no-index --find-links=/wheels -r requirements.txt\n\n# Create models directory\nRUN mkdir -p /app/models\n\n# Pre-download models\nRUN python -c \"from sentence_transformers import SentenceTransformer; \\\n    model = SentenceTransformer('all-MiniLM-L6-v2'); \\\n    model.save('/app/models/all-MiniLM-L6-v2')\"\n\n# Set environment variables\nENV SENTENCE_TRANSFORMERS_HOME=/app/models\nENV PYTHONPATH=/app/src\n\n# Expose port\nEXPOSE 8000\n\n# Run the server directly\nENTRYPOINT [\"python\", \"src/mcp_server_any_openapi/server.py\"]\n",
        "base_docker_image": "python:3.11-slim"
      }
    },
    {
      "name": "OpenAPI",
      "repo_url": "https://www.openapis.org/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:26.328161+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.openapis.org/"
      }
    },
    {
      "name": "OpenAPI Schema",
      "repo_url": "https://github.com/hannesj/mcp-openapi-schema",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:41.239756+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 14,
        "forks": 2,
        "watchers": 14,
        "language_stack": [
          "JavaScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "An MCP server that exposes OpenAPI schema information, allowing Large Language Models (LLMs) like Claude to explore and understand API specifications through a set of specialized tools.",
        "tools_exposed": [
          "list-endpoints",
          "get-endpoint",
          "get-request-body",
          "get-response-schema",
          "get-path-parameters",
          "list-components",
          "get-component",
          "list-security-schemes",
          "get-examples",
          "search-schema"
        ],
        "packages": {
          "dependencies": {
            "@apidevtools/swagger-parser": "^10.1.1",
            "@modelcontextprotocol/sdk": "^1.7.0",
            "js-yaml": "^4.1.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "OpenAPI",
      "repo_url": "https://www.openapis.org/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:41.240060+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.openapis.org/"
      }
    },
    {
      "name": "OpenCTI",
      "repo_url": "https://github.com/Spathodea-Network/opencti-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:38:58.867295+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 7,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing seamless integration with the OpenCTI (Open Cyber Threat Intelligence) platform, enabling the querying and retrieval of threat intelligence data through a standardized interface.",
        "tools_exposed": [
          "get_latest_reports",
          "get_report_by_id",
          "search_malware",
          "search_indicators",
          "search_threat_actors",
          "get_user_by_id",
          "list_users",
          "list_groups",
          "list_attack_patterns",
          "get_campaign_by_name",
          "list_connectors",
          "list_status_templates",
          "get_file_by_id",
          "list_files",
          "list_marking_definitions",
          "list_labels"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "axios": "^1.7.9"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image with the appropriate version\nFROM node:16-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json for dependency installation\nCOPY package.json package.json\n\n# Install dependencies\nRUN npm install --ignore-scripts\n\n# Copy the rest of the application source code\nCOPY . .\n\n# Build the TypeScript project\nRUN npm run build\n\n# Prepare the runtime environment\nFROM node:16-alpine AS release\n\n# Set working directory\nWORKDIR /app\n\n# Copy built files and necessary configuration\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\n\n# Set environment variables\nENV OPENCTI_URL=https://your-opencti-url\nENV OPENCTI_TOKEN=your-opencti-token\n\n# Run the server\nENTRYPOINT [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:16-alpine"
      }
    },
    {
      "name": "OpenDota",
      "repo_url": "https://github.com/asusevski/opendota-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:39:19.519588+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 2,
        "watchers": 4,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server implementation for accessing OpenDota API data, enabling LLMs and AI assistants to retrieve real-time Dota 2 statistics, match data, player information, and more.",
        "tools_exposed": [
          "get_player_by_id",
          "get_player_recent_matches",
          "get_match_data",
          "get_player_win_loss",
          "get_player_heroes",
          "get_hero_stats",
          "search_player",
          "get_pro_players",
          "get_pro_matches",
          "get_player_peers",
          "get_heroes",
          "get_player_totals",
          "get_player_rankings",
          "get_player_wordcloud",
          "get_team_info",
          "get_public_matches",
          "get_match_heroes"
        ],
        "packages": {
          "dependencies": [
            "aiohttp>=3.11.12",
            "anthropic>=0.46.0",
            "black>=24.10.0",
            "dnspython>=2.7.0",
            "fastapi>=0.115.8",
            "httpx>=0.28.1",
            "huggingface-hub>=0.28.1",
            "isort>=5.13.2",
            "itsdangerous>=2.2.0",
            "jinja2>=3.1.5",
            "mcp[cli]>=1.2.1",
            "motor>=3.7.0",
            "pydantic-settings>=2.7.1",
            "pymongo>=4.11.1",
            "pyproject-toml>=0.1.0",
            "pytest",
            "python-dotenv>=1.0.1",
            "streamlit",
            "uuid>=1.30"
          ],
          "devDependencies": [
            "black==24.10.0",
            "ruff==0.8.0",
            "isort==5.13.2",
            "pyright==1.1.389"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "OpenRPC",
      "repo_url": "https://github.com/shanejonas/openrpc-mpc-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:39:32.297626+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 31,
        "forks": 7,
        "watchers": 31,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that provides JSON-RPC functionality through OpenRPC, allowing calling arbitrary methods and discovering available methods on a server.",
        "tools_exposed": [
          "rpc_call",
          "rpc_discover"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "@open-rpc/client-js": "^1.8.1"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "OpenRPC",
      "repo_url": "https://open-rpc.org",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:39:32.298028+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://open-rpc.org"
      }
    },
    {
      "name": "Open Strategy Partners Marketing Tools",
      "repo_url": "https://github.com/open-strategy-partners/osp_marketing_tools",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:39:51.684494+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 125,
        "forks": 15,
        "watchers": 125,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Provides a suite of tools for technical marketing content creation, optimization, and product positioning based on Open Strategy Partners' methodologies, utilizing the Model Context Protocol (MCP).",
        "tools_exposed": [
          "OSP Product Value Map Generator",
          "OSP Meta Information Generator",
          "OSP Content Editing Codes",
          "OSP Technical Writing Guide",
          "OSP On-Page SEO Guide"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]",
            "aiohttp==3.11.11"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Start with a base image that has Python and uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Set the working directory\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Specify the UV link mode\nENV UV_LINK_MODE=copy\n\n# Copy the pyproject.toml file to the working directory\nCOPY pyproject.toml /app/\n\n# Use uv to install dependencies\nRUN --mount=type=cache,target=/root/.cache/uv uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Copy the entire project into the working directory\nADD . /app\n\n# Use uv to finalize the installation\nRUN --mount=type=cache,target=/root/.cache/uv uv sync --frozen --no-dev --no-editable\n\n# Start a new stage to keep the final image small\nFROM python:3.12-slim-bookworm\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the necessary files from the uv stage\nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Update the PATH environment variable to include the virtual environment binaries\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Set the entry point to run the MCP server\nENTRYPOINT [\"python\", \"src/osp_marketing_tools/server.py\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Pandoc",
      "repo_url": "https://github.com/vivekVells/mcp-pandoc",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:40:07.114976+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 136,
        "forks": 23,
        "watchers": 136,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "An MCP server for document format conversion using pandoc. It transforms content between various formats (markdown, html, pdf, docx, rst, latex, epub, txt) while aiming to preserve structure.",
        "tools_exposed": [
          "convert-contents"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.1.0",
            "pandoc>=2.4",
            "pypandoc>=1.14"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "PIF",
      "repo_url": "https://github.com/hungryrobot1/MCP-PIF",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:40:21.726870+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 19,
        "forks": 6,
        "watchers": 19,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This server implements the Model Context Protocol (MCP) as a practical embodiment of the Personal Intelligence Framework (PIF), using structured tools and progressive interaction patterns to create spaces for meaningful development of understanding between humans and AI.",
        "tools_exposed": [
          "pwd",
          "cd",
          "read",
          "write",
          "mkdir",
          "delete",
          "move",
          "rename",
          "reason",
          "think",
          "journal_create",
          "journal_read"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.3.2",
            "simple-git": "^3.27.0",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@types/node": "^22.10.7",
            "@types/vscode": "^1.85.0",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Pinecone",
      "repo_url": "https://github.com/sirmews/mcp-pinecone",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:40:43.290422+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 101,
        "forks": 17,
        "watchers": 101,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Read and write to a Pinecone index.",
        "tools_exposed": [
          "semantic-search",
          "read-document",
          "list-documents",
          "pinecone-stats",
          "process-document"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.0",
            "jsonschema>=4.23.0",
            "mcp>=1.0.0",
            "pinecone>=5.4.1",
            "python-dotenv>=1.0.1",
            "tiktoken>=0.8.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the project files to the working directory\nADD . /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Sync the dependencies and lockfile\nRUN --mount=type=cache,target=/root/.cache/uv     --mount=type=bind,source=uv.lock,target=uv.lock     --mount=type=bind,source=pyproject.toml,target=pyproject.toml     uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Install the project\nRUN --mount=type=cache,target=/root/.cache/uv     uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Entry point for running the MCP server\nENTRYPOINT [\"uv\", \"run\", \"mcp-pinecone\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Placid.app",
      "repo_url": "https://github.com/felores/placid-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:41:02.014839+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6,
        "forks": 2,
        "watchers": 6,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server implementation for integrating with Placid.app's API. This server provides tools for listing templates and generating images and videos through the Model Context Protocol.",
        "tools_exposed": [
          "placid_list_templates",
          "placid_generate_video",
          "placid_generate_image"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "dotenv": "^16.4.7"
          },
          "devDependencies": {
            "@types/jest": "^29.0.0",
            "@types/node": "^20.17.28",
            "jest": "^29.0.0",
            "ts-jest": "^29.3.0",
            "ts-node-dev": "^2.0.0",
            "typescript": "^5.0.0"
          }
        },
        "dockerfile_content": "# Use the official Node.js 16 image as the base image\nFROM node:16-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the package.json and package-lock.json files\nCOPY package.json package-lock.json ./\n\n# Install the dependencies\nRUN npm install\n\n# Copy the rest of the application source code\nCOPY . .\n\n# Build the application\nRUN npm run build\n\n# Use a lighter base image for the runtime\nFROM node:16-alpine AS release\n\n# Set the working directory\nWORKDIR /app\n\n# Copy only the necessary files from the builder stage\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/node_modules /app/node_modules\nCOPY --from=builder /app/package.json /app/package.json\n\n# Set environment variables\nENV NODE_ENV=production\n\n# Define the command to run the application\nENTRYPOINT [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:16-alpine"
      }
    },
    {
      "name": "Playwright",
      "repo_url": "https://github.com/executeautomation/mcp-playwright",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:41:21.506475+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2529,
        "forks": 194,
        "watchers": 2529,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol server using Playwright for browser automation, enabling LLMs to interact with web pages, take screenshots, generate test code, web scrape pages, and execute JavaScript in a real browser environment.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.6.1",
            "@playwright/browser-chromium": "1.51.1",
            "@playwright/browser-firefox": "1.51.1",
            "@playwright/browser-webkit": "1.51.1",
            "playwright": "1.51.1",
            "@playwright/test": "^1.51.1",
            "uuid": "^9.0.1"
          },
          "devDependencies": {
            "@types/jest": "^29.5.14",
            "@types/node": "^20.10.5",
            "jest": "^29.7.0",
            "jest-playwright-preset": "^4.0.0",
            "shx": "^0.3.4",
            "ts-jest": "^29.2.6",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use Node.js image for building the project\nFROM node:20-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package.json package-lock.json ./\n\n# Install dependencies without running scripts to prevent automatic build\nRUN npm install --ignore-scripts\n\n# Copy the entire source directory\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the project\nRUN npm run build\n\n# Use a minimal Node.js image for running the project\nFROM node:20-alpine AS release\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the built files from the builder stage\nCOPY --from=builder /app/dist ./dist\nCOPY --from=builder /app/package.json ./package.json\nCOPY --from=builder /app/package-lock.json ./package-lock.json\n\n# Install production dependencies\nRUN npm ci --ignore-scripts --omit=dev\n\n# Set the command to run the server\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:20-alpine"
      }
    },
    {
      "name": "Postman",
      "repo_url": "https://github.com/shannonlal/mcp-postman",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:41:39.410366+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 37,
        "forks": 4,
        "watchers": 37,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm",
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": true,
        "server_description": "An MCP server that enables running Postman collections using Newman, allowing LLMs to execute API tests and get detailed results through a standardized interface.",
        "tools_exposed": [
          "run-collection"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "latest",
            "newman": "^6.0.0",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/express": "^4.17.21",
            "@types/newman": "^5.3.0",
            "@types/node": "^20.0.0",
            "@typescript-eslint/eslint-plugin": "^6.0.0",
            "@typescript-eslint/parser": "^6.0.0",
            "@vitest/coverage-v8": "^1.0.0",
            "axios": "^1.7.9",
            "cross-env": "^7.0.3",
            "eslint": "^8.0.0",
            "eslint-config-prettier": "^9.0.0",
            "express": "^4.18.2",
            "husky": "^9.1.7",
            "lint-staged": "^15.3.0",
            "nodemon": "3.1.9",
            "prettier": "^3.0.0",
            "ts-node": "^10.9.0",
            "typescript": "^5.0.0",
            "vitest": "^1.0.0"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image\nFROM node:18-alpine AS builder\n\n# Install pnpm\nRUN npm install -g pnpm\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and pnpm-lock.yaml to leverage Docker cache for dependencies\nCOPY package.json pnpm-lock.yaml ./\n\n# Install dependencies\nRUN pnpm install\n\n# Copy the source code\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the project\nRUN pnpm build\n\n# Use a smaller Node.js image for running the application\nFROM node:18-alpine\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the built files and package.json\nCOPY --from=builder /app/build ./build\nCOPY --from=builder /app/package.json ./\n\n# Install only production dependencies\nRUN pnpm install --prod\n\n# Set the entry point for the application\nENTRYPOINT [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "Productboard",
      "repo_url": "https://github.com/kenjihikmatullah/productboard-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:41:53.932814+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 2,
        "watchers": 5,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Integrate the Productboard API into agentic workflows via MCP.",
        "tools_exposed": [
          "get_companies",
          "get_company_detail",
          "get_components",
          "get_component_detail",
          "get_features",
          "get_feature_detail",
          "get_feature_statuses",
          "get_notes",
          "get_products",
          "get_product_detail"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.0"
          },
          "devDependencies": {
            "@types/node": "^22.13.5",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Prometheus",
      "repo_url": "https://github.com/pab1it0/prometheus-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:42:10.924716+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 19,
        "forks": 4,
        "watchers": 19,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server for Prometheus that provides access to Prometheus metrics and queries through standardized MCP interfaces, allowing AI assistants to execute PromQL queries and analyze metrics data.",
        "tools_exposed": [
          "execute_query",
          "execute_range_query",
          "list_metrics",
          "get_metric_metadata",
          "get_targets"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]",
            "prometheus-api-client",
            "python-dotenv",
            "pyproject-toml>=0.1.0",
            "requests"
          ],
          "devDependencies": [
            "pytest>=7.0.0",
            "pytest-cov>=4.0.0",
            "pytest-asyncio>=0.21.0",
            "pytest-mock>=3.10.0"
          ]
        },
        "dockerfile_content": "FROM python:3.12-slim-bookworm AS builder\n\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n\nWORKDIR /app\n\nENV UV_COMPILE_BYTECODE=1\n\nCOPY pyproject.toml ./\nCOPY uv.lock ./\nCOPY src ./src/\n\nRUN uv venv && \\\n    uv pip install -e .\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n\nRUN groupadd -r app && useradd -r -g app app\n\nCOPY --from=builder /app/.venv /app/.venv\nCOPY --from=builder /app/src /app/src\nCOPY pyproject.toml /app/\n\nENV PATH=\"/app/.venv/bin:$PATH\" \\\n    PYTHONUNBUFFERED=1 \\\n    PYTHONDONTWRITEBYTECODE=1 \\\n    PYTHONPATH=\"/app\" \\\n    PYTHONFAULTHANDLER=1\n\nUSER app\n\nEXPOSE 8000\n\nHEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n\nCMD [\"/app/.venv/bin/prometheus-mcp-server\"]\n\n# GitHub Container Registry Metadata\nLABEL org.opencontainers.image.title=\"Prometheus MCP Server\" \\\n      org.opencontainers.image.description=\"Model Context Protocol server for Prometheus integration\" \\\n      org.opencontainers.image.version=\"1.0.0\" \\\n      org.opencontainers.image.authors=\"Pavel Shklovsky\" \\\n      org.opencontainers.image.source=\"https://github.com/pab1it0/prometheus-mcp-server\" \\\n      org.opencontainers.image.licenses=\"MIT\" \\\n      org.opencontainers.image.url=\"https://github.com/pab1it0/prometheus-mcp-server\" \\\n      org.opencontainers.image.documentation=\"https://github.com/pab1it0/prometheus-mcp-server#readme\" \\\n      org.opencontainers.image.vendor=\"Pavel Shklovsky\"",
        "base_docker_image": "python:3.12-slim-bookworm"
      }
    },
    {
      "name": "Pulumi",
      "repo_url": "https://github.com/dogukanakkaya/pulumi-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:42:21.849319+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 0,
        "watchers": 2,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "dotenv": "^16.4.7",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.10",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\nWORKDIR /app\n\n# Copy package files and install dependencies\nCOPY package*.json ./\nRUN npm install --ignore-scripts\n\n# Copy the rest of the code\nCOPY . .\n\n# Build the TypeScript source code\nRUN npm run build\n\n# Expose port if needed (not required for stdio-based MCP)\n\n# Run the MCP server\nCMD [ \"npm\", \"start\" ]\n",
        "base_docker_image": "node:lts-alpine",
        "error": "Gemini analysis error: README analysis error: Empty README content"
      }
    },
    {
      "name": "Pushover",
      "repo_url": "https://github.com/ashiknesin/pushover-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:42:37.878306+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 1,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This Model Context Protocol (MCP) server enables AI agents to send notifications via Pushover.net.",
        "tools_exposed": [
          "send"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "commander": "^13.1.0",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "tsx": "^4.7.1",
            "typescript": "^5.3.3",
            "vitest": "^1.3.1"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\n# Install global dependencies\nRUN npm install -g pnpm\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package.json pnpm-lock.yaml ./\n\n# Install dependencies without running scripts\nRUN pnpm install --ignore-scripts\n\n# Copy source code\nCOPY . .\n\n# Build the project\nRUN pnpm build\n\n# Define the startup command\nCMD [\"node\", \"dist/cli.js\", \"start\"]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "Pushover.net",
      "repo_url": "https://pushover.net/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:42:37.878583+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://pushover.net/"
      }
    },
    {
      "name": "QGIS",
      "repo_url": "https://github.com/jjsantos01/qgis_mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:42:55.885864+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 411,
        "forks": 45,
        "watchers": 411,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "Connects QGIS to Claude AI via the Model Context Protocol (MCP), allowing Claude to directly interact with and control QGIS. This enables prompt assisted project creation, layer loading, code execution, and more.",
        "tools_exposed": [
          "ping",
          "get_qgis_info",
          "load_project",
          "create_new_project",
          "get_project_info",
          "add_vector_layer",
          "add_raster_layer",
          "get_layers",
          "remove_layer",
          "zoom_to_layer",
          "get_layer_features",
          "execute_processing",
          "save_project",
          "render_map",
          "execute_code"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "QuickChart",
      "repo_url": "https://github.com/GongRzhe/Quickchart-MCP-Server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:43:10.660392+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 2,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that generates various types of charts using QuickChart.io by converting Chart.js configurations into chart URLs or downloadable images.",
        "tools_exposed": [
          "generate_chart",
          "download_chart"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.6.0",
            "axios": "^1.7.9"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\n# Create app directory\nWORKDIR /app\n\n# Install app dependencies\nCOPY package*.json ./\nRUN npm install --ignore-scripts\n\n# Bundle app source\nCOPY . .\n\n# Build the TypeScript source\nRUN npm run build\n\n# Expose port if needed (not strictly needed for stdio services)\n\n# Run the MCP server\nCMD [ \"node\", \"./build/index.js\" ]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "Qwen_Max",
      "repo_url": "https://github.com/66julienmartin/MCP-server-Qwen_Max",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:43:26.577605+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 3,
        "watchers": 10,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation for the Qwen Max language model.",
        "tools_exposed": [
          "qwen_max"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "dotenv": "^16.4.7",
            "openai": "^4.80.1"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use Node.js 18 as the base image\nFROM node:18-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN npm install\n\n# Copy the rest of the application code\nCOPY src ./src\nCOPY tsconfig.json ./\n\n# Build the application\nRUN npx tsc\n\n# Create the runtime image\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Copy built application from the builder stage\nCOPY --from=builder /app/build ./build\nCOPY package.json package-lock.json ./\n\n# Install production dependencies\nRUN npm install --production\n\n# Copy .env file (or ensure it's mounted at runtime)\nCOPY .env ./\n\n# Expose necessary ports (if any are known; adjust as needed)\nEXPOSE 3000\n\n# Define the default command\nCMD [\"node\", \"build/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "RabbitMQ",
      "repo_url": "https://github.com/kenliao94/mcp-server-rabbitmq",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:43:47.498638+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 12,
        "forks": 2,
        "watchers": 12,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server implementation for RabbitMQ, enabling MCP clients to interact with queues and topics hosted in a RabbitMQ instance.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "markdownify>=0.13.1",
            "mcp>=1.1.2",
            "pika>=1.3.2",
            "protego>=0.3.1",
            "pydantic>=2.0.0",
            "readabilipy>=0.2.0",
            "requests>=2.32.3"
          ],
          "devDependencies": [
            "pyright>=1.1.389",
            "ruff>=0.7.3"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"mcp-server-rabbitmq\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "RAG Web Browser",
      "repo_url": "https://github.com/apify/mcp-server-rag-web-browser",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:44:04.670054+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 102,
        "forks": 10,
        "watchers": 102,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server designed to enable AI agents and LLMs to interact with the web and extract information from web pages by communicating locally with the RAG Web Browser Actor.",
        "tools_exposed": [
          "search"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "express": "^4.21.2",
            "node-fetch": "^3.3.2",
            "zod": "^3.24.1",
            "zod-to-json-schema": "^3.24.1"
          },
          "devDependencies": {
            "@apify/eslint-config": "^0.5.0-beta.7",
            "@apify/eslint-config-ts": "^0.4.1",
            "@apify/tsconfig": "^0.1.0",
            "@types/express": "^5.0.0",
            "@types/node": "^20.11.24",
            "dotenv": "^16.4.7",
            "eslint": "^9.22.0",
            "tsx": "^4.6.2",
            "typescript": "^5.3.3",
            "typescript-eslint": "^8.18.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Actor",
      "repo_url": "https://apify.com/apify/rag-web-browser",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:44:04.670329+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://apify.com/apify/rag-web-browser"
      }
    },
    {
      "name": "Reaper",
      "repo_url": "https://github.com/dschuler36/reaper-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:44:19.060919+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 21,
        "forks": 2,
        "watchers": 21,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server connects a Reaper project to an MCP client like Claude Desktop, enabling users to ask questions about the project.",
        "tools_exposed": [
          "find_reaper_projects",
          "parse_reaper_project"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.2.0",
            "asyncio>=3.4.3",
            "pytest>=8.3.4"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.10-slim"
      }
    },
    {
      "name": "Reaper",
      "repo_url": "https://www.reaper.fm/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:44:19.061239+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.reaper.fm/"
      }
    },
    {
      "name": "Redis",
      "repo_url": "https://github.com/GongRzhe/REDIS-MCP-Server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:44:35.732674+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 21,
        "forks": 3,
        "watchers": 21,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Redis Model Context Protocol (MCP) server implementation for interacting with Redis databases, enabling LLMs to use Redis key-value stores via standardized tools.",
        "tools_exposed": [
          "set",
          "get",
          "delete",
          "list"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.4.0",
            "@types/redis": "^4.0.10",
            "redis": "^4.7.0"
          },
          "devDependencies": {
            "@types/node": "^22.10.2",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine as builder\n\nCOPY src/redis /app\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nRUN npm run build\n\nFROM node:22-alpine AS release\n\nCOPY --from=builder /app/build /app/build\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nWORKDIR /app\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Redis",
      "repo_url": "https://github.com/prajwalnayak7/mcp-server-redis",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:44:54.691934+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 15,
        "forks": 1,
        "watchers": 15,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This server provides a foundation for Redis integration through MCP, offering tools for basic operations, list, hash, set, and pub/sub commands.",
        "tools_exposed": [
          "get_value",
          "set_value",
          "delete_key",
          "increment",
          "list_push",
          "list_range",
          "hash_set",
          "hash_get",
          "set_add",
          "set_members",
          "publish_message"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.2.1",
            "python-dotenv>=1.0.1",
            "redis>=5.2.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Set the working directory\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv     --mount=type=bind,source=uv.lock,target=uv.lock     --mount=type=bind,source=pyproject.toml,target=pyproject.toml     uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Add the rest of the project source code and install it\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv     uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Run the server\nENTRYPOINT [\"python\", \"src/main.py\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Rememberizer AI",
      "repo_url": "https://github.com/skydeckai/mcp-server-rememberizer",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:45:13.531721+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 19,
        "forks": 1,
        "watchers": 19,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server for interacting with Rememberizer's document and knowledge management API, enabling Large Language Models to search, retrieve, and manage documents and integrations.",
        "tools_exposed": [
          "retrieve_semantically_similar_internal_knowledge",
          "smart_search_internal_knowledge",
          "list_internal_knowledge_systems",
          "rememberizer_account_information",
          "list_personal_team_knowledge_documents",
          "remember_this"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.27.2",
            "mcp>=1.0.0",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": [
            "pyright>=1.1.389"
          ]
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Start with the base Python image\nFROM python:3.11-slim-bookworm\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the project files into the container\nCOPY . .\n\n# Install the necessary dependencies\nRUN pip install --no-cache-dir --upgrade pip \\\n    && pip install --no-cache-dir .\n\n# Set the environment variable for the Rememberizer API token\n# It is recommended to set this as a secret in production environments\nENV REMEMBERIZER_API_TOKEN=your_rememberizer_api_token\n\n# The command to run your application\nENTRYPOINT [\"python\", \"-m\", \"mcp_server_rememberizer.server\"]\n",
        "base_docker_image": "python:3.11-slim-bookworm"
      }
    },
    {
      "name": "Replicate",
      "repo_url": "https://github.com/deepfates/mcp-replicate",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:45:32.599535+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 41,
        "forks": 8,
        "watchers": 41,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation for Replicate, allowing users to run Replicate models through a simple tool-based interface.",
        "tools_exposed": [
          "search_models",
          "list_models",
          "get_model",
          "list_collections",
          "get_collection",
          "create_prediction",
          "get_prediction",
          "cancel_prediction",
          "list_predictions",
          "view_image",
          "clear_image_cache",
          "get_image_cache_stats"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.6.0",
            "replicate": "^1.0.1"
          },
          "devDependencies": {
            "@biomejs/biome": "^1.5.3",
            "@types/node": "^20.11.5",
            "typescript": "^5.3.3",
            "vitest": "^1.2.1"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": "node:18"
      }
    },
    {
      "name": "Rquest",
      "repo_url": "https://github.com/xxxbrian/mcp-rquest",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:45:53.005854+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 13,
        "forks": 1,
        "watchers": 13,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing advanced HTTP request capabilities with realistic browser emulation for LLMs like Claude, enabling interaction with websites and bypassing anti-bot measures. It supports various HTTP methods and conversion of HTML/PDF content to Markdown.",
        "tools_exposed": [
          "http_get",
          "http_post",
          "http_put",
          "http_delete",
          "http_patch",
          "http_head",
          "http_options",
          "http_trace",
          "get_stored_response",
          "get_stored_response_with_markdown",
          "get_model_state",
          "restart_model_loading"
        ],
        "packages": {
          "dependencies": [
            "markdownify>=0.13.1,<0.14.0",
            "mcp[cli]>=1.4.1",
            "rnet>=2.0.0",
            "tiktoken>=0.5.0",
            "marker-pdf>=1.6.1"
          ],
          "devDependencies": [
            "ruff>=0.0.292",
            "pytest>=7.0.0",
            "pytest-asyncio>=0.21.1",
            "black>=23.9.1",
            "build>=1.0.3",
            "twine>=6.1.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Rijksmuseum",
      "repo_url": "https://github.com/r-huijts/rijksmuseum-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:46:08.739368+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 39,
        "forks": 8,
        "watchers": 39,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing access to the Rijksmuseum's collection via natural language interactions, enabling AI models to explore, analyze, and interact with artworks and collections.",
        "tools_exposed": [
          "search_artwork",
          "get_artwork_details",
          "get_artwork_image",
          "get_user_sets",
          "get_user_set_details",
          "open_image_in_browser",
          "get_artist_timeline"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "axios": "^1.7.9",
            "dotenv": "^16.4.7"
          },
          "devDependencies": {
            "@types/node": "^18.0.0",
            "typescript": "^5.0.0"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Salesforce MCP",
      "repo_url": "https://github.com/smn2gnt/MCP-Salesforce",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:46:25.415288+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 41,
        "forks": 11,
        "watchers": 41,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for Salesforce integration, allowing LLMs to interact with Salesforce data through SOQL queries, SOSL searches, metadata retrieval, record manipulation (CRUD), Tooling API requests, Apex REST requests, and direct REST API calls.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp",
            "simple-salesforce",
            "python-dotenv"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Scholarly",
      "repo_url": "https://github.com/adityak74/mcp-scholarly",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:46:41.765969+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 72,
        "forks": 9,
        "watchers": 72,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": true,
        "has_tests": false,
        "server_description": "This MCP server searches for accurate academic articles.",
        "tools_exposed": [
          "search-arxiv"
        ],
        "packages": {
          "dependencies": [
            "arxiv>=2.1.3",
            "free-proxy>=1.1.3",
            "mcp>=1.1.2",
            "scholarly>=1.7.11"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"mcp-scholarly\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "scrapling-fetch",
      "repo_url": "https://github.com/cyberchitta/scrapling-fetch-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:47:02.439578+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 1,
        "watchers": 10,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that helps AI assistants access text content from websites that implement bot detection, bridging the gap between browser visibility and AI accessibility.",
        "tools_exposed": [
          "s-fetch-page",
          "s-fetch-pattern"
        ],
        "packages": {
          "dependencies": [
            "beautifulsoup4>=4.13.3",
            "lxml>=5.3.1",
            "markdownify>=1.1.0",
            "mcp>=1.4.0",
            "packaging>=24.1, <25.0",
            "scrapling>=0.2.98"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "SearXNG",
      "repo_url": "https://github.com/ihor-sokoliuk/mcp-searxng",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:47:16.852157+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 43,
        "forks": 8,
        "watchers": 43,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that integrates the SearxNG API, providing web search capabilities.",
        "tools_exposed": [
          "searxng_web_search"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.0.1",
            "node-html-markdown": "^1.3.0"
          },
          "devDependencies": {
            "@types/node": "^22.10.2",
            "shx": "^0.3.4",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\n# Must be entire project because `prepare` script is run during `npm install` and requires all files.\nCOPY ./ /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "SearXNG",
      "repo_url": "https://docs.searxng.org",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:47:16.852435+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://docs.searxng.org"
      }
    },
    {
      "name": "ServiceNow",
      "repo_url": "https://github.com/osomai/servicenow-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:47:40.262034+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 31,
        "forks": 20,
        "watchers": 31,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": true,
        "has_tests": true,
        "server_description": "An MCP server implementation allowing Claude to interact with ServiceNow instances, retrieve data, and perform actions via the ServiceNow API.",
        "tools_exposed": [
          "create_incident",
          "update_incident",
          "add_comment",
          "resolve_incident",
          "list_incidents",
          "list_catalog_items",
          "get_catalog_item",
          "list_catalog_categories",
          "create_catalog_category",
          "update_catalog_category",
          "move_catalog_items",
          "create_catalog_item_variable",
          "list_catalog_item_variables",
          "update_catalog_item_variable",
          "get_optimization_recommendations",
          "update_catalog_item",
          "create_change_request",
          "update_change_request",
          "list_change_requests",
          "get_change_request_details",
          "add_change_task",
          "submit_change_for_approval",
          "approve_change",
          "reject_change",
          "list_workflows",
          "get_workflow",
          "create_workflow",
          "update_workflow",
          "delete_workflow",
          "list_script_includes",
          "get_script_include",
          "create_script_include",
          "update_script_include",
          "delete_script_include",
          "list_changesets",
          "get_changeset_details",
          "create_changeset",
          "update_changeset",
          "commit_changeset",
          "publish_changeset",
          "add_file_to_changeset",
          "create_knowledge_base",
          "list_knowledge_bases",
          "create_category",
          "create_article",
          "update_article",
          "publish_article",
          "list_articles",
          "get_article",
          "create_user",
          "update_user",
          "get_user",
          "list_users",
          "create_group",
          "update_group",
          "add_group_members",
          "remove_group_members",
          "list_groups"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]==1.3.0",
            "requests>=2.28.0",
            "pydantic>=2.0.0",
            "python-dotenv>=1.0.0",
            "starlette>=0.27.0",
            "uvicorn>=0.22.0",
            "httpx>=0.24.0"
          ],
          "devDependencies": [
            "pytest>=7.0.0",
            "pytest-cov>=4.0.0",
            "black>=23.0.0",
            "isort>=5.12.0",
            "mypy>=1.0.0",
            "ruff>=0.0.1"
          ]
        },
        "dockerfile_content": "FROM python:3.11-slim\n\nWORKDIR /app\n\n# Copy project files\nCOPY pyproject.toml README.md LICENSE ./\nCOPY src/ ./src/\n\n# Install the package in development mode\nRUN pip install -e .\n\n# Expose the port the app runs on\nEXPOSE 8080\n\n# Command to run the application using the provided CLI\nCMD [\"servicenow-mcp-sse\", \"--host=0.0.0.0\", \"--port=8080\"] ",
        "base_docker_image": "python:3.11-slim"
      }
    },
    {
      "name": "Shopify",
      "repo_url": "https://github.com/GeLi2001/shopify-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:47:58.253341+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 14,
        "forks": 0,
        "watchers": 14,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Server for Shopify API, enabling interaction with store data (products, customers, orders) through the GraphQL Admin API.",
        "tools_exposed": [
          "get-products",
          "get-product-by-id",
          "get-customers",
          "update-customer",
          "get-customer-orders",
          "get-orders",
          "update-order"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "dotenv": "^16.0.3",
            "graphql": "^16.6.0",
            "graphql-request": "^5.1.0",
            "minimist": "^1.2.8",
            "zod": "^3.21.4"
          },
          "devDependencies": {
            "@types/jest": "^29.5.0",
            "@types/minimist": "^1.2.2",
            "@types/node": "^18.15.11",
            "jest": "^29.5.0",
            "rimraf": "^5.0.10",
            "ts-jest": "^29.1.0",
            "ts-node": "^10.9.1",
            "typescript": "^5.0.4"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Siri Shortcuts",
      "repo_url": "https://github.com/dvcrn/mcp-server-siri-shortcuts",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:48:14.243316+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 101,
        "forks": 7,
        "watchers": 101,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server provides access to Siri shortcuts functionality via the Model Context Protocol (MCP), allowing listing, opening, and running shortcuts from the macOS Shortcuts app.",
        "tools_exposed": [
          "list_shortcuts",
          "open_shortcut",
          "run_shortcut"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.0.1",
            "express": "^4.21.1",
            "zod": "^3.23.8",
            "zod-to-json-schema": "^3.23.5"
          },
          "devDependencies": {
            "@types/express": "^5.0.0",
            "shx": "^0.3.4",
            "typescript": "^5.6.2"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine AS builder\n\nCOPY src/everything /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nCMD [\"node\", \"dist/index.js\"]",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Snowflake",
      "repo_url": "https://github.com/isaacwasserman/mcp-snowflake-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:48:28.234562+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 34,
        "forks": 12,
        "watchers": 34,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation providing database interaction with Snowflake. It enables running SQL queries with tools and interacting with a memo of data insights.",
        "tools_exposed": [
          "read_query",
          "write_query",
          "create_table",
          "list_tables",
          "describe-table",
          "append_insight"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "snowflake-connector-python[pandas]>=3.13.2",
            "pandas>=2.2.3",
            "python-dotenv>=1.0.1",
            "sqlparse>=0.5.3",
            "snowflake-snowpark-python>=1.26.0"
          ],
          "devDependencies": [
            "pyright>=1.1.389"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Solana Agent Kit",
      "repo_url": "https://github.com/sendaifun/solana-agent-kit/tree/main/examples/agent-kit-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:48:44.436381+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 1192,
        "forks": 635,
        "watchers": 1192,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm",
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Solana Agent Kit implementation using the Model Context Protocol (MCP) for handling protocol operations on the Solana blockchain.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.5.0",
            "dotenv": "^16.4.7",
            "solana-agent-kit": "1.4.8",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^22.13.4",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Spotify",
      "repo_url": "https://github.com/varunneal/spotify-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:48:58.499221+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 170,
        "forks": 30,
        "watchers": 170,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP project to connect Claude with Spotify. It allows controlling playback, searching for tracks/albums/artists/playlists, getting information, and managing the queue.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "mcp==1.3.0",
            "python-dotenv>=1.0.1",
            "spotipy==2.24.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.12"
      }
    },
    {
      "name": "Starwind UI",
      "repo_url": "https://github.com/Boston343/starwind-ui-mcp/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:48:58.736355+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [
          "Unknown"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null,
        "error": "GitHub API error: Error fetching basic stats: Redirect response '301 Moved Permanently' for url 'https://api.github.com/repos/Boston343/starwind-ui-mcp'\nRedirect location: 'https://api.github.com/repositories/948419950'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301; File fetch error: Failed to fetch repository contents: 301; Gemini analysis error: File list analysis error: Empty file list; README analysis error: Empty README content"
      }
    },
    {
      "name": "Stripe",
      "repo_url": "https://github.com/atharvagupta2003/mcp-stripe",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:49:21.507264+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 22,
        "forks": 1,
        "watchers": 22,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation that integrates with Stripe for handling payments, customers, and refunds, providing a structured API to manage financial transactions securely.",
        "tools_exposed": [
          "customer_create",
          "customer_retrieve",
          "customer_update",
          "payment_intent_create",
          "charge_list",
          "refund_create"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.2.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use the Python base image\nFROM python:3.12-slim\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the pyproject.toml and uv.lock files\nCOPY pyproject.toml uv.lock /app/\n\n# Install the dependencies\nRUN pip install --no-cache-dir uv\n\n# Copy the application code\nCOPY src /app/src\n\n# Set environment variables\nENV UV_COMPILE_BYTECODE=1\nENV UV_LINK_MODE=copy\n\n# Ensure that .venv/bin is in the PATH to access installed packages\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Copy .env.example to .env (to be configured with actual values in practice)\nCOPY .env.example .env\n\n# Run the MCP server\nENTRYPOINT [\"uv\", \"run\", \"src/server.py\"]\n",
        "base_docker_image": "python:3.12-slim"
      }
    },
    {
      "name": "ShaderToy",
      "repo_url": "https://github.com/wilsonchenghy/ShaderToy-MCP",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:49:34.095190+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 6,
        "forks": 0,
        "watchers": 6,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server connects LLMs to ShaderToy, allowing the LLM to query ShaderToy information and learn from existing shaders to generate complex new ones.",
        "tools_exposed": [
          "get_shader_info()",
          "search_shader()"
        ],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "TMDB",
      "repo_url": "https://github.com/Laksh-star/mcp-server-tmdb",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:49:49.998323+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 19,
        "forks": 3,
        "watchers": 19,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates with The Movie Database (TMDB) API to provide movie information, search capabilities, and recommendations.",
        "tools_exposed": [
          "search_movies",
          "get_recommendations",
          "get_trending"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.3",
            "node-fetch": "^3.3.2"
          },
          "devDependencies": {
            "@types/node": "^22.10.1",
            "@types/node-fetch": "^2.6.12",
            "shx": "^0.3.4",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\n# Create app directory\nWORKDIR /usr/src/app\n\n# Install app dependencies\n# A wildcard is used to ensure both package.json and package-lock.json are copied\nCOPY package*.json ./\n\n# Install dependencies (ignoring prepare scripts to avoid auto-build if necessary)\nRUN npm install --ignore-scripts\n\n# Build the project explicitly\nCOPY tsconfig.json ./\nCOPY src ./src\nRUN npm run build\n\n# Bundle app source\n# Expose a volume if necessary, but here we assume a command line tool\n\n# Default command\nCMD [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "Tavily search",
      "repo_url": "https://github.com/RamXX/mcp-tavily",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:50:09.258551+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 46,
        "forks": 9,
        "watchers": 46,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol server that provides AI-powered web search capabilities using Tavily's search API, enabling LLMs to perform sophisticated web searches, get direct answers, and search recent news articles.",
        "tools_exposed": [
          "tavily_web_search",
          "tavily_answer_search",
          "tavily_news_search"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "pydantic>=2.10.2",
            "python-dotenv>=1.0.1",
            "tavily-python>=0.5.0"
          ],
          "devDependencies": [
            "pytest>=8.3.5",
            "pytest-asyncio>=0.25.3",
            "pytest-cov>=6.0.0",
            "pytest-mock>=3.14.0"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Telegram",
      "repo_url": "https://github.com/chigwell/telegram-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:50:26.217045+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 23,
        "forks": 11,
        "watchers": 23,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Telegram MCP server providing tools to interact with Telegram chats (list chats, get messages, send messages) directly through MCP-compatible hosts.",
        "tools_exposed": [
          "get_chats",
          "get_messages",
          "send_message"
        ],
        "packages": {
          "dependencies": [
            "dotenv>=0.9.9",
            "httpx>=0.28.1",
            "mcp[cli]>=1.4.1",
            "nest-asyncio>=1.6.0",
            "telethon>=1.39.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Terminal-Control",
      "repo_url": "https://github.com/GongRzhe/terminal-controller-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:50:44.766742+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 15,
        "forks": 5,
        "watchers": 15,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server that enables secure terminal command execution, directory navigation, and file system operations through a standardized interface.",
        "tools_exposed": [
          "execute_command",
          "get_command_history",
          "get_current_directory",
          "change_directory",
          "list_directory",
          "write_file",
          "read_file",
          "insert_file_content",
          "delete_file_content",
          "update_file_content"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.3.0",
            "httpx>=0.25.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "TFT-Match-Analyzer",
      "repo_url": "https://github.com/GeLi2001/tft-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:50:59.964618+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 3,
        "forks": 0,
        "watchers": 3,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a Model Context Protocol (MCP) server for Team Fight Tactics (TFT) that provides access to TFT game data, allowing users to get match history and detailed match information.",
        "tools_exposed": [
          "tft_match_history",
          "tft_match_details"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.8.0",
            "node-fetch": "^3.3.2",
            "cheerio": "^1.0.0-rc.12",
            "yargs": "^17.7.2",
            "zod": "^3.23.8"
          },
          "devDependencies": {
            "@types/node": "^20.11.19",
            "@types/yargs": "^17.0.32",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": "node:14"
      }
    },
    {
      "name": "Ticketmaster",
      "repo_url": "https://github.com/delorenj/mcp-server-ticketmaster",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:51:14.900575+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 4,
        "watchers": 9,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server that provides tools for discovering events, venues, and attractions through the Ticketmaster Discovery API.",
        "tools_exposed": [
          "search_ticketmaster"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "@playwright/test": "^1.49.1",
            "axios": "^1.6.5",
            "dotenv": "^16.3.1"
          },
          "devDependencies": {
            "@types/node": "^20.11.5",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Todoist",
      "repo_url": "https://github.com/abhiz123/todoist-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:51:28.930883+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 121,
        "forks": 22,
        "watchers": 121,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation integrating Claude with Todoist for natural language task management. It allows Claude to interact with Todoist tasks using everyday language.",
        "tools_exposed": [
          "todoist_create_task",
          "todoist_get_tasks",
          "todoist_update_task",
          "todoist_complete_task",
          "todoist_delete_task"
        ],
        "packages": {
          "dependencies": {
            "@doist/todoist-api-typescript": "^3.0.3",
            "@modelcontextprotocol/sdk": "0.5.0"
          },
          "devDependencies": {
            "@types/node": "^22.10.1",
            "shx": "^0.3.4",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Typesense",
      "repo_url": "https://github.com/suhail-ak-s/mcp-typesense-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:51:46.654742+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 5,
        "forks": 1,
        "watchers": 5,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation that provides AI models with access to Typesense search capabilities, enabling LLMs to discover, search, and analyze data stored in Typesense collections.",
        "tools_exposed": [
          "typesense_query",
          "typesense_get_document",
          "typesense_collection_stats"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.0",
            "typesense": "^2.0.3"
          },
          "devDependencies": {
            "@types/node": "^22.13.5",
            "ts-node": "^10.9.2",
            "tsx": "^4.19.3",
            "typescript": "^5.7.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Travel Planner",
      "repo_url": "https://github.com/GongRzhe/TRAVEL-PLANNER-MCP-Server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:52:04.611799+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 26,
        "forks": 6,
        "watchers": 26,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation enabling interaction with Google Maps and travel planning services for tasks like location search, place details lookup, and route calculation.",
        "tools_exposed": [
          "searchPlaces",
          "getPlaceDetails",
          "calculateRoute",
          "getTimeZone"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.5.0",
            "@googlemaps/google-maps-services-js": "^3.3.41",
            "node-fetch": "^3.3.2",
            "zod": "^3.22.4",
            "zod-to-json-schema": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^22",
            "@types/google.maps": "^3.54.10",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "FROM node:22.12-alpine as builder\n\nCOPY src/travel-planner /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"] ",
        "base_docker_image": "node:22.12-alpine"
      }
    },
    {
      "name": "Unity Catalog",
      "repo_url": "https://github.com/ognis1205/mcp-server-unitycatalog",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:52:22.586474+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 11,
        "forks": 3,
        "watchers": 11,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": true,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "A Model Context Protocol (MCP) server for Unity Catalog that exposes Unity Catalog Functions as MCP tools.",
        "tools_exposed": [
          "uc_list_functions",
          "uc_get_function",
          "uc_create_function",
          "uc_delete_function"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.2.1",
            "pydantic>=2.10.6",
            "pydantic-settings>=2.7.1",
            "unitycatalog-ai>=0.1.0"
          ],
          "devDependencies": [
            "pyright>=1.1.393",
            "ruff>=0.9.4",
            "pytest>=8.3.4"
          ]
        },
        "dockerfile_content": "# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\n# Production environment\nFROM python:3.12-slim-bookworm\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Copy installed packages from the uv stage (if any exist in /root/.local)\n# This is typically where user-installed Python packages go when using pip with --user\n#COPY --from=uv /root/.loca[l] /root/.local\n\n# Copy the virtual environment from the uv stage\n# This ensures the application runs with the pre-installed dependencies\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"mcp-server-unitycatalog\"]",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "Unity3d Game Engine",
      "repo_url": "https://github.com/CoderGamester/mcp-unity",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:52:46.095902+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 303,
        "forks": 37,
        "watchers": 303,
        "language_stack": [
          "C#"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "MCP Unity is an implementation of the Model Context Protocol for the Unity editor, enabling AI assistants to interact with Unity projects. It provides a bridge between Unity and a Node.js server implementing the MCP protocol.",
        "tools_exposed": [
          "execute_menu_item",
          "select_gameobject",
          "update_component",
          "add_package",
          "run_tests",
          "notify_message",
          "add_asset_to_scene"
        ],
        "packages": {
          "dependencies": {
            "com.unity.nuget.newtonsoft-json": "3.2.1",
            "com.unity.editorcoroutines": "1.0.0"
          },
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Unity Integration (Advanced)",
      "repo_url": "https://github.com/quazaai/UnityMCPIntegration",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:53:14.437858+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 33,
        "forks": 7,
        "watchers": 33,
        "language_stack": [
          "C#"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This server provides integration between the Model Context Protocol (MCP) and the Unity Editor, allowing AI assistants to understand, interact with, and manipulate Unity projects in real-time, including accessing scene/project info, managing files, and executing code.",
        "tools_exposed": [
          "get_editor_state",
          "get_current_scene_info",
          "get_game_objects_info",
          "execute_editor_command",
          "get_logs",
          "verify_connection",
          "read_file",
          "read_multiple_files",
          "write_file",
          "edit_file",
          "list_directory",
          "directory_tree",
          "search_files",
          "get_file_info",
          "find_assets_by_type",
          "list_scripts"
        ],
        "packages": {
          "dependencies": {
            "com.unity.nuget.newtonsoft-json": "3.2.1"
          },
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Vega-Lite",
      "repo_url": "https://github.com/isaacwasserman/mcp-vegalite-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:53:27.602740+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 47,
        "forks": 12,
        "watchers": 47,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server providing an interface for LLMs to visualize data using Vega-Lite syntax.",
        "tools_exposed": [
          "save_data",
          "visualize_data"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "vl-convert-python"
          ],
          "devDependencies": [
            "pyright>=1.1.389"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Video Editor",
      "repo_url": "https://github.com/burningion/video-editing-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:53:43.987220+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 88,
        "forks": 13,
        "watchers": 88,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows users to upload, edit, search, and generate videos using the Video Jungle service and API key.",
        "tools_exposed": [
          "add-video",
          "search-videos",
          "generate-edit-from-videos",
          "generate-edit-from-single-video",
          "search-local-videos"
        ],
        "packages": {
          "dependencies": [
            "einops>=0.8.0",
            "manim>=0.18.1",
            "mcp>=1.0.0",
            "numpy>=2.2.2",
            "opentimelineio>=0.17.0",
            "osxphotos>=0.69.2",
            "pillow>=11.0.0",
            "requests>=2.32.3",
            "thefuzz>=0.22.1",
            "timm>=1.0.12",
            "torch>=2.5.1",
            "transformers>=4.47.1",
            "videojungle>=0.1.46"
          ],
          "devDependencies": [
            "ipykernel>=6.29.5",
            "manim>=0.18.1",
            "mcp[cli]===1.2.0rc1",
            "pre-commit>=4.0.1",
            "ruff>=0.8.4"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Video Jungle",
      "repo_url": "https://www.video-jungle.com/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:53:43.987471+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 0,
        "forks": 0,
        "watchers": 0,
        "language_stack": [],
        "package_manager": [],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": false,
        "has_examples": false,
        "has_tests": false,
        "server_description": null,
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "error": "Not a GitHub repository: https://www.video-jungle.com/"
      }
    },
    {
      "name": "Virtual location (Google Street View,etc.)",
      "repo_url": "https://github.com/mfukushim/map-traveler-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:54:05.782508+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 0,
        "watchers": 8,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server that creates an environment for a virtual avatar to travel on Google Maps, allowing users to give instructions and receive progress reports with photos via an MCP client.",
        "tools_exposed": [
          "get_traveler_view_info",
          "get_traveler_location",
          "reach_a_percentage_of_destination",
          "set_traveler_location",
          "get_traveler_destination_address",
          "set_traveler_destination_address",
          "start_traveler_journey",
          "stop_traveler_journey",
          "set_traveler_info",
          "get_traveler_info",
          "set_avatar_prompt",
          "reset_avatar_prompt",
          "get_sns_feeds",
          "get_sns_mentions",
          "post_sns_writer",
          "reply_sns_writer",
          "add_like",
          "tips",
          "get_setting"
        ],
        "packages": {
          "dependencies": {
            "@anthropic-ai/sdk": "^0.33.1",
            "@atproto/api": "^0.13.27",
            "@effect/platform": "^0.73.1",
            "@effect/platform-node": "^0.69.1",
            "@effect/sql": "^0.26.1",
            "@effect/sql-sqlite-node": "^0.27.1",
            "@libsql/client": "^0.14.0",
            "@modelcontextprotocol/sdk": "^1.1.1",
            "@pixai-art/client": "^0.4.0",
            "dayjs": "^1.11.13",
            "dotenv": "^16.4.7",
            "drizzle-orm": "^0.38.3",
            "effect": "^3.12.4",
            "form-data": "^4.0.1",
            "geolib": "^3.3.4",
            "jimp": "^1.6.0",
            "sharp": "^0.33.5",
            "ws": "^8.18.0",
            "zod": "^3.24.1"
          },
          "devDependencies": {
            "@babel/cli": "^7.26.4",
            "@babel/core": "^7.26.0",
            "@babel/plugin-transform-export-namespace-from": "^7.25.9",
            "@babel/plugin-transform-modules-commonjs": "^7.26.3",
            "@effect/build-utils": "^0.7.8",
            "@effect/language-service": "^0.2.0",
            "@effect/vitest": "^0.17.0",
            "@types/node": "^22.10.7",
            "@types/ws": "^8.5.13",
            "babel-plugin-annotate-pure-calls": "^0.5.0",
            "drizzle-kit": "^0.30.1",
            "tsx": "^4.19.2",
            "typescript": "^5.7.3",
            "vitest": "^2.1.8"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "VolcEngine TOS",
      "repo_url": "https://github.com/dinghuazhou/sample-mcp-server-tos",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:54:20.578495+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 1,
        "watchers": 2,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server implementation for retrieving data from volcengine TOS (Tencent Object Storage).",
        "tools_exposed": [
          "ListBuckets",
          "ListObjectsV2",
          "GetObject"
        ],
        "packages": {
          "dependencies": [
            "tos>=2.8.0",
            "mcp>=1.0.0",
            "python-dotenv>=1.0.1"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Wanaku MCP Router",
      "repo_url": "https://github.com/wanaku-ai/wanaku/",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:54:39.891581+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 56,
        "forks": 16,
        "watchers": 56,
        "language_stack": [
          "Java"
        ],
        "package_manager": [
          "maven"
        ],
        "dependencies_file": "pom.xml",
        "has_dockerfile": false,
        "has_docs": true,
        "has_readme": true,
        "has_examples": true,
        "has_tests": true,
        "server_description": "Wanaku is an MCP Router for AI-enabled applications, designed to facilitate standardized context provision to LLMs using the Model Context Protocol.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [],
          "devDependencies": [
            "kr.motd.maven:os-maven-plugin",
            "org.apache.maven.plugins:maven-release-plugin",
            "org.jreleaser:jreleaser-maven-plugin"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Webflow",
      "repo_url": "https://github.com/kapilduraphe/webflow-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:54:53.898557+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 9,
        "forks": 6,
        "watchers": 9,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables Claude to interact with Webflow's APIs.",
        "tools_exposed": [
          "get_sites",
          "get_site"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.0.4",
            "webflow-api": "^3.0.0",
            "dotenv": "^16.4.1",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@types/node": "^20.11.5",
            "prettier": "^3.2.4",
            "ts-node": "^10.9.2",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Stage 1: Build\nFROM node:16-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package.json ./\n\n# Install dependencies\nRUN npm install --ignore-scripts\n\n# Copy the source code\nCOPY . .\n\n# Build the project\nRUN npm run build\n\n# Stage 2: Run\nFROM node:16-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy only the necessary files\nCOPY --from=builder /app/dist /app/dist\nCOPY package.json ./\n\n# Set environment variables (you should set this in your environment or secrets)\nENV WEBFLOW_API_TOKEN=your-api-token\n\n# Install production dependencies\nRUN npm install --production\n\n# Start the server\nENTRYPOINT [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:16-alpine"
      }
    },
    {
      "name": "whale-tracker-mcp",
      "repo_url": "https://github.com/kukapay/whale-tracker-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:55:11.464518+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 8,
        "forks": 3,
        "watchers": 8,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server integrates with the Whale Alert API to enable real-time tracking and analysis of large cryptocurrency transactions (whale movements) by exposing tools, resources, and prompts to MCP-compatible clients.",
        "tools_exposed": [
          "get_recent_transactions",
          "get_transaction_details"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.4.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Whois MCP",
      "repo_url": "https://github.com/bharathvaj-ganesan/whois-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:55:25.727980+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 5,
        "watchers": 4,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "pnpm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows AI agents to perform WHOIS lookups to retrieve domain, TLD, IP address, and ASN registration details, such as ownership and expiry dates.",
        "tools_exposed": [
          "whois_domain",
          "whois_tld",
          "whois_ip",
          "whois_as"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.6.1",
            "whoiser": "2.0.0-beta.3",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "shx": "^0.3.4",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Wikidata MCP",
      "repo_url": "https://github.com/zzaebok/mcp-wikidata",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:55:46.614314+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 2,
        "forks": 0,
        "watchers": 2,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This is a server implementation for the Wikidata API using the Model Context Protocol (MCP). It provides tools to search Wikidata identifiers (entity and property), extract metadata (labels and descriptions), and execute SPARQL queries.",
        "tools_exposed": [
          "search_entity",
          "search_property",
          "get_properties",
          "execute_sparql",
          "get_metadata"
        ],
        "packages": {
          "dependencies": [
            "mcp[cli]>=1.4.1",
            "httpx>=0.28.1"
          ],
          "devDependencies": [
            "black>=25.1.0",
            "langchain-openai>=0.3.11",
            "langgraph>=0.3.21",
            "langchain-core>=0.3.49",
            "langchain-mcp-adapters>=0.0.6"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": "python:3.11"
      }
    },
    {
      "name": "WildFly MCP",
      "repo_url": "https://github.com/wildfly-extras/wildfly-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:55:58.625560+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 4,
        "forks": 6,
        "watchers": 4,
        "language_stack": [
          "Java"
        ],
        "package_manager": [
          "Unknown"
        ],
        "dependencies_file": null,
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This project aims to define tooling allowing WildFly users to benefit from Generative AI capabilities when monitoring and managing WildFly servers.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {},
          "devDependencies": {}
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Windows CLI",
      "repo_url": "https://github.com/SimonB97/win-cli-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:56:19.923338+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 126,
        "forks": 22,
        "watchers": 126,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "An MCP server for secure command-line interactions on Windows systems, enabling controlled access to PowerShell, CMD, Git Bash shells, and remote systems via SSH.",
        "tools_exposed": [],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "1.0.1",
            "@types/ssh2": "^1.15.1",
            "ssh2": "^1.16.0",
            "yargs": "^17.7.2",
            "zod": "^3.22.4"
          },
          "devDependencies": {
            "@jest/globals": "^29.7.0",
            "@types/jest": "^29.5.11",
            "@types/node": "^20.11.0",
            "@types/yargs": "^17.0.33",
            "jest": "^29.7.0",
            "shx": "^0.3.4",
            "ts-jest": "^29.1.1",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use an official Node.js runtime as a parent image\nFROM node:18-alpine AS build\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the package files and install the dependencies\nCOPY package.json package-lock.json ./\nRUN npm install --ignore-scripts\n\n# Copy the rest of the application\nCOPY . .\n\n# Build the TypeScript code\nRUN npm run build\n\n# Use a lighter image for the runtime\nFROM node:18-alpine AS runtime\n\nWORKDIR /app\n\n# Copy the built application from the build stage\nCOPY --from=build /app/dist ./dist\nCOPY --from=build /app/package.json ./package.json\nCOPY --from=build /app/package-lock.json ./package-lock.json\n\n# Install only production dependencies\nRUN npm ci --omit=dev\n\n# Command to run the application\nENTRYPOINT [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "World Bank data API",
      "repo_url": "https://github.com/anshumax/world_bank_mcp_server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:56:42.136303+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 15,
        "forks": 4,
        "watchers": 15,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip",
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server enables interaction with the open World Bank data API, allowing AI assistants to list indicators and analyse those indicators for available countries.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "fastmcp>=0.4.1",
            "mcp>=1.0.0",
            "mysql-connector-python>=9.2.0",
            "pandas>=2.2.3",
            "requests>=2.32.3"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use an official Python image from the Docker Hub\nFROM python:3.11-slim-bookworm\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the project files into the working directory\nCOPY . /app\n\n# Install the required dependencies\nRUN pip install --no-cache-dir hatchling && \\\n    pip install --no-cache-dir -r requirements.txt\n\n# Expose the port that the server runs on\nEXPOSE 8000\n\n# Set the environment path\nENV PYTHONPATH \"${PYTHONPATH}:/app/src\"\n\n# Run the application\nENTRYPOINT [\"hatch\", \"run\", \"world_bank_mcp_server\"]\n",
        "base_docker_image": "python:3.11-slim-bookworm"
      }
    },
    {
      "name": "X (Twitter)",
      "repo_url": "https://github.com/EnesCinr/twitter-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:56:56.484784+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 162,
        "forks": 13,
        "watchers": 162,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "This MCP server allows Clients to interact with Twitter, enabling posting tweets and searching Twitter.",
        "tools_exposed": [
          "post_tweet",
          "search_tweets"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "0.6.0",
            "dotenv": "^16.4.7",
            "twitter-api-v2": "^1.18.2",
            "zod": "^3.24.0"
          },
          "devDependencies": {
            "@types/node": "^20.11.24",
            "typescript": "^5.3.3"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Node.js image for building the server\nFROM node:18-alpine AS builder\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy package.json and package-lock.json to the working directory\nCOPY package.json package-lock.json ./\n\n# Install dependencies\nRUN npm install\n\n# Copy the entire source code into the working directory\nCOPY . .\n\n# Build the TypeScript files\nRUN npm run build\n\n# Use a smaller Node.js image for the runtime\nFROM node:18-slim\n\n# Set the working directory in the runtime image\nWORKDIR /app\n\n# Copy the build files from the builder image\nCOPY --from=builder /app/build ./build\n\n# Copy package.json and package-lock.json for production install\nCOPY package.json package-lock.json ./\n\n# Install only production dependencies\nRUN npm install --omit=dev\n\n# Set environment variables for Twitter API\nENV API_KEY=your_api_key_here\nENV API_SECRET_KEY=your_api_secret_key_here\nENV ACCESS_TOKEN=your_access_token_here\nENV ACCESS_TOKEN_SECRET=your_access_token_secret_here\n\n# Start the server\nCMD [\"node\", \"build/index.js\"]",
        "base_docker_image": "node:18-alpine"
      }
    },
    {
      "name": "X (Twitter)",
      "repo_url": "https://github.com/vidhupv/x-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:57:16.949040+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 44,
        "forks": 12,
        "watchers": 44,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "An MCP server to create, manage and publish X/Twitter posts directly through Claude chat.",
        "tools_exposed": [],
        "packages": {
          "dependencies": [
            "httpx>=0.28.0",
            "mcp>=1.1.0",
            "python-dotenv>=1.0.1",
            "tweepy>=4.14.0"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the pyproject.toml and uv.lock to install dependencies\nCOPY pyproject.toml uv.lock ./\n\n# Install the project's dependencies using uv\nRUN --mount=type=cache,target=/root/.cache/uv uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Add the rest of the project source code\nADD src /app/src\n\n# Install the project itself\nRUN --mount=type=cache,target=/root/.cache/uv uv sync --frozen --no-dev --no-editable\n\n# Create a new stage for the final release\nFROM python:3.12-slim-bookworm\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the installed dependencies from the uv stage\nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Add the source code to the container\nADD src /app/src\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Set environment variables for Twitter API keys\n# These should be set during runtime or via a secrets manager\nENV TWITTER_API_KEY=your_api_key\nENV TWITTER_API_SECRET=your_api_secret\nENV TWITTER_ACCESS_TOKEN=your_access_token\nENV TWITTER_ACCESS_TOKEN_SECRET=your_access_token_secret\n\n# Run the MCP server using uv\nENTRYPOINT [\"uv\", \"run\", \"x-mcp\"]\n",
        "base_docker_image": "ghcr.io/astral-sh/uv:python3.12-bookworm-slim"
      }
    },
    {
      "name": "xcodebuild",
      "repo_url": "https://github.com/ShenghaiWang/xcodebuild",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:57:33.728249+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 38,
        "forks": 1,
        "watchers": 38,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "uv",
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server that builds and tests iOS Xcode workspaces/projects, enabling seamless workflows in Visual Studio Code using extensions like Cline or Roo Code.",
        "tools_exposed": [
          "build",
          "test"
        ],
        "packages": {
          "dependencies": [
            "httpx>=0.28.1",
            "mcp[cli]>=1.3.0"
          ],
          "devDependencies": [
            "pyright>=1.1.389",
            "ruff>=0.7.3"
          ]
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "Xero-mcp-server",
      "repo_url": "https://github.com/john-zhang-dev/xero-mcp",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:57:54.168769+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 10,
        "forks": 4,
        "watchers": 10,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": true,
        "server_description": "This MCP server allows Clients to interact with Xero Accounting Software.",
        "tools_exposed": [
          "authenticate",
          "create_bank_transactions",
          "create_contacts",
          "get_balance_sheet",
          "list_accounts",
          "list_bank_transactions",
          "list_contacts",
          "list_invoices",
          "list_journals",
          "list_organisations",
          "list_payments",
          "list_quotes"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.7.0",
            "dotenv": "^16.4.7",
            "open": "^10.1.0",
            "xero-node": "^10.0.0",
            "zod": "^3.24.2"
          },
          "devDependencies": {
            "@types/jest": "^29.5.14",
            "@types/node": "^22.13.10",
            "jest": "^29.7.0",
            "ts-jest": "^29.3.0",
            "ts-node": "^10.9.2",
            "tsx": "^4.19.3",
            "typescript": "^5.8.2"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\nFROM node:lts-alpine\n\nWORKDIR /app\n\n# Copy package files and install dependencies\nCOPY package*.json ./\nRUN npm install --ignore-scripts\n\n# Copy all source files\nCOPY . .\n\n# Build the project\nRUN npm run build\n\nEXPOSE 5000\n\nCMD [ \"node\", \"build/index.js\" ]\n",
        "base_docker_image": "node:lts-alpine"
      }
    },
    {
      "name": "XiYan",
      "repo_url": "https://github.com/XGenerationLab/xiyan_mcp_server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:58:09.416524+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 48,
        "forks": 8,
        "watchers": 48,
        "language_stack": [
          "Python"
        ],
        "package_manager": [
          "pip"
        ],
        "dependencies_file": "pyproject.toml",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server that enables natural language queries to databases, powered by XiYan-SQL.",
        "tools_exposed": [
          "get_data"
        ],
        "packages": {
          "dependencies": [
            "mcp>=1.0.0",
            "mysql-connector-python>=9.1.0",
            "llama_index",
            "sqlalchemy",
            "pymysql"
          ],
          "devDependencies": []
        },
        "dockerfile_content": "# \u4f7f\u7528Python 3.11\u4f5c\u4e3a\u57fa\u7840\u955c\u50cf\nFROM python:3.11-slim\n\n# \u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55\nWORKDIR /app\n\n#COPY requirements.txt .\nRUN pip install xiyan-mcp-server\n\n\n# \u8fd0\u884c\u5e94\u7528\nCMD [\"python\", \"-m\", \"xiyan_mcp_server\"]",
        "base_docker_image": "python:3.11-slim"
      }
    },
    {
      "name": "XMind",
      "repo_url": "https://github.com/apeyroux/mcp-xmind",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:58:22.700990+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 18,
        "forks": 1,
        "watchers": 18,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": false,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol server for analyzing and querying XMind mind maps, enabling search, extraction, and analysis of their content.",
        "tools_exposed": [
          "read_xmind",
          "get_todo_tasks",
          "list_xmind_directory",
          "read_multiple_xmind_files",
          "search_xmind_files",
          "extract_node",
          "extract_node_by_id",
          "search_nodes"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^0.5.0",
            "adm-zip": "^0.5.16",
            "diff": "^5.1.0",
            "glob": "^10.3.10",
            "minimatch": "^10.0.1",
            "zod": "^3.24.1",
            "zod-to-json-schema": "^3.24.1"
          },
          "devDependencies": {
            "@types/adm-zip": "^0.5.7",
            "@types/diff": "^5.0.9",
            "@types/minimatch": "^5.1.2",
            "@types/node": "^20.17.10",
            "shx": "^0.3.4",
            "typescript": "^5.7.2"
          }
        },
        "dockerfile_content": null,
        "base_docker_image": null
      }
    },
    {
      "name": "YouTube",
      "repo_url": "https://github.com/ZubeidHendricks/youtube-mcp-server",
      "type": "community",
      "analysis_results": {
        "analysis_time_utc": "2025-04-08T02:58:43.856278+00:00",
        "gemini_model_analysis": "gemini-2.5-pro-exp-03-25",
        "stars": 85,
        "forks": 13,
        "watchers": 85,
        "language_stack": [
          "TypeScript",
          "Node.js"
        ],
        "package_manager": [
          "npm",
          "yarn"
        ],
        "dependencies_file": "package.json",
        "has_dockerfile": true,
        "has_docs": false,
        "has_readme": true,
        "has_examples": false,
        "has_tests": false,
        "server_description": "A Model Context Protocol (MCP) server implementation for YouTube, enabling AI language models to interact with YouTube content through a standardized interface.",
        "tools_exposed": [
          "videos.getVideo",
          "transcripts.getTranscript",
          "videos.searchVideos",
          "channels.getChannel",
          "channels.listVideos",
          "playlists.getPlaylistItems",
          "playlists.getPlaylist"
        ],
        "packages": {
          "dependencies": {
            "@modelcontextprotocol/sdk": "^1.1.1",
            "googleapis": "^129.0.0",
            "ytdl-core": "^4.11.5",
            "youtube-transcript": "^1.0.6"
          },
          "devDependencies": {
            "@types/node": "^18.0.0",
            "typescript": "^5.0.0",
            "ts-node": "^10.9.1",
            "nodemon": "^3.0.0"
          }
        },
        "dockerfile_content": "# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile\n# Use an official Node runtime as the base image\nFROM node:16-alpine AS builder\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and package-lock.json\nCOPY package.json /app/\nCOPY tsconfig.json /app/\n\n# Install dependencies\nRUN npm install\n\n# Copy the rest of the application's source code\nCOPY . /app\n\n# Build the application\nRUN npm run build\n\n# Use a lightweight Node runtime as the release image\nFROM node:16-alpine AS release\n\n# Set the working directory\nWORKDIR /app\n\n# Copy the built application from the builder stage\nCOPY --from=builder /app/dist /app/dist\n\n# Copy package.json and package-lock.json\nCOPY --from=builder /app/package.json /app/package-lock.json /app/\n\n# Install only production dependencies\nRUN npm ci --only=production\n\n# Set environment variables (You need to set these while running the Docker container)\n# ENV YOUTUBE_API_KEY=<Your-YouTube-API-Key>\n# ENV YOUTUBE_TRANSCRIPT_LANG=en\n\n# Define the command to run the application\nCMD [\"node\", \"dist/index.js\"]\n",
        "base_docker_image": "node:16-alpine"
      }
    }
  ]
}